{"ChilloutMix":{"status":"inactive","modelid":"civitai-11745","rating":4.94,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/20fcc1d7-29ce-42d8-1502-02c4e50e9100/width=450/174703.jpeg","description":"<h3><u>This model has been republished and its ownership transferred to Civitai with the full permissions of the model creator. They have asked that all identifying information about them be removed from the model details.</u><br /><br /><br /><strong><u>*I modified the License.(22/2/Feb)<br />That is not usual \"creativeml-openrail-m\"<br />Check Permission and Liscense below(modified Dreamlike Liscense.)</u></strong></h3><p></p><p></p><p><u>When I made samples,<br />My eta (see setting) was \"0\".</u></p><p><u>And ESND was \"1\"</u></p><p><u>Now,I canged them to eta to \"0.67\" and ESND \"31337\"(20/Feb/2023)</u></p><p></p><p></p><p><strong><u>よいこのみんなは節度を守って楽しもうな！！</u></strong></p><p></p><p><strong><u>職場や家族の前で開くのはやめておいたほうがいいよ！！</u></strong></p><p></p><p><strong><u>当モデルを転売することは認めていません。</u></strong></p><p><strong><u>生成された画像の取り扱いには、自己責任の上、十分注意してください。</u></strong></p><p><strong><u>当モデルを使用したことを明記せずに生成された画像を公開することは禁止です。</u></strong></p><p><strong><u>商用利用は一切認めていません。</u></strong></p><p></p><p><strong><u>AIコミュニティの発展に悪影響を与えるような行動や個人の権利やプライバシーを侵害するような利用は禁止します。</u></strong></p><p></p><p><strong><u>New merge model for 2.5D illustration here!!</u></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9291/sunshinemix\">https://civitai.com/models/9291/sunshinemix</a></p><p>↑</p><p>(少しイラスト寄りにしたのもあります。)</p><p></p><h3>IMPORTANT:First of all, I never suggest regenerate images of “real “person,</h3><h1>but, photo \"realistic\" images.</h1><h3><strong><u>本人郑重声明：本模型原则上禁止用于训练基于明星、公众人物肖像的风格模型训练，因为这会带来争议，对AI社区的发展造成不良的负面影响。如各位一定要违反以上声明训练相关模型并公开发布，请在您的发布说明中删除与本模型有关的一切描述。感谢各位使用者的支持与理解。</u></strong></h3><p><strong><u>I solemnly declare: In principle, this model is prohibited from being used for training style models based on portraits of celebrities and public figures, because it will cause controversy and have a negative impact on the development of the AI community. If you must violate the above statement to train the relevant model and release it publicly, please delete all descriptions related to this model in your release notes. Thank you for your support and understanding.</u></strong></p><p></p><h3><u>I appreciate you enjoy my model.</u></h3><h3><u>But, it might cause legal conflicts if you made some works/Loras/Embeddings named with actual person/copyright.</u></h3><h3><u>I beg you never to put them with my model.</u></h3><h3><u>If you can't be with actual name/copyright, just remove my model from your works.</u></h3><h3><u>I never suggest to regenerate actual persons/copyright with my models.</u></h3><h3><u>And I never want any legal conflicts from my models.</u></h3><h3><br /><u>PLEASE!! Care about legal conscious and privacy!!</u><br /></h3><p></p><h3><strong><u>Show what your favorite works from this merge</u></strong></h3><h3><strong><u>on comments, if you like this mix.</u></strong></h3><h3><br /><strong><u>I wanna see and share your good ideas from this merge. :)</u></strong></h3><p></p><h3><strong><u>It’s my pleasure.</u></strong></h3><p></p><h3><strong><u>Let's share your good ideas</u></strong></h3><h3><strong><u>and enjoy this merge!!</u></strong></h3><p>(Some funs have already put their great works from this merge.<br />It could be like a kind of community.)</p><p></p><p></p><p><strong><u>I started to put some tips with samples/prompts on review.<br />Try to find them!!(I've already put 5. 14/Feb/2023)</u></strong></p><p></p><p>(I'm sorry but I stop to invite my discord.)</p><p></p><p>&lt;EXPLANATION of this model&gt;</p><p>Konnichiwa!!!!</p><p></p><p><u>・This is Merged \"</u><strong><u>Basilmix</u></strong><u>\"(</u><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix\"><u>nuigurumi/basil_mix · Hugging Face)</u></a></p><p><u>+ wonderful realistic models.</u></p><p><strong><u>(</u></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4486/pov-skin-texture-r34-lucid-black\"><strong><u>PoV Skin Texture - r34 Lucid Black | Stable Diffusion Checkpoint | Civitai</u></strong></a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4481/pov-skin-texture-dreamlike-r34\"><strong><u>PoV Skin Texture - Dreamlike r34 | Stable Diffusion Checkpoint | Civitai</u></strong></a></p><p><strong><u>by </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/twilightBOO\"><strong><u>twilightBOO</u></strong></a><strong><u>)</u></strong></p><p></p><p></p><h3><s><u>・Use: </u></s><strong><s><u>vae-ft-mse-840000（←！！）</u></s></strong></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\"><s>stabilityai/sd-vae-ft-mse-original at main (</s></a><a target=\"_blank\" rel=\"ugc\" href=\"http://huggingface.co\"><s>huggingface.co</s></a><s>)</s></p><p><s>1. Get </s><strong><s><u>vae-ft-mse-840000-ema-pruned.safetensor</u></s></strong></p><p><s>2. Put it in folder(models&gt;VAE)</s></p><p><s>3. Set VAE on webUI(Settings&gt;Stable diffusion&gt;SD VAE)</s></p><p><s>4. Don't forget to push \"Apply settings\"</s></p><p><s>(Your picture would be foggy, if you didnt use vae with this merge.)</s></p><p>You dont need to use VAE with the latest ver.\"Chilloutmix-Ni\"</p><p></p><p><u>・All sample images have been upscaled using highrexfix</u></p><p>And, I made some samples when I made test ckpt file for myself.<br />I made safetensor file after that.<br />(Cuz, ckpt files couldnt be liked on this site, because they include arbitrary code.)<br /><strong>That’s why Prompts from some sample pictures wouldn't make the same pictures,sorry.</strong></p><p></p><p><u>・I think this model is not perfect,</u></p><p><u>but better for realistic </u><strong><u>Asian(+ other areas.Just try)</u></strong><u> .</u></p><p></p><h3><strong><u>・Face variation is really limited.</u></strong></h3><h3><u>Use </u><strong><u>LORA</u></strong><u> or </u><strong><u>Embeddings</u></strong><u> as you like.(←！！)</u></h3><p>I like to use \"<strong>Ulzzang-6500</strong>\" embeddings <strong>(I used that for all sample images).</strong><br />This is my type....I couldn't avoid generating with this....</p><p><strong>You can get it here.</strong></p><p>(Thanks @jayp<strong> </strong>and<strong> @</strong>samo9t4gmailcom<strong> </strong>for telling me on comments.)</p><p>↓</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/sdnsfw/comments/yv8d3l/embedding_i_trained_for_korean_ulzzang_face/\">https://www.reddit.com/r/sdnsfw/comments/yv8d3l/embedding_i_trained_for_korean_ulzzang_face/</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://moritz.pm/files/ulzzang-6500.pt\">https://moritz.pm/files/ulzzang-6500.pt</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://oo.pe/https://moritz.pm/files/ulzzang-6500.pt\">https://oo.pe/https://moritz.pm/files/ulzzang-6500.pt</a></p><p>(all 3 adress are the same files)</p><p><br /><strong>Other Embeddings</strong></p><p>By <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/FapMagi\">FapMagi Creator Profile | Civitai</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4514/pure-eros-face\">Pure Eros Face | Stable Diffusion TextualInversion | Civitai</a></p><p></p><p>By Dcy:Asian face mix</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dcy/AsiaFacemix/tree/main\"><u>https://huggingface.co/dcy/AsiaFacemix/tree/main</u></a></p><p>(Thanks for sharing <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:182740\" data-label=\"yatagarasu\">@yatagarasu</span> !!)</p><p></p><p></p><p><em>As the same as other areas of this world, Asian are quite variated and there are quite lots of races, communities and nations in Asia.</em></p><p><em>Who can tell you what is the typical Asian?</em></p><p><em>'\"Typical \"could cause less variation.</em></p><p></p><h3><strong><u>I've been coming to think face variation should be developed not on models, but on LORAs and also on embeddings.</u></strong></h3><h3><strong><u>Because,results can be quite randomed if that was developed on models.</u></strong></h3><p><strong><u>(Yeah,I know random encounting could be also fun,though.)</u></strong></p><h3><strong><u>You can make ideal faces with LORAs, embeddings as you like.</u></strong></h3><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2b7da5af-5fd7-41df-7f35-599b030ebb00/width=525\" /><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/153f7b0b-8e7a-4824-136a-73b7da7d9e00/width=525\" /><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e3e62a54-9227-403d-5f4d-2ab7fb338e00/width=525\" /><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/41341746-b47a-493f-7d96-970206636000/width=525\" /><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/43d782a3-fecc-47d5-eb0f-a9a3e477ce00/width=525\" /><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c3c44036-82e6-4eba-434a-9ae908462a00/width=525\" /><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9447904a-cfbd-4470-8e9b-75bb54616c00/width=525\" /><p></p><p>(Some examples of face variation by using some TI/HN/LORA)</p><p></p><p></p><h3><strong><u>Some Lora could work very nice, even though they were made for 2D charas.</u></strong><br /><br /><strong>They are notable that 2D charas Loras generate not only crothes, hair styles, but also facial features!!</strong></h3><h3></h3><h3><u>This model is likely to get bigger tits.</u></h3><p>If you like more smaller tits, try both of prompts,</p><p>\"(small breasts) and (fantasy breasts)\"</p><p>(Slim girl) maybe good.</p><p><br /></p><p>・Preparing:<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/TASUKU2023/Chilloutmix\">TASUKU2023/Chilloutmix · Hugging Face</a></p><p></p><p></p><p>I put explanation too much,sorry.</p><p></p><p>ーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーーー</p><p>Due to using <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0\">Dreamlike Diffusion 1.0</a>, this model has the following license:</p><p></p><p>Modified License（Dreamlike photoreal allowed me to modify Liscence.）</p><p>This model is licesed under a modified CreativeML OpenRAIL-M license.</p><p>- You can't host or use the model or its derivatives on websites/apps/etc., from which you earn, will earn, or plan to earn revenue or donations. If you want to, please email us at <a target=\"_blank\" rel=\"ugc\" href=\"mailto:contact@dreamlike.art\">contact@dreamlike.art</a></p><p>- You are free to host the model card and files (Without any actual inference or finetuning) on both commercial and non-commercial websites/apps/etc. Please state the full model name (Dreamlike Diffusion 1.0) and include a link to the model card (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0\">https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0</a><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)**\">)</a></p><p>- You are free to host the model or its derivatives on completely non-commercial websites/apps/etc (Meaning you are not getting ANY revenue or donations). Please state the full model name (Dreamlike Diffusion 1.0) and include a link to the model card (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0\">https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0</a><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)**\">)</a></p><p></p><p><s>- You are free to use the outputs of the model or the outputs of the model's derivatives for commercial purposes in teams of 10 or less</s></p><p><strong><u>（Edit</u></strong><u>:</u><strong><u>We sencerely ban to use the outputs of the model or the outputs of the model's derivatives(further murged models and Loras included) for commercial purposes. Because, it would cause controversy and have a negative impact on the development of the AI community, wheter images were generated from real person or not.）</u></strong></p><p>- You can't use the model to deliberately produce nor share illegal or harmful outputs or content</p><p>- The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license</p><p>- You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the modified CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully) Please read the full license here: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md\">https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md</a></p>","ratingcount":2228,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"NeverEnding Dream (NED)":{"status":"inactive","modelid":"civitai-11925","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b58bd267-9df8-45dc-7543-4e62101cad00/width=450/114053.jpeg","description":"<h2>NeverEnding Dream (a.k.a. NED)</h2><h3>\"This is a dream that you will never want to wake up from. A NeverEnding Dream.\"</h3><p><strong>Add a ❤️ to receive future updates. This took much time and effort, please be supportive </strong>🫂<br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><p><strong>Available on </strong><a target=\"_blank\" rel=\"ugc\" href=\"http://Sinkin.ai\"><strong>Sinkin.ai</strong></a><strong> with GPU acceleration.</strong></p><p>It has been a while since I made a model. I've been making LoRA's non stop for the last month, but I felt like I needed something. A big problem with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\">DreamShaper</a> is that it wasn't much compatibles with the LoRA's I was making. So I wanted to create a model that was \"artistic\" like DreamShaper but also able to use my LoRA's and booru tags for generating images. Plus I wanted this to be able to make <strong>good </strong>anime stuff out of the box, without needing an additional LoRA.</p><p>After a lot of tests and also fine tuning (plus LoRA merges) here is my newest model.</p><p>It came out a bit more realistic then I wanted, but I won't complain.</p><p><strong>What is this model great at?</strong></p><ul><li><p>Generating cosplay images</p></li><li><p>Generating anime pictures</p></li><li><p>Work accurately with character LoRA</p></li><li><p>Generating good looking people</p></li><li><p>Generating realistic animals</p></li><li><p>Generating images using booru-like tags</p></li></ul><p><strong>What is this model not too good at?</strong></p><ul><li><p>Generating pictures from complex sentences</p></li><li><p>Making fantasy/sci-fi paintings</p></li></ul><p>So this basically complements <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384\">DreamShaper</a>, and it also doesn't include Dreamlike in the mix.</p><p></p><p>I hope you'll enjoy it!</p><p></p><p>Some tips:</p><ul><li><p>Use CLIP skip 2.</p></li><li><p>Select \"auto\" as vae if you're using the baked vae version.</p></li><li><p>Use highres fix or img2img to upscale the images after you get a preview. See the examples generation data for settings suggestions, I've tested various techniques.</p></li><li><p>If you're making images where the subject is far, remember you can inpaint eyes and faces selecting \"only masked\".</p></li><li><p>Stable Diffusion is great, have fun with it!</p></li></ul><p></p>","ratingcount":191,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"DDosMix":{"status":"inactive","modelid":"civitai-12183","rating":4.96,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/71398988-0c9a-4e01-6eb7-5654d7cf6f00/width=450/132965.jpeg","description":"<p>v2: 2023-02-20 I erased the roughly made picture and put in the painstakingly made picture.</p><p>Do img2img SD upscaling.</p><p>img2img SD upscale method: scale 20-25, denoising 0.2-0.3 After selecting SD Upscale at the bottom, tile overlap 64, scale factor2</p><p>caution! Sampler must be DPM++SDE karras.</p><p></p><p>If you want to make it more realistic, use DPM++ SDE Karras. If you want a clean face, use eluer a.</p><p>Have fun using it.</p><p>I used vae kl f8 anime for the example meme, but I recommend using 840000.</p><p>clip skip 2</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt</a>\n\n<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae\">https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae</a>\n\nApply VAE.\n\nYou will get better color results.</p><pre><code></code></pre><p><br /></p><p></p><p>v1: I don't like the model with too many prompts and forcing you to use LoRa.</p><p>So it was created.</p><p></p><p>Let's extract high-quality images with 6-word prompts!</p><p></p><p>Check the sampler, scale and step in the example image.</p><p>Looking at the example image, there is a repeating prompt.</p><p></p><p>VAE: vae-ft-mse-840000-ema-pruned</p><p></p><p>Skip Clips: 2</p><p></p><p>It was a very simple test, so I think there will be many better results.</p><p>I didn't even do upscale testing.</p><p></p><p>Have fun while testing!</p><p>!There is one downside. It's fine for dark eyes, but for other eye colors, the pupils often collapse without upscaling.</p><pre><code></code></pre><p><br /></p>","ratingcount":28,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"JIM EIDOMODE":{"status":"inactive","modelid":"civitai-12720","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2ba86409-b314-481e-9e0f-723c0f14c500/width=450/122765.jpeg","description":"<p>I have created something amazing that creates very stylized images, especially digital art. The model is good at creating animals, women, men, fantastic landscapes and much more.</p><p><strong>For art</strong>, I recommend DPM++ 2M \\ 22-35 steps \\ Then upscale via a script in the Euler A sampler. <strong>Enjoy it!</strong></p><p><strong>Positive hint \\ </strong>Amazing anatomy, (fantastic horror perfect art, 64k ultra hd:1.1), (art by apterus, art by dan mumford, art by lovecraft:1.2), best quality, 500px, cgsociety</p><p><strong>Positive hint \\ </strong>(delightful anatomy:1.1), (gloomy illumination, insane, stunning, dramatic, completed artwork, HQ:1.1), (Apterus anatomy, Dan mumford style:1.2)</p><p></p><p><strong>Add to the negative hint \\ </strong>worst quality, lowres, EasyNegative, hermaphrodite, cropped, not in the frame, additional faces, jpeg large artifacts, jpeg small artifacts, ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, blurry, bad anatomy, blurred, watermark, grainy, signature, cut off, draft, not finished drawing, unfinished image, bad eyes, doll, 3d, cartoon, (bad eyes:1.2), (worst quality:1.2), (low quality:1.2), bad-image-v2-39000, (bad_prompt_version2:0.8)</p>","ratingcount":29,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Unvail AI 3DKX v2":{"status":"inactive","modelid":"civitai-12751","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e5857b9d-1d36-4acb-062d-55383395f200/width=450/123158.jpeg","description":"<h3><a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/presentation/d/1zG-pvw47ZRO9JjCkU3B2YbcYNwOHoNQ27qN6h-Xs0mM/\">Model Guide / Cheat sheet</a><br /><br /><strong><u>Changelog: </u></strong></h3><p><strong><u>V2: </u></strong> Extensive upgrade, check the guide above !</p><p><strong>V1.1: </strong>Minor update based on feedback, containing the following fixes:</p><p><strong>-</strong>“<strong>nsfw</strong>”, “<strong>nudity</strong>” , and “<strong>erotica</strong>” have been trained into the model and work as Negatives to greatly reduce unintended NSFW content.</p><p><strong>- CFG </strong>can be pushed a bit higher before the images become burnt. As a result, the model can accommodate more complicated prompts now.</p><p><strong>- </strong>Oversaturated images will be encountered less often</p><p><strong>V1.0b: </strong>Initial version.</p><p></p><h2>Description:</h2><p>SFW model with limited nsfw capabilities (suggestive nsfw) that is highly versatile for 3D renders. The model has the particularity of splitting itself into two different well balanced styles. If you'd like to have your 3D characters have a more \"Cartoony\" face, you simply start your prompt with \"3d cartoon of\", and if you want the classic 3D render style, you write \"a 3d render of\".<br /></p><p><strong>Note that this model has an embedded vae, do not use one with this model! Might produce weird results.</strong></p><p>If you want to chat with us and join our community visit our discord:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/unvailai\">https://discord.gg/unvailai</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/unvailai\">https://www.patreon.com/unvailai</a></p><h2>Dataset:</h2><ul><li><p>between 140 and 180 pictures of 3D render of all kind</p><p></p></li></ul><h3></h3><p></p><h2>Has a high success rate at:</h2><ul><li><p>sfw portraits, full body poses, close ups, etc</p></li><li><p>high versatility in terms of outputs, it isn't locked to perform well on portraits</p></li><li><p>Landscapes, cyberpunk, steampunk, natural, scifi, fantasy, animated film, etc.</p></li><li><p>2B Nier Automata (Don't ask us why)</p></li><li><p>different body types - different ethnicity</p></li><li><p>nsfw portraits, full body poses, close ups, etc</p></li></ul><h2>What it \"In theory\" shouldn't exceed at:</h2><ul><li><p>anything outside the scope of portraits, people, landscapes, game artworks, 3D sculptures, 3D fantasy, 3D film stills, etc</p></li><li><p>celebrities</p></li><li><p>highly specific animated cartoon characters</p></li><li><p>multiple subjects</p></li><li><p>highly specific video-game characters</p></li><li><p>pornography, genitalia and highly explicit materials</p><p><br /></p></li></ul>","ratingcount":34,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"The Ally's Mix III: Revolutions":{"status":"inactive","modelid":"civitai-12763","rating":4.87,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e0186f2b-861c-4912-aecd-bac4ec7ea000/width=450/142689.jpeg","description":"<p><strong>Please consider joining my Patreon</strong>! Advanced SD tutorials, explanations, exclusive embeddings, adult-art, from a female content creator (me!) <a target=\"_blank\" rel=\"ugc\" href=\"http://patreon.com/theally\">patreon.com/theally</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8bfdf2e8-f4a5-499f-3bdc-1788e151a000/width=525\" /><h2>A THIRD version?!</h2><p>Yup! But my first <strong><em>NSFW </em></strong>🔞 focused release. Sure, it does good SFW portraits, and other content, but it <em>excels </em>at the naughty stuff. It also contains the amazing <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10391/noise-offset-for-true-darkness-in-sd\">Noise Offset </a>code/process, so it produces <strong><em>EXCELLENT</em></strong><em> </em>darkness - <strong><em>true </em></strong>darkness, which hasn't really been consistently possible until now. Lots of great contrast, deep shadows, etc. It's very grim and moody.</p><p></p><h2>What's in it?</h2><p>I've taken my Ally's Mix II: Churned, cut in a dash of my favourite model, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">ReV Animated</a>, then taken the result of that + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10391/noise-offset-for-true-darkness-in-sd\">Noise Offset</a> - SD 1.5.<br /></p><h2>STOP AND READ, LoRA FANS!</h2><p>This is mixed with the OG Noise Offset model by <a target=\"_blank\" rel=\"ugc\" href=\"https://www.crosslabs.org/team\"><u>Nicholas Guttenberg at Crosslabs</u></a></p><p>You cannot - <strong>CANNOT </strong>- extract a LoRA from this model and get similar results to the model. The noise offset <strong>does not extract</strong>. You have to train the noise offset in, or cut it in with a difference merge.<br /><br /><strong>If you extract this model to LoRA, it will look like shit, and kids will point and laugh at you in the street.</strong><br /><br />I am making a LoRA from this model, the correct way, ty 💗</p><p></p><h2><strong>Recreating my sample images?!</strong></h2><p>Some of my sample images are created with <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9868/controlnet-pre-trained-difference-models\">ControlNet</a>, to get poses and compositions from my previous generations - you'll never be able to reproduce those. Others, it's possible, but some do use Patron exclusive embeddings. The sample images are meant to show what's <strong><em>possible </em></strong>with a model. I do have a<a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/theally\"> tutorial on Patreon on recreating my images</a>, the common settings I use, etc.</p>","ratingcount":84,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"PFG":{"status":"inactive","modelid":"civitai-1316","rating":4.88,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a1b244df-7189-43a8-03e5-c246db324b00/width=450/10821.jpeg","description":"<p>The origins of this are unknown</p>","ratingcount":50,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"SunshineMix＆SunlightMix":{"status":"inactive","modelid":"civitai-13510","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8f477a4a-30ba-4b33-cb4c-22223a8aaf00/width=450/169200.jpeg","description":"<h3><u>This model has been republished and its ownership transferred to Civitai with the full permissions of the model creator. They have asked that all identifying information about them be removed from the model details.</u><br /><br /><br /><strong><u>*I modified the License.(22/2/Feb)<br />That is not usual \"creativeml-openrail-m\"<br />Check Permission and Liscense below(modified Dreamlike Liscense.)</u></strong></h3><p></p><p></p><h2><strong><u>These models are good for 2.5D charas especially closeup portrait.</u></strong></h2><h2><strong><u>(Usually I dont put prompts of \"realistic\",\"photorealistic\"on these models.Try not to put those prompts on these models, if you want to get \"CUTE\" 2.5D charas.</u></strong></h2><h2><strong><u>Good combination of prompts are different among chillout, Sunshine and Sunlight.Thank you.)</u></strong></h2><h2></h2><p><u>When I made samples,<br />My eta (see setting) was \"0\".</u></p><p><u>And ESND was \"1\"</u></p><p><u>Now,I canged them to eta to \"0.67\" and ESND \"31337\"(20/Feb/2023)</u></p><p></p><p></p><p>こっちはChilloutmixより少しデフォルメされたモデルです。<br />(Sunshinemix(リアル寄り)とSunlightmix(イラスト寄り)の２つあります)</p><p><br />イラストとリアルの境界を楽しんでもらえたらなぁ、と。</p><p></p><p>ChilloutMixだとリアルすぎて合わないようなやつでも、こっちのだとわりと可愛く作れたりしますよ。</p><p></p><p>肌の質感が気に入っています。</p><p>職場や家族の前で開くのはやめておいたほうがいいよ！！</p><p></p><p></p><p><strong><u>当モデルを転売することは認めていません。</u></strong></p><p><strong><u>生成された画像の取り扱いには、自己責任の上、十分注意してください。</u></strong></p><p><strong><u>当モデルを使用したことを明記せずに生成された画像を公開することは禁止です。</u></strong></p><p><strong><u>商用利用は一切認めていません。</u></strong></p><p></p><p><strong><u>AIコミュニティの発展に悪影響を与えるような行動や個人の権利やプライバシーを侵害するような利用は禁止します。</u></strong></p><p></p><h3><strong><u>本人郑重声明：本模型原则上禁止用于训练基于明星、公众人物肖像的风格模型训练，因为这会带来争议，对AI社区的发展造成不良的负面影响。如各位一定要违反以上声明训练相关模型并公开发布，请在您的发布说明中删除与本模型有关的一切描述。感谢各位使用者的支持与理解。</u></strong></h3><p><strong><u>I solemnly declare: In principle, this model is prohibited from being used for training style models based on portraits of celebrities and public figures, because it will cause controversy and have a negative impact on the development of the AI community. If you must violate the above statement to train the relevant model and release it publicly, please delete all descriptions related to this model in your release notes. Thank you for your support and understanding.</u></strong></p><p></p><p>Maido, Ookini!!</p><p></p><p>・I merged <strong><u>chilloutmix-Ni+YuzuLemonmilk </u></strong>for<strong><u> illustration.</u></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/thiros/YuzuLemonTea#yuzulemonmilk\">thiros/YuzuLemonTea · Hugging Face</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6424/chilloutmix\">ChilloutMix | Stable Diffusion Checkpoint | Civitai</a></p><p></p><p><strong><u>I made</u></strong></p><p><strong><u>Sunshinemix</u></strong></p><p><strong><u>＆</u></strong></p><p><strong><u>Sunlightmix(more deformed, leaning on 2D)</u></strong></p><p></p><p>They are a little deformed from Chilloutmix-Ni like 2.5D</p><p></p><p><strong><u>Good for illustration and portraits (YES!!Kawaii!!)</u></strong></p><p><strong><u>Enjoy the difference ！！</u></strong></p><h3><strong><u>Check beautiful SKIN texture （←！！！！）</u></strong><br /><strong><u>Recommend prompt \"Microbikini\" Lol</u></strong></h3><p></p><p><strong><u>And yes, of course, good combinations with some LORAs!!(see works from funs!!)</u></strong></p><p></p><p></p><p>・I made some samples with additional Networks.</p><p></p><p><strong><u>・Please comment your impression and show me your works with this model!!</u></strong></p><p></p><p><strong><u>・Finger things still there.（yeah, as like samples）</u></strong></p><p></p><p>Not perfect, not enough.</p><p>But, I still keep aiming for higher beauty and possibilities with AI........</p><p>How would we reach to the sun？</p><p></p><p>Modified License（Dreamlike photoreal allowed me to modify Liscence.）</p><p>This model is licesed under a <strong>modified</strong> CreativeML OpenRAIL-M license.</p><ul><li><p><strong>You are not allowed to host, finetune, or do inference with the model or its derivatives on websites/apps/etc. If you want to, please email us at </strong><a target=\"_blank\" rel=\"ugc\" href=\"mailto:contact@dreamlike.art\"><strong><u>contact@dreamlike.art</u></strong></a></p></li><li><p><strong>You are free to host the model card and files (Without any actual inference or finetuning) on both commercial and non-commercial websites/apps/etc. Please state the full model name (Dreamlike Photoreal 2.0) and include the license as well as a link to the model card (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0\"><strong><u>https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0</u></strong></a><strong>)</strong></p></li><li><p><strong><u>Edit:We sencerely ban to use the outputs of the model or the outputs of the model's derivatives(further murged models and Loras included) for commercial purposes. Because, it would cause controversy and have a negative impact on the development of the AI community, wheter images were generated from real person or not.</u></strong></p></li><li><p>You can't use the model to deliberately produce nor share illegal or harmful outputs or content</p></li><li><p>The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license</p></li><li><p>You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the <strong>modified</strong> CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully) Please read the full license here: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\"><strong><u>https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md</u></strong></a></p></li></ul>","ratingcount":114,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Night Sky YOZORA Style Model":{"status":"inactive","modelid":"civitai-14459","rating":4.86,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c357a915-c4ff-4bb6-52fe-93cd5b38c600/width=450/165982.jpeg","description":"<h1><strong>Night Sky YOZORA Model ——“For ultimate image quality and large image size（&gt;1536 x 1024）”</strong></h1><h3><strong>Trained by <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:34898\" data-label=\"YozoRaAru\">@YozoRaAru</span></strong></h3><h2><strong><em><u>如果你需要更好的色彩表现，我推荐你试一下</u></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21200/color-box-model\"><strong><em><u>Color Box</u></em></strong></a></h2><h2><strong><em><u>If you want better colour representation There is a new style model </u></em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21200/color-box-model\"><strong><em><u>Color Box</u></em></strong></a></h2><p><strong>YOZORA</strong> is a model that pursues perfection and is <strong>filled with personal preferences</strong>. I trained it using images that I like, which give it an unparalleled level of detail and completion. It can provide you with very exquisite character images.</p><p>In addition to training, I also blended it with dozens of other high-quality models that I personally like, and I tried layer blending as well. Among these models, I selected NovelAI's original model as the major weight because it can give it excellent adaptability to a variety of prompts. I haven't tried testing it with landscape + character yet, but I believe it can also perform excellently in that aspect.</p><ul><li><p>For the <strong><em>best results</em></strong>, please ensure that your <strong><em>final resolution &gt; 1536x1024</em></strong>. This is <strong><em>necessary</em></strong> for generating exquisite illustrations</p><p></p></li></ul><p>Here are some recommended settings for the parameters:</p><ul><li><p><strong>Clip skip</strong>: It is recommended to set it at no less than 2. <strong>YOZORA</strong> already has a rich level of detail, and setting it at 1 may make the image appear cluttered and confusing.</p></li><li><p><strong>Resolution</strong>: <strong>YOZORA</strong> may <strong>not be suitable for generating small images</strong> because the extreme level of detail may become too crowded. It is recommended <strong>do not use Hires.fix</strong> to generate <strong>large images</strong>. A larger resolution is equivalent to a larger canvas, making it easier for YOZORA to capture details. It is recommended to use <strong>1536 x 1024</strong> or higher for Hires.fix.</p></li><li><p><strong>Negative prompts</strong>: It is recommended to use <strong>EasyNegative</strong> to provide brief and precise descriptions.</p></li></ul><p>The name YOZORA means <strong>\"strolling among the stars in the night sky\"</strong>. I hope that she can bring you the excitement and joy of a sky full of stars on a starry night.</p><p></p><p></p>","ratingcount":49,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Elldreth's Lucid Mix":{"status":"inactive","modelid":"civitai-1450","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/35f15f29-4410-4dcd-22fb-3cbf13af7d00/width=450/12584.jpeg","description":"<p>This mixed model is a combination of my all-time favorites AND new-found favorite, Dreamlike (thanks to JustMaier for the heads-up). A genuine simple mix of a very popular anime model and the powerful and Zeipher's fantastic f222 mixed in with Dreamlike (minus sd1.5).</p><p><strong>What's it good at?</strong></p><ul><li>Realistic portraits</li><li>Stylized characters</li><li>Landscapes</li><li>Fantasy</li><li>Sci-Fi</li><li>Anime</li><li>Horror</li></ul><p>It's an all-around easy-to-prompt general purpose semi-realistic to realistic model that cranks out some really nice images. No trigger words required. All models were scanned prior to mixing and totally safe. If you thought my 4060 mix was awesome.. this one takes the cake, seriously! Great results from simple prompts. Plenty of examples included.</p>","ratingcount":45,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Deliberate":{"status":"inactive","modelid":"civitai-15236","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0fb83c7f-7760-4870-95ec-4f7653ea4f00/width=450/150226.jpeg","description":"<h1>Deliberate</h1><h3>All in One / Any Case Version</h3><p>This model provides you the ability to create anything you want. The more power of prompt knowledges you have, the better results you'll get. It basically means that you'll never get a perfect result with just a few words. You have to fill out your prompt line extremely detailed.</p><h3>Who find this model perfect:</h3><ul><li><p>NSFW masters</p></li><li><p>Meticulous anatomy artists</p></li><li><p>Creative prompters</p></li><li><p>Art designers</p></li></ul><p>Dive into the perfect creations world with my prompts. Your research will be appreciated, so feel free to show everyone, what you can get with this model.</p><p><em>🎨 Deliberate 2 </em><strong><em>Inpainting</em></strong><em>-version you can download </em><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/XpucT/Deliberate/resolve/main/Deliberate-inpainting.safetensors\"><em>here</em></a><em>.</em></p><p></p><div data-youtube-video><iframe width=\"100%\" height=\"480\" allowfullscreen=\"true\" autoplay=\"false\" disablekbcontrols=\"false\" enableiframeapi=\"false\" endtime=\"0\" ivloadpolicy=\"0\" loop=\"false\" modestbranding=\"false\" origin playlist src=\"https://www.youtube.com/embed/QQFabEW1ltE\" start=\"0\"></iframe></div>","ratingcount":1274,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Uber Realistic Porn Merge (URPM)":{"status":"inactive","modelid":"civitai-15640","rating":4.9,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/dc03c869-cceb-4f1a-3fa1-e6850627ba00/width=450/156234.jpeg","description":"<p><strong><u>Get early access to test builds on </u></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/uber_realistic_porn_merge\"><strong><u>Patreon</u></strong></a> or join for support on <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/pcbYSSA5RS\"><strong>Discord</strong></a>! <br /><br />🏴‍☠️ <a target=\"_blank\" rel=\"ugc\" href=\"http://PirateDiffusion.com\"><strong>PirateDiffusion.com</strong></a> is a proud sponsor of URPM, <strong>now preinstalled with 80+ full NSFW models. Render from ANY smartphone or PC.</strong> <strong>Come join the amazing community of thousands of AI creators!</strong></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c9e5494d-4baf-4b62-d09f-9c5d80be8200/width=525\" /><p>🧙 <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space\"><strong>Mage.Space</strong></a> - <strong>50+ fine-tuned AI models including URPM, and Text-to-GIF are available. Render from any smartphone or PC via their website. <u>With every render of URPM on this platform, you support me directly!</u></strong></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/973ad92b-559f-4b95-4d4d-311437313a00/width=525/973ad92b-559f-4b95-4d4d-311437313a00\" /><p><strong><u>Additional Downloads: </u></strong><br /><br />When clicking the arrow to the right of the primary download, <strong>you can choose between pruned and unpruned versions</strong>. I recommend the unpruned version when merging with other models. <strong>You can also find the inpainting model as a separate version below.</strong><br /><br /><strong><u>Example Images: </u></strong><br /></p><p><u>None of the sample images were altered, upscaled, etc.</u> All can be reproduced using the metadata via the unpruned model (however the pruned model should now have the same results).<br /><br />Xformers: Off<br />ETA Seed Noise Delta: 0<br />ClipSkip: 1<br /><br /><strong><u>Prompting help:</u></strong><br /></p><p><strong>If you notice that it’s not doing what it should do</strong>, <u>be extremely light with the negative prompt</u>. Example: <em>((blurry)), animated, cartoon, duplicate, child, childish</em><br /><br />And then I re-use the same seed and add more words when needed.<br /><br />Just like any NSFW merge that <strong>contains merges with Stable Diffusion 1.5</strong>, it is important to use negatives <strong>to avoid combining people of all ages with NSFW</strong>. This is sadly unavoidable without adding negative prompts, until there is an embedding or the like that can help automate this process. <strong>Here are a few things that I generally do to avoid such imagery</strong> (and will start representing this change in future version examples):<br /><br /><strong>I <u>avoid using the term \"girl\" or \"boy\"</u></strong> in the positive prompt and <strong><u>instead opt for \"woman\" or \"man\"</u></strong>. The only exception is when I am specifying how many women should appear in a scene, which I would then use \"1girl\" or \"2girls\".<br /><br /><strong>In the negative prompt I use: <u>child, childish</u>.</strong><br /><br />This has helped me prevent any kind of accidental imagery. I know a lot of us are used to using the term \"girl\" for \"women\", but AI can't understand the difference.<br /></p><p><strong><u>Merge Recipe:</u></strong><br /><br />As an open source advocate it is important for me to help provide the \"source code\" with everything I do. You can find the merge recipes to the right of every version below.<br /><br /><strong><u>If you'd like to support my efforts and have access to early and bleeding edge builds</u></strong>, please think about joining my Patreon: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/uber_realistic_porn_merge\">https://www.patreon.com/uber_realistic_porn_merge</a></p>","ratingcount":368,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"FaeTastic":{"status":"inactive","modelid":"civitai-16553","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/194e880f-d984-469e-aed8-c6598bdc4800/width=450/551156.jpeg","description":"<h1><strong>FaeTastic</strong></h1><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/post/The-Double-Headed-Issue-E1E0JO2UV\">https://ko-fi.com/post/The-Double-Headed-Issue-E1E0JO2UV</a></p><h1><strong>PLEASE FOR THE LOVE OF GOD READ THIS TUTORIAL ABOVE IF YOU GET DOUBLE-HEADED THINGS</strong></h1><p><strong>IF YOU ARE PUZZLED WHY YOU CAN'T 1:1 AN IMAGE PLEASE SEE THIS COMMENT: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/14065/faetastic?commentId=69125&amp;modal=commentThread\"><strong>https://civitai.com/models/14065/faetastic?commentId=69125&amp;modal=commentThread</strong></a></p><p><strong>A Versatile Mixed Model with Noise Offset</strong></p><p><strong>If you have time please make sure to read everything below!</strong></p><h2><strong>Please make sure to download and use the included VAE!!! IF YOUR IMAGES ARE WASHED OUT, YOU NEED VAE! :)</strong></h2><p>This is my first model mix that was born from a failure of mine. I tried training a model on some generated images that I loved, but I did not love how it came out. Instead of tossing it I instead started to mix it into other models to produce <strong>'FaeTastic'</strong>. :)</p><p>This model was mixed up 22 times to finally get an iteration that I loved. I <em>hate</em> when models don't 'listen' to you and also when they double up and produce some wacky stuff. While I'm not going to claim that this model is perfect, I think it just does a fantastic job at what I was trying to aim for.</p><p>The model is also extremely versatile, it can do beautiful landscapes, excels at semi-realistic characters, can do anime styles if you prompt it to (you need to weight anime tags though), can do NSFW, works beautifully with embeddings and LORAs and also has the fantastic noise offset built in to produce rich dark beautiful images, if you ask it to!</p><p></p><h3><strong>Model Genetics</strong></h3><p>The base came from a 1.5-trained model I made and then mixed in the following models as well as the base mix 22 times. These are the following models that were used:</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10391/noise-offset-for-true-darkness-in-sd\">Noise Offset for True Darkness</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">ReV Animated</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">The Ally's Mix III: Revolutions</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4807/2dn\">2DN</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">Deliberate</a></p><p><strong>Fae's Sad Model that Sucked by Itself</strong></p><p>Sadly, I am not smart enough or knowledgeable enough to understand how much of each model stays into something when mixed up 22 times. Some models were mixed more than others and one model was only mixed in one time, etc. Regardless, I wanted to credit all of the models that were used. If my model doesn't tickle your fancy, then I highly recommend the above models as they are all wonderful and awesome too!</p><p></p><h3><strong>Why Aren't My Images Crisp Like Yours?</strong></h3><p><strong>PLEASE READ THE FOLLOWING GUIDE: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/post/The-Double-Headed-Issue-E1E0JO2UV\"><strong>https://ko-fi.com/post/The-Double-Headed-Issue-E1E0JO2UV</strong></a></p><p>I am just going to put this here from the beginning, as I've been asked this question before regarding the textual inversions that I have made. Plus it might come in helpful for those that are just getting into AI Art, sometimes it's hard for people to remember when they themselves were noobs! :)</p><p>So, the answer to this question is that I generate my initial images with Hires. fix on, then take an image that I like, send it to img2img, and then upscale it further there with the SD upscale script.</p><img src=\"https://i.imgur.com/3E3TQwy.png\" /><p>This is an example of what my general settings are when generating initial txt2imgs. I also sometimes use Euler A, DPM++2MKarras, DDIM. I usually only do between 20-40 Sampling steps, usually keep CFG Scale between 10-12, and the Denoising Strength I usually keep between 0.3-0.45. For the upscale, I prefer using 4x Foolhardy Remacri or 4x UltraSharp.</p><p>Just play around and find what you personally enjoy yourself! :)</p><p><strong>If you are still confused and not getting the results that you like, feel free to leave a comment on my model page or you can send me a message on discord, I am in the CivitAI discord! I'll do my best to help you! :)</strong></p><p></p><h3><strong>My Images Aren't Coming out like Yours!</strong></h3><p>This could be a lot of reasons! I use xformers, I might have different A111 settings than yours, did you check the seed, did you check your VAE, do you accidentally have Clip skip 2 on, I only use Clip skip 1. I have ETA Noise seed delta set at 31337. It could be a lot of things! Regardless if you use the prompt and have all of the embeddings or LORAs included, then the results should be similar! If you still can't figure it out, feel free to comment on this page or message me in discord and we can try to troubleshoot together! :)</p><p>PLEASE SEE THIS COMMENT I REPLIED TO SOMEONE WITH FOR FURTHER EXPLANATION: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/14065/faetastic?commentId=69125&amp;modal=commentThread\">https://civitai.com/models/14065/faetastic?commentId=69125&amp;modal=commentThread</a></p><h3><strong>Textual Inversions/Embeddings and LORAs</strong></h3><p><strong>Update 3/21/23 - I have removed all textual inversions and LORAs in my display pictures due to receiving too many questions and issues regarding them. I still highly recommend the below list for those that want to utilize them!</strong></p><p><strong>I am a huge fan of using embeddings and LORAs, they up your AI game and you should be using them! </strong>Below I am going to list all of the Textual Inversions/Embeddings, LORAs that I used for the display images. If I missed one, I deeply apologize and just post a comment and I'll update this page!</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6339/style-nebula-magic\">Nebula Magic</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7523/style-sylva-magic\">Sylva Magic</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10764/style-rust-magic\">Rust Magic</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative (THIS GOES INTO YOUR NEGATIVE PROMPT)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">Deep Negative V1.x (THIS GOES INTO YOUR NEGATIVE PROMPT)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9215/dollie-nobody\">Dollie Nobody</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/14903/bridal-style\">Bridal Style</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/bad_prompt/tree/main\">Bad Prompt (THIS GOES INTO YOUR NEGATIVE PROMPT)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist\">Bad Artist (THIS GOES INTO YOUR NEGATIVE PROMPT)</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18052\">Style PaintMagic</a> - Released now! :)</p><p>FaeMagic3 - Sorry another embedding of mine that I haven't released, but I will!</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2032/empire-style\">Empire Style</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5042/wlop-style-lora\">WLOP Style LoRA</a></p><p>I believe this is everything, but again very sorry if I missed one!</p><p></p><h3><strong>Where Do I Put Textual Inversions/LORAs/Models/VAE?</strong></h3><p>Embeddings/Textual Inversions go in Stable Diffusion Folder &gt; Stable-Diffusion-Webui &gt; Embeddings</p><p>LORAS go into Stable Diffusion Folder &gt; Stable-Diffusion-Webui&gt;Models&gt;Lora</p><p>Models go into Stable Diffusion Folder &gt; Stable-Diffusion-Webui&gt;Models&gt;Stable-diffusion</p><p>VAE go into Stable Diffusion Folder &gt; Stable-Diffusion-Webui&gt;Models&gt;VAE (AND THEN YOU TURN VAE ON IN YOUR SETTINGS IN THE A1111 WEBUI)</p><p>These instructions are for use of the A1111 WebUI ONLY. I do not use other things and I am not knowledgeable about them, sorry!</p><p></p><p>I believe this is everything I can think of. Please leave any comments or contact me on discord for anything not here, thank you, and enjoy making beautiful things! :)</p><p></p>","ratingcount":43,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"BlueberryMix":{"status":"inactive","modelid":"civitai-16859","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/322d93cf-621e-46f0-430f-2289c1392c00/width=450/174739.jpeg","description":"<p>A simple photorealistic merge.</p><p></p><p><strong>Positive Prompts</strong>: best quality, masterpiece, ultra high res, (photorealistic:1.4), 1girl, looking at viewer</p><p><strong>Negative Prompts</strong>: (low quality, worst quality:1.4)</p><p><strong>Recommended Settings</strong>: DPM++ 2M Karras, 20 Steps, CFG Scale 7</p><p><strong>VAE is baked in by default</strong>, I'm using <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.safetensors\">vae-ft-mse-840000-ema-pruned</a><br /><br /><strong>ChilloutMix isn't part of the mix.</strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0\">Dreamlike Photoreal 2.0</a> is included and the same license will apply.</p><p></p><h3>License</h3><p>This model is licensed under a <strong>modified</strong> CreativeML OpenRAIL-M license.</p><ul><li><p>You are not allowed to host, finetune, or do inference with the model or its derivatives on websites/apps/etc. If you want to, please email us at <a target=\"_blank\" rel=\"ugc\" href=\"mailto:contact@dreamlike.art\"><u>contact@dreamlike.art</u></a></p></li><li><p>You are free to host the model card and files (Without any actual inference or finetuning) on both commercial and non-commercial websites/apps/etc. Please state the full model name (Dreamlike Photoreal 2.0) and include the license as well as a link to the model card (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0\"><u>https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0</u></a>)</p></li><li><p>You are free to use the outputs (images) of the model for commercial purposes in teams of 10 or less</p></li><li><p>You can't use the model to deliberately produce nor share illegal or harmful outputs or content</p></li><li><p>The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license</p></li><li><p>You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the <strong>modified</strong> CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully) <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">Please read the full license here</a></p></li></ul>","ratingcount":36,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"KoreanStyle2.5D":{"status":"inactive","modelid":"civitai-17084","rating":4.89,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/94f69206-b1ee-45fd-7881-75837bdd3000/width=450/255733.jpeg","description":"<h2>Updated 2023/3/15</h2><p>新加入了3张韩风预览图，试了一下宽画幅，好像效果也OK，主要是想提醒大家这是一个韩风模型，然后告诉大家韩风模型需要用的Lora！最后提醒大家一定要用hires-fix对图片进行高清修复。</p><p>Newly added 3 Korean style preview images, tried a wide format, seems not bad. want to remind everyone that this is a Korean style model, and you can use some Korean style Lora to improve the quality of generated images. At last,<strong> do not forget to use hires-fix </strong>on the picture HD repair.</p><p>........................................................................................................................................................</p><p></p><h3><strong>一款韩风的2.5D模型，能够在尽量保证画风足够真实、好看的同时又保留有足够的创造力。</strong></h3><h2><strong>English introduction is below.</strong></h2><p></p><p><strong>推荐与以下几款Lora搭配使用： fashion_girls,ulzzang-6500-v1.1,chilloutmixss20, korean_doll_likeness, 权重大概在0.2到0.3就可以形成比较好看的韩风脸。也可以与各种概念类的lora搭配，如Pillory 枷具、millking machine等，经测试效果都比较好。</strong></p><p><strong><u>还有一点比较重要的是，本模型非常推荐使用hires高清修复，能够极大提升细节质量，没有副作用，并解决有时候脸部崩坏的问题。</u></strong></p><p>················································································································································································································································································································</p><p>下面我给一个生成样例展示一下如何同时结合韩风脸外加从那些概念生成的lora，这里以Pillory 枷具为例：</p><p>该Lora可以在这里下载：</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15132/conceptpillory-jiaju\">https://civitai.com/models/15132/conceptpillory-jiaju</a></p><p>(masterpiece),(best quality),extreamly delicate and beautiful,illustration,straight-on,nude, 1girl,1boy, pillory, bound wrists, bondage, bound,,very long hair, (forehead:0.98), breasts, cleavage, navel,thighs, saliva,chains, ass,hetero, condom, full-face blush, embarrassed, sweat,city,street,surrounded, multiple others, exhibitionism, audience, background characters, crowd, public humiliation pov , &lt;lora:ConceptPilloryJiaju_v10:0.51&gt;, ulzzang-6500-v1.1 &lt;lora:chilloutmixss20_v20:0.3&gt; &lt;lora:koreanDollLikeness_v15:0.2&gt;</p><p>Negative prompt: EasyNegative,worst quality,low quality</p><p>Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 4030484714, Size: 512x512, Model hash: 0e9c1bdca1, Denoising strength: 0.41, Clip skip: 2, ENSD: 31337, Hires upscale: 2, Hires upscaler: Latent</p><p></p><p>这个样例中既生成了比较好看的韩风脸，又也同样用好了通常只能在类似AbyssOrange那种动漫风的模型中才能用到的概念：枷具。这个也就是我创作这个模型的初衷：<strong><em>既保留好看的韩风脸，也不会丢失创造力。</em></strong>当然，预览图应该过不了审，我就不放出来了，大家自己尝试就好。</p><p>················································································································································································································································································································</p><p>先说一下为什么要创造这款模型，众所周知,chilloutMix模型是现在很流行的真人类模型，但是它非常依赖于lora,没有lora人物出来就很不好看，除此以外，由于训练集过于稀少，所以其实很多tag对它都没有用，很多衣服、挂件、姿势都摆不出来。所以我就思考，也许能够把它和一些二次元模型融合，然后让它学到二次元画中的姿势、衣服等等。所以就创造出了这款模型，画风大概是介于2、3D之间的。</p><p>与chilloutMix相比，这个模型的优点在于它不依赖于lora就可以出比较好看的图，然后2.5D画风也让人不容易恐怖谷。（当然我建议还是搭配一些好看的lora效果更好）更重要的是，它可以自由的搭配几乎所有的tag，它从二次元模型中学到了tag的含义，这样你就可以自由的搭配各种衣服、姿势、玩具等，这些chilloutmix很难做到。</p><p>跟动漫风格的模型相比，就是模型更加韩风、更加好看了。</p><p>················································································································································································································································································································</p><h3></h3><h3>A Korean-style 2.5D model can ensure that the style is realistic and beautiful while retaining enough creativity.</h3><p></p><p><strong>It is recommended to use with the following Lora: fashion_girls, ulzzang-6500-v1.1, chilloutmixss20, korean_doll_likeness, the weight is about 0.2 to 0.3 to generate a pretty Korean style face. It can also be used with various conceptual lora, such as Pillory , millking machine, etc. and the test results performed well.</strong></p><p></p><p><strong><u>The model is highly recommended to use hires-fix, which can greatly improve the quality of details, has no side effects, and solves the problem of sometimes face or eyes collapse.</u></strong></p><p>················································································································································································································································································································</p><p></p><p>Next, I will give a generation example to show how to combine the Korean style face and the concepts lora generated from AbyssOrange Here we take the <strong>Pillory </strong>as an example, the Lora could be downloaded at here:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15132/conceptpillory-jiaju\">https://civitai.com/models/15132/conceptpillory-jiaju</a></p><p>(masterpiece),(best quality),extreamly delicate and beautiful,illustration,straight-on,nude, 1girl,1boy, pillory, bound wrists, bondage, bound,,very long hair, (forehead:0.98), breasts, cleavage, navel,thighs, saliva,chains, ass,hetero, condom, full-face blush, embarrassed, sweat,city,street,surrounded, multiple others, exhibitionism, audience, background characters, crowd, public humiliation pov , &lt;lora:ConceptPilloryJiaju_v10:0.51&gt;, ulzzang-6500-v1.1 &lt;lora:chilloutmixss20_v20:0.3&gt; &lt;lora:koreanDollLikeness_v15:0.2&gt;</p><p>Negative prompt: EasyNegative,worst quality,low quality</p><p>Steps: 20, Sampler: Euler a, CFG scale: 7, Seed: 4030484714, Size: 512x512, Model hash: 0e9c1bdca1, Denoising strength: 0.41, Clip skip: 2, ENSD: 31337, Hires upscale: 2, Hires upscaler: Latent</p><p>In this example, not only a good-looking Korean face is generated, but also a concept that usually can only be used in anime-style models like AbyssOrange is also used: <strong>Pillory </strong>This is the original intention of my creation of this model: <strong><em>to retain the pretty Korean style face without losing creativity. </em></strong>However, the preview image should not pass the review, so I won't release it. You can try it ourself.</p><p></p><p>················································································································································································································································································································</p><p>Let me first talk about why this model was created. As is known to all, the ChilloutMix model is a popular realistic model, but it is dependent on lora, and does not perform well without lora characters. In addition, due to the scarce of the training dataset, many tags are useless in CHilloutmix, many clothes, pendants, and poses cannot be displayed. So I thought, maybe it can be merged with some anime-style models to learn the tags of poses, clothes, etc. So this model was created, the painting style is between 2D and 3D.</p><p>Compared with chilloutMix, the advantage of this model is that it can produce better-looking pictures without relying on lora, and the 2.5D painting style is not easy to make the uncanny valley. (Of course, I suggest to use it with some beautiful loras) More importantly, it can match almost all tags freely, and it has learned the meaning of tags from other style, so that you can freely match various clothes, poses, toys, etc while chilloutmixe is hard to do.</p><p>Compared with the anime-style model, the model is more Korean-style and beautiful.</p>","ratingcount":71,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AbyssOrangeMix3 (AOM3)":{"status":"inactive","modelid":"civitai-17233","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8e43c79f-1a34-46a5-0708-c031a8ede200/width=450/175095.jpeg","description":"<p>▼Some tips</p><ul><li><p>Discussion:</p><p>I warmly welcome you to share your creations made using this model in the discussion section. If you encounter any issues, please feel free to add a comment, and both the community and I will do our best to help and provide solutions.</p><p>您也可以使用中文在讨论区与我交流。</p><p>吾生也有涯，而知也无涯。👩‍🍳</p></li><li><p>VAE:</p><p>Given the color variation that different VAEs bring to this model, I have not baked a specific VAE onto the model. The VAE used in the sample image is kl-f8, and I appreciate its color saturation.However, perhaps you prefer orangemix.vae (NAI.vae) or others? Please feel free to try them out.</p></li><li><p>Sample image:</p><p>I am terribly sorry! It seems that I triggered a bug related to the \"DPM++ SDE Karras\" sampler and batch generation while creating the sample image, which resulted in the inability to reproduce the sample image through the seed. However, you should be able to obtain a similar image to mine by using the same settings. Once again, I apologize for any inconvenience caused.</p></li><li><p>Wrong limb:</p><p>Was it a necessary compromise for the sake of the model's diversity and creativity? In any case, please try to generate images in batches and select the high-quality works from them. Perhaps I will release an inpainting model later on?</p></li></ul><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e8116f15-5d60-4462-bbdc-849481ed6000/width=525\" /><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix3-aom3\">AbyssOrangeMix3 (AOM3) HuggingFace Model Card</a><br />Credit for this model goes to the original author(s) and the maintainer on HuggingFace, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777\">WarriorMama777</a>. Consider checking out their repository on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">Huggingface </a>and giving it a like! Also, check out their profile on <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/WarriorMama777\">Civitai</a>!</p><p></p><p>▼About</p><p>The main model, \"AOM3 (AbyssOrangeMix3)\", is a purely upgraded model that improves on the problems of the previous version, \"AOM2\". \"AOM3\" can generate illustrations with very realistic textures and can generate a wide variety of content. There are also three variant models based on the AOM3 that have been adjusted to a unique illustration style. These models will help you to express your ideas more clearly.</p><p> </p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/541d680e-0d8f-4994-0f4d-5128dc36be00/width=525\" /><h3>AOM3</h3><p>Features: high-quality, realistic textured illustrations can be generated.<br />There are two major changes from AOM2.</p><p>1: Models for NSFW such as <em>nsfw and </em>hard have been improved: the models after nsfw in AOM2 generated creepy realistic faces, muscles and ribs when using Hires.fix, even though they were animated characters. These have all been improved in AOM3.</p><p>2: sfw/nsfw merged into one model. Originally, nsfw models were separated because adding NSFW content (models like NAI and gape) would change the face and cause the aforementioned problems. Now that those have been improved, the models can be packed into one.<br />In addition, thanks to excellent extensions such as <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/arenatemp/stable-diffusion-webui-model-toolkit\"><strong><u>ModelToolkit</u></strong></a>, the model file size could be reduced (1.98 GB per model).</p><p></p><p>▼Variations</p><h3>AOM3A1</h3><p>Features: Anime like illustrations with flat paint. Cute enough as it is, but I really like to apply LoRA of anime characters to this model to generate high quality anime illustrations like a frame from a theatre version.</p><h3>AOM3A2</h3><p>Features: Oil paintings like style artistic illustrations and stylish background depictions. In fact, this is mostly due to the work of Counterfeit 2.5, but the textures are more realistic thanks to the U-Net Blocks Weight Merge.</p><h3>AOM3A3</h3><p>Features: Midpoint of artistic and kawaii. the model has been tuned to combine realistic textures, a artistic style that also feels like an oil colour style, and a cute anime-style face. Can be used to create a wide range of illustrations.</p><h3><strong>AOM3A1B</strong></h3><p>AOM3A1B added. The model was merged by mistakenly selecting 'Add sum' when 'Add differences' should have been selected in the AOM3A3 recipe. It was an unintended merge, but we share it because the illustrations produced are consistently good results.<br />In my review, this is an illustration style somewhere between AOM3A1 and A3.</p><h3>MORE</h3><p>In addition, these U-Net Blocks Weight Merge models take numerous steps but are carefully merged to ensure that mutual content is not overwritten.</p><p> </p><p>(Of course, all models allow full control over adult content.)</p><ul><li><p>🔐 When generating illustrations for the general public: write \"nsfw\" in the negative prompt field</p></li><li><p>🔞 It can be generated without putting it in. If you include it, the atmosphere will be more NSFW.</p></li></ul><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a506296d-1573-4cad-e3e9-83edf4477c00/width=525\" /><h3><strong>Description for enthusiast</strong></h3><p>AOM3 was created with a focus on improving the nsfw version of AOM2, as mentioned above.The AOM3 is a merge of the following two models into AOM2sfw using U-Net Blocks Weight Merge, while extracting only the NSFW content part.<br />(1) NAI: trained in Danbooru<br />(2)gape: Finetune model of NAI trained on Danbooru's very hardcore NSFW content.<br />In other words, if you are looking for something like AOM3sfw, it is AOM2sfw.The AOM3 was merged with the NSFW model while removing only the layers that have a negative impact on the face and body. However, the faces and compositions are not an exact match to AOM2sfw.AOM2sfw is sometimes superior when generating SFW content. I recommend choosing according to the intended use of the illustration.See below for a comparison between AOM2sfw and AOM3.</p><p></p><p>▼How to use</p><ul><li><p>Prompts</p><ul><li><p>Negative prompts is As simple as possible is good.<br />(worst quality, low quality:1.4)</p></li><li><p>Using \"3D\" as a negative will result in a rough sketch style at the \"sketch\" level. Use with caution as it is a very strong prompt.</p></li><li><p>How to avoid Real Face<br />(realistic, lip, nose, tooth, rouge, lipstick, eyeshadow:1.0), (abs, muscular, rib:1.0),</p></li><li><p>How to avoid Bokeh<br />(depth of field, bokeh, blurry:1.4)</p></li><li><p>🔰Basic negative prompts sample for Anime girl ↓</p><ul><li><p>v1<br /><code>nsfw, (worst quality, low quality:1.4), (realistic, lip, nose, tooth, rouge, lipstick, eyeshadow:1.0), (dusty sunbeams:1.0),, (abs, muscular, rib:1.0), (depth of field, bokeh, blurry:1.4),(motion lines, motion blur:1.4), (greyscale, monochrome:1.0), text, title, logo, signature</code></p></li><li><p>v2<br /><code>nsfw, (worst quality, low quality:1.4), (lip, nose, tooth, rouge, lipstick, eyeshadow:1.4), ( jpeg artifacts:1.4), (depth of field, bokeh, blurry, film grain, chromatic aberration, lens flare:1.0), (1boy, abs, muscular, rib:1.0), greyscale, monochrome, dusty sunbeams, trembling, motion lines, motion blur, emphasis lines, text, title, logo, signature,</code></p></li></ul></li></ul></li><li><p>Sampler: Take your pick</p></li><li><p>Steps:</p><ul><li><p>DPM++ SDE Karras: Test: 12～ ,illustration: 20～</p></li><li><p>DPM++ 2M Karras: Test: 20～ ,illustration: 28～</p></li></ul></li><li><p>Clipskip: 1 or 2</p></li><li><p>Upscaler :</p><ul><li><p>Detailed illust → Latenet (nearest-exact)<br />Denoise strength: 0.5 (0.5~0.6)</p></li><li><p>Simple upscale: Swin IR, ESRGAN, Remacri etc…<br />Denoise strength: Can be set low. (0.35~0.6)</p></li></ul></li></ul><p></p><p>👩‍🍳Model details / Recipe</p><p>▼Hash</p><ul><li><p>AOM3.safetensors<br />D124FC18F0232D7F0A2A70358CDB1288AF9E1EE8596200F50F0936BE59514F6D</p></li><li><p>AOM3A1.safetensors<br />F303D108122DDD43A34C160BD46DBB08CB0E088E979ACDA0BF168A7A1F5820E0</p></li><li><p>AOM3A2.safetensors<br />553398964F9277A104DA840A930794AC5634FC442E6791E5D7E72B82B3BB88C3</p></li><li><p>AOM3A3.safetensors<br />EB4099BA9CD5E69AB526FCA22A2E967F286F8512D9509B735C892FA6468767CF</p></li></ul><p>▼Use Models</p><ol><li><p>AOM2sfw<br />「038ba203d8ba3c8af24f14e01fbb870c85bbb8d4b6d9520804828f4193d12ce9」</p></li><li><p>AnythingV3.0 huggingface pruned<br />[2700c435]「543bcbc21294831c6245cd74c8a7707761e28812c690f946cb81fef930d54b5e」</p></li><li><p>NovelAI animefull-final-pruned<br />[925997e9]「89d59c3dde4c56c6d5c41da34cc55ce479d93b4007046980934b14db71bdb2a8」</p></li><li><p>NovelAI sfw<br />[1d4a34af]「22fa233c2dfd7748d534be603345cb9abf994a23244dfdfc1013f4f90322feca」</p></li><li><p>Gape60<br />[25396b85]「893cca5903ccd0519876f58f4bc188dd8fcc5beb8a69c1a3f1a5fe314bb573f5」</p></li><li><p>BasilMix<br />「bbf07e3a1c3482c138d096f7dcdb4581a2aa573b74a68ba0906c7b657942f1c2」</p></li><li><p>chilloutmix_fp16.safetensors<br />「4b3bf0860b7f372481d0b6ac306fed43b0635caf8aa788e28b32377675ce7630」</p></li><li><p>Counterfeit-V2.5_fp16.safetensors<br />「71e703a0fca0e284dd9868bca3ce63c64084db1f0d68835f0a31e1f4e5b7cca6」</p></li><li><p>kenshi_01_fp16.safetensors<br />「3b3982f3aaeaa8af3639a19001067905e146179b6cddf2e3b34a474a0acae7fa」<br /></p></li></ol>","ratingcount":451,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"RealEldenApocalypse_AnalogSexKnoll_4CandyPureSimp+FEET":{"status":"inactive","modelid":"civitai-1798","rating":4.43,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8b4ab898-eab8-48cf-1fde-a636453b8e00/width=450/15895.jpeg","description":"<p>PLEASE READ DESCRIPTION</p><p><strong>*update*: I do love REA, but I consider it to be an outdated version of this new baby</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3950/art-and-eros-aeros-a-tribute-to-beauty\">https://civitai.com/models/3950/art-and-eros-aeros-a-tribute-to-beauty</a></p><p>As such, it will have no new development. I will keep it here should anybody have a need for it.</p><p></p><p>Patreon at the beginning, yay!: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/user?u=84473395\">https://www.patreon.com/user?u=84473395</a></p><p>Check any info or questions at our private Discord here: <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/z88HpDwbGq\">https://discord.gg/z88HpDwbGq</a></p><p><strong>it needs vae-ft-mse-840000-ema-pruned (or another one if you want to get experimental) or it will output broken images.</strong></p><p>Hello everybody!! I proudly present you my merged NSFW model I have been working for weeks to try and get the most emergent properties within the models contained. SD 1.5 is the base most of the models contained used, with exceptions. The name is a meme and it references all that is inside of it.</p><p>So let me thank everybody who made it possible, because I if there's anything good on it is because the source material was great too. So my thanks in no particular order to <em>Hassan</em>, <em>AloeVera</em>, the <em>CivitAI Team</em>, <em>Izuek</em>, <em>Someone88</em>, <em>wavymulder</em>, <em>UnstableDiffusion Team</em> and any other creator I might not have been able to cite.</p><p><u>ABOUT:</u></p><p>First it may not be the best begginer checkpoint out there. I consider myself experienced at prompting so I haven't tried much basic prompts, however I doubt that a plain \"pretty naked woman, big boobs\" is going to take you very far with it. However, although I prompt a bit different than that I have tested that <strong>it understands the words from the language of PhotoReal v0.5</strong> (it is contained within the merge), so if you are having troubles getting good outputs from it you can begin from there, but in general, try to use a more natural language than an array of commas: https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</p><p>There's also one screenshot with a very basic example prompt for you to get the idea.</p><p>According to my testing it is a very powerful model for it's porpouse, but it is a project I made for myself which means that depending on what you want it may or may not lack certain areas. It has been intensively tested to <strong>generate photorealistic(ish) images of different types of girls in different poses in different places wearing different things with different artistic moods</strong>. Nothing more, nothing less. From hardcore, to to group, to drawing, are out of the scope uses that may or may not work.</p><p><u>HOW TO USE IT:</u></p><ul><li><p>You <strong>MUST USE vae-ft-mse-840000-ema-pruned</strong> (or experimentally other VAEs). Otherwise it breaks.</p></li><li><p>Some users report having problems using something different than Automatic1111webui. Cannot troubleshoot that myself.</p></li><li><p>This model <strong>DOES <u>NOT</u> REQUIRE TO USE TRIGGER WORDS</strong>.</p></li><li><p>Works for a wide variety of steps from 20 to 130 tested. I use 128.</p></li><li><p>It works on it's own at making general or NSFW images of ladies of high quality.</p></li><li><p>Resolutions tested are <em>512x512, 384x704, 512x768</em> and <em>768x768</em> (the latest is a bit more buggy but decent enough)</p></li><li><p>Trigger words are general <strong>style modifiers</strong>. They can be used alone or in combination and will give an special mood to the composition.</p></li><li><p>Trigger words have only been tested using them <strong>at the beggining</strong> of the prompt.</p></li><li><p>If used together in any subset combination they work better if they appear in this relative order: \"<em>elden ring style postapocalypse knollingcase analog style b</em>f\" or \"<em>postapocalypse elden ring style knollingcase analog style bf</em>\".</p></li></ul><p><u>MERGED:</u></p><p>I haven't kept track of all the steps done in the merge (I used a weird methodology), but this is what's inside in different proportions:</p><ul><li><p>PhotoReal v0.5: https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</p></li><li><p>Elden Ring Style: https://civitai.com/models/5/elden-ring-style</p></li><li><p>Postapocalypse: https://civitai.com/models/1136/postapocalypse</p></li><li><p>Analog Diffusion: https://civitai.com/models/1265/analog-diffusion</p></li><li><p>SXD: https://civitai.com/models/1169/sxd</p></li><li><p>Knollingcase: https://civitai.com/models/1092/knollingcase</p></li><li><p>Hassan's 1.4 and CandyBerry: https://civitai.com/models/1173/hassanblend-all-versions</p></li><li><p>PurePornPlus: https://civitai.com/models/1235/purepornplus-merge</p></li><li><p>SimpMaker 3K1: https://civitai.com/models/1258/aloeveras-simpmaker-3k-series</p></li><li><p>One ancient feet model that can be grabbed from some repositories (the only one I know of is too dubious to link it).</p></li><li><p>It also works GREAT as an extra style modifier with this hypernetwork for extra artistic outputs: https://civitai.com/models/1141/mjv4-hypernetwork</p></li></ul><p><u>TROUBLESHOOT:</u></p><ul><li><p>Images are a chaotic trip of LSD colors:</p></li></ul><p>You are not using the VAE.</p><ul><li><p>Images seem like real images but are a mess of body horror and whatnot:</p></li></ul><p>You need to keep working in your prompt. This is <u>NOT</u> an easy to use model (not rocket science either).</p><ul><li><p>Model gives error when trying to launch.</p></li></ul><p>I have totally no idea of what can be the problem, I am not a software developer, just a somewhat experienced user. However @Technerd has shared with us this info for an specific problem:</p><p>Technerd - \"Python Error: Key Error: 'state_dict' pops up no images generated. Cannot get it to work with NMKD 1.8 GUI\".</p><p>Technerd - \"Just to let you know I've downloaded your new \"safetensors\" version and converted it via NMKD GUI to a \"ckpt\" file and now it works\".</p><p><u>FUTURE:</u></p><p>This project is considered finished. From now on it is going to become my base model. I may start to train it as the big kids do. I may create a new merge in a future using it too. The sky is the limit, wanna be updated?</p><p>https://linktr.ee/ainecaptain</p><p>And if you wish to support me and get exclusive content such as evolutions of the model before they are released, lot's of NSFW pics made with it and what not...</p><p>https://www.patreon.com/user?u=84473395</p>","ratingcount":30,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Nyan Mix":{"status":"inactive","modelid":"civitai-18151","rating":4.84,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6e0cf8dd-efde-4325-a365-1d20b0ef5e00/width=450/186595.jpeg","description":"<p><strong><em>TLDR of everything below: \"Use absurd2 version if you use HiresFix. Use normal version if you don't use HiresFix. When absurd2 is unstable, use withContrastFix version. When it's too black, use normal version. Use included VAE (nai). Consider using CFG Fix extension, most example images used it.\"</em></strong><br /></p><ul><li><p>If you happened to try out this mix, please leave a review, because I'm curious about how it performs with other people prompting styles!</p></li><li><p>There's currently no version that is better or worse than the rest, different versions are just different style-wise, or have a different \"detailed but possibly messy : stable but possibly boring\" kind of balance, to which every mix approaches differently. Check out example images of different versions of the mix! (those are not cherry-picked and are directly comparable between versions)</p></li><li><p>Also the \"How\" section explains some differences between the versions.</p></li></ul><p></p><h1>Why.</h1><p>Out of curiosity I've made a model out of the models I've been using, just for personal use, but the result is so good that I decided it was worth to share the nice stuff with more people!</p><p>I really liked the rich crispy details of YOZORA, the crazy semi-realistic capabilities of Xtracolor, the artstyle of AOM, the creativity in details of Counterfeit and the faces from MeinaMix and Korean 2.5D. Also added the uiouiouio's models because I liked the results overall and those were close to what I was trying to achieve.</p><p>So, Nyan Mix ended up being able to produce very colorful images with high contrast and rich effects in semi-realistic styles, but at the cost of making environments too abstract (unless you're using CFG Fix!), and being very dark on average by default (when using \"withContrastFix\" versions).</p><p></p><h1>What.</h1><p>The recipes are described in the versions' changelogs.</p><ul><li><p>From my initial testing, it's best to use \"normal\" or \"withContrastFix\" version as a general-purpose model and \"absurd2\" for dynamic scenes with darker backgrounds.</p></li><li><p>The \"absurd\" version is much more detailed compared to \"normal\", while \"intense\" version is somewhere in between. Doesn't seem to be as unstable as I expected when used with certain parameters (namely <strong>Highres Fix</strong>), but amplifying it even further breaks it, as well as using it with some other parameters. Might become unstable enough when used with LORAs, but I haven't tested that.</p></li><li><p>The \"absurd2\" version is very dark compared to \"normal\", but the contrast is great. The \"withContrastFix\" versions are somewhere in between.</p></li><li><p><em>You can switch around the version tabs a little bit lower here on the page - the example images are made so that you could directly compare the different models' features.</em></p></li></ul><p><em>Note: 230301 version is more 2.5D-ish, while 230303 versions are more 2D-ish by design.</em></p><p>Comparison between versions (will be updated with more examples soon): <a target=\"_blank\" rel=\"ugc\" href=\"https://imgur.com/a/JvSQqUV\">https://imgur.com/a/JvSQqUV</a></p><p></p><h1>How to use.</h1><p>Maybe it's not the best configuration (I'll be happy if you'll discover a better way), but that's what I used to generate most of the example images:</p><p><strong>Sampler</strong>: DPM++ SDE Karras</p><p><strong>Highres fix</strong>: Enabled</p><p><strong>Upscaler</strong>: Latent (nearest)</p><p><strong>Upscale by</strong>: 2</p><p><strong>Sampling steps</strong>: 20-50</p><p><strong>Highres steps</strong>: 15-25</p><p>(generally 20+15 steps is already good enough)</p><p><strong>Denoising strength</strong>: 0.6</p><p><strong>CFG Scale</strong>: 7</p><p><strong>Clip skip</strong>: 2</p><p><strong>Resolution</strong>: basically everything works well - both portrait and landscape aspect ratio capabilities are good, both low-res bases (200x400) and high-res bases (896x1344) are also good.</p><p><strong>VAE</strong>: Included with the \"absurd2\" version, it's the same file that Counterfeit/OrangeMix/RefSlave/etc use. Other VAEs might degrade eyes and introduce severe unintended \"chromatic aberration\" effect.</p><p></p><h3>Consider this!!!:</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/mcmonkeyprojects/sd-dynamic-thresholding.git\">https://github.com/mcmonkeyprojects/sd-dynamic-thresholding.git</a></p><p><strong>CFG Scale</strong>: 15</p><p><strong>CFG Fix</strong>: Enabled</p><p><strong>Mimic CFG Scale</strong>: 7</p><p><strong>Top percentile</strong>: 95%</p><p><strong>Mimic Scale Scheduler</strong>: Half Cosine Up</p><p><strong>CFG Scale Scheduler</strong>: Half Cosine Up</p><p><strong>Minimum value of CFG Scheduler</strong>: 3.5</p><p><strong>Power Scheduler Value</strong>: 4</p><p>(Most of the example images were made using this)</p><p></p><h3>Alternatively:</h3><p><strong>Sampler</strong>: DPM++ 2S a Karras</p><p><strong>Highres fix</strong>: Disabled</p><p><strong>Resolution</strong>: preferably no less than 800*1200</p><p><strong>CFG Scale</strong>: 7</p><p><strong>Sampling steps</strong>: 10-30</p><p></p><h3>Alternatively:</h3><p><strong>Sampler</strong>: DPM++ SDE Karras</p><p><strong>Highres fix</strong>: Disabled</p><p><strong>Resolution</strong>: preferably no less than 600*900</p><p><strong>CFG Scale</strong>: 8.5 or lower depending on resolution</p><p><strong>Sampling steps</strong>: 15-35</p><p></p><h1>Plans.</h1><p>Will try to reach for better stability and even better backgrounds.<br />The next version will be more 2.5D-ish.<br />Will try injecting different styles to see if something will look like it belongs here.</p>","ratingcount":45,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"DucHaitenAIart":{"status":"inactive","modelid":"civitai-50724","rating":4.86,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5de94c2c-c998-437d-4cd0-f3e966e00200/width=450/564962.jpeg","description":"<p>Big update of DucHaitenAIart, v4 is able to receive more diverse, more detailed prompts with gorgeous colors and more realistic shadows. The image has the breath of 3D anime, but the material is much more realistic.</p><p></p><p>For those of you who don't have a pc or a weak computer, you can consider using my model via sinkin and mage website using the link below:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/NRz9J7R\">https://sinkin.ai/m/NRz9J7R</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space\">https://www.mage.space</a></p><p></p><p><strong><u>please support me by becoming a patron:</u></strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"http://patreon.com/duchaitenreal\"><u>patreon.com/duchaitenreal</u></a></p><p><strong><em>*****</em></strong></p><p>All sample images only use text to image, no editing, no image to image, no restore face no highres fix no extras.</p><p></p><p>DPM++ 2S a Karras cfg 11</p><p></p><p>negative prompt:</p><p>illustration, painting, cartoons, sketch, (worst quality:2), (low quality:2), (normal quality:2), lowres, bad anatomy, bad hands, ((monochrome)), ((grayscale)), collapsed eyeshadow, multiple eyeblows, vaginas in breasts, (cropped), oversaturated, extra limb, missing limbs, deformed hands, long neck, long body, imperfect, (bad hands), signature, watermark, username, artist name, conjoined fingers, deformed fingers, ugly eyes, imperfect eyes, skewed eyes, unnatural face, unnatural body, error</p>","ratingcount":44,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Lucky Strike Mix":{"status":"inactive","modelid":"civitai-19159","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/53a4e583-3bfc-4e42-2fbb-c20e82498400/width=450/200643.jpeg","description":"<p>2023/3/30</p><p>hello everyone, I updated a few lora models that you all want,</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/26491/lorak-aigirl-face\">https://civitai.com/models/26491/lorak-aigirl-face</a></p><p></p><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3b2ff1bb-1f69-4f88-4dc5-bd9e7e013900/width=525/3b2ff1bb-1f69-4f88-4dc5-bd9e7e013900\" /><p>与一般的真实系模型相比，Lucky Strike Mix提供了非常纤细的少女体型，并且通过Clip剪切，身体比例也是接近1:9（9头身），而非1：8</p><p>Compared with the general real model, Lucky Strike Mix provides a very slender girlish figure, and through Clip cutting, the body ratio is close to 1:9 (9 head body) instead of 1:8</p><p></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5c30f405-9520-43ef-5d96-9a944cbc9500/width=525/5c30f405-9520-43ef-5d96-9a944cbc9500\" /><p>0.2版本改善了手部的表现</p><p>具体方法是通过脚本将所有ATTN1块信息更换为AOM2-NSFW的，</p><p>然后将处理后的模型与v0.1流程中的模型混合，</p><p>但是这个过程中出现了画面劣化的问题，所以我只混入了约50%的手部修正。</p><p>“Lucky Strike”的特色传统依然被保留（笑）。</p><p>Version 0.2 improves hand performance</p><p>The specific method is to replace all ATTN1 block information with AOM2-NSFW through the script,</p><p>The processed model is then blended with the model from the v0.1 pipeline,</p><p>But there was a problem of image degradation in the process, so I only mixed in about 50% of the hand correction.</p><p>The characteristic tradition of \"Lucky Strike\" is still preserved (laughs).</p><p></p><p>..............................................................................................</p><p>这个模型的初衷是画出纤细修长的大腿。</p><p>The original intention of this model is to draw slender and slender thighs，</p><p>这个出发点是基本能满足，但是副作用是完全不会画手了。</p><p>This starting point is basically satisfactory, but the side effect is that I can't draw hands at all.</p><p>Lucky Strike Mix这个名字也是因此而来，如果次数足够多，总会有完美的图片出现。</p><p>The name Lucky Strike Mix is ​​also derived from this, if there are enough times, there will always be a perfect picture。</p><p></p><p>The following is the composition of the model</p><p>base model：</p><p>0.7(0.5(Gf_style2) + 0.5(mixedmixedmixedV2)) + 0.3(basil_mix)</p><p></p><p>replace OUT02,OUT04 with nightSkyYOZORAStyle_yozoraV1</p><p>--to get legs</p><p>replace IN00,IN01 with AbyssOrangeMix2_nsfw</p><p>--to get fingers</p><p>then reset all clips to get basic weight set</p><p></p><p>虽然直接生成的图片是偏手绘的，但我保留了大部分真实光影，因此配合真实系的Lora使用，可以绘制更加真实的图片</p><p>Although the directly generated pictures are hand-painted, I kept most of the real light and shadow, so it can be used with the real Lora to draw more realistic pictures</p><p></p><p>需要注意的是，只有站立状态下的腿型是完美的（对我而言），其他姿势依然非常容易出错</p><p>It should be noted that only standing legs are perfect (for me), other postures are still very error-prone</p><p></p><p>最后欢迎来我的pixiv</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.pixiv.net/users/656406\">https://www.pixiv.net/users/656406</a></p>","ratingcount":105,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"BeautyProMix":{"status":"inactive","modelid":"civitai-19597","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/03942658-1c00-41f9-2ef8-3d18d259a900/width=450/213367.jpeg","description":"<h2><strong>關於BeautyProMix模型(人物及光影加強)</strong></h2><p>本模型經過約略1個月進行各項參數的調整並搭配大量的圖庫進行訓練，前後進行了近百次的混合及比例調整，此版本針對人像及光影表面十分令人讚賞(可參考示意圖的光影效果)。尤其是這個模型加入了BeautyPro首席穿搭顧問及彩妝師團隊的協助，針對用於訓練的每張照片進行細節的調整，使得面部表現更為優良。</p><p></p><p>感謝參與此模型製作的人員，包含製作者及提供照片作為模型訓練的朋友們，本模型搭配了多個主流模型進行訓練並條列如下，製作團隊已經盡力找到各個用於訓練模型的源頭，但難以確認每一個模型及每一張用於訓練的圖片是否存在版權疑慮，若我們的模型對您個人或公司的權益造成損害，請立即留言通知我們，製作團隊將立即將相關內容於模型中完全移除後，發布修正版本，謝謝。</p><p></p><p><strong>#BeautyProMix</strong><br />*為了感謝無日無夜測試模型的製作者團隊及無私提供照片的所有朋友，請於製作出來的圖片標註是採用 <u>#BeautyProMix</u>，僅代表製作者團隊群感謝您。</p><p></p><h2>About the BeautyProMix Model(Enhancement of Characters and Lighting)</h2><p>After approximately one month of adjusting various parameters and training with a large database of images, this model has undergone nearly 100 blends and ratio adjustments. This version focuses on enhancing the appearance of characters and lighting, and has received high praise. In particular, the model has incorporated the expertise of the BeautyPro team's chief fashion consultants and makeup artists to fine-tune the details of each photo used for training, resulting in superior detail of the face.</p><p>We would like to thank everyone who contributed to the production of this model, including the creators and friends who provided photos for training. The model was trained with multiple mainstream models, and we have made every effort to locate the sources of each model used for training. However, it is difficult to confirm whether each model or image used for training may have copyright concerns. If our model causes any damage to your personal or company interests, please inform us immediately. The developing team will promptly remove the relevant content from the model and release a corrected version. Thank you.</p><p></p><p><strong>#BeautyProMix</strong></p><p>*To express gratitude to the develop team who tirelessly tested the model day and night, and to all friends who generously provided photos, please tag the images produced using #BeautyProMix. This tag represents the collective appreciation of the developing team.</p><p></p><h2><strong>Mixed-model list</strong></h2><p><strong>BeautyProAsiaFace</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/beautypro/BeautyProAsiaFace\">https://huggingface.co/beautypro/BeautyProAsiaFace</a></p><p><strong>MUSE_v1</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/13564/musev1\">https://civitai.com/models/13564/musev1</a></p><p><strong>AsiaFacemix</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dcy/AsiaFacemix\">https://huggingface.co/dcy/AsiaFacemix</a></p><p><strong>Colorful</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7279/colorful\">https://civitai.com/models/7279/colorful</a></p><p><strong>LOFI</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9052/lofi\">https://civitai.com/models/9052/lofi</a></p><p><strong>Deliberate</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">https://civitai.com/models/4823/deliberate</a></p><p><strong>QGO-10b</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4188/qgo-10b\">https://civitai.com/models/4188/qgo-10b</a></p><p><strong>HassanBlend</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\">https://civitai.com/models/1173/hassanblend-1512-and-previous-versions</a></p><p></p><p>*重要備註：此模型完全未使用到明定無法商用的模型ChilloutMix及Dreamlike Diffusion進行訓練</p><p>*Important Note: This model was not trained using the ChilloutMix and Dreamlike Diffusion models, which are explicitly not available for commercial use.</p><p></p><h2>徵求更多的好照片</h2><p>製作團隊正在收集更多願意提供用於訓練的人物照片或景色圖片，若您願意提供給BeautyPro團隊進行訓練，團隊將在共同製作者名單中，加入您的名字，以展示您對於AI繪圖及相關領域的付出及努力！</p><p></p><h2>We need more quality Photos</h2><p>The developing team is currently collecting more character portraits and scenic images from those willing to provide them for training. If you are willing to offer your photos to the BeautyPro team for training purposes, your name will be included in the list of co-creators to showcase your contribution and efforts to the field of AI drawing.</p><p></p><h2>即將推出</h2><p>人物強化的進階版正在進行訓練中，若有更新的突破，我們將立即上傳提供大家測試及使用！若有任何建議及使用上的問題，也歡迎隨時留言，製作團隊感謝您提供的寶貴意見。</p><p></p><h2>To be continued</h2><p>An advanced version of the character and lighting enhancement model is currently being trained. If there are any breakthroughs in the update, we will immediately upload it for testing and use. If you have any suggestions or issues using the model, please feel free to leave a message. The developing team appreciates your valuable feedback.</p><h2></h2><p></p><p></p>","ratingcount":36,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Cetus-Mix":{"status":"inactive","modelid":"civitai-48569","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/399afc22-2a06-4873-d283-c81f3ba60500/width=450/521590.jpeg","description":"<p><strong>NOTICE</strong>:<strong>LET ME KNOW</strong> before you put this model on <u>commercial usage</u>.</p><p>My twitter account:<strong>@eagelaxis </strong>:) Contact me if needed.</p><p>Discord Account:<strong>Eagelaxis#7818</strong></p><p><strong>Version Choosing Advice</strong>:<strong>V2f,V3,Coda and V3.5</strong> are recommended,especially <strong>CODA</strong> for first-time users.</p><p>Hard to tell how many models used to merge.</p><p>Check the example images to recognize this model's art style</p><p>For more example images, just take a look at <a target=\"_blank\" rel=\"ugc\" href=\"https://pixai.art\">https://pixai.art</a></p><p>More attention on shades and backgrounds compared with former models(<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6408/andromeda-mix\">Andromeda-Mix | Stable Diffusion Checkpoint | Civitai)</a></p><p>Hands-fix is still waiting to be improved.</p><p>Highres-fix(upscaler) is strongly recommended(using the SwinIR_4x,R-ESRGAN 4x+anime6B by myself) in order to not make blurry images.</p><p>(Sorry for the misunderstanding caused by myself.\"Bad_prompt_v2:1.4\" is a kind of embedding recognized as collection of normal negative prompts such as\"lowres,bad anatomy\".)</p><p>Recommend: Clip skip 2 Sampler:DPM++2M Karras Steps:20+</p><p>CFG scale:4-8 Vae:<a target=\"_blank\" rel=\"ugc\" href=\"http://Pastel-Waifu-Diffusion.vae.pt\">Pastel-Waifu-Diffusion.vae.pt</a>(The vae used by Pastel-mix si just good enough)</p><p>Highres.fix:SwinIR_4x Hires steps:10+ Denoising strength:0.4+ Upscale by: 1.5+</p><p>Loras along with embeddings on hands-fix are strongly recommended.</p><p>V4 should be coming soon.</p><p>Looking forward to your reviews!</p>","ratingcount":253,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"ChikMix":{"status":"inactive","modelid":"civitai-20663","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/799a60e3-355d-40ba-a5d7-6b06dfbdb200/width=450/218715.jpeg","description":"<h3>ChikMix_v2 now release!</h3><p>Better face and body proportion, enjoy</p><p></p><h3>Feature:</h3><p>2.5D K-doll style focus</p><p>Super simple prompts focus</p><p>Wide nsfw content Support</p><p>No VAE need</p><p>Check more image I made: <a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/xxxholic6666\">https://twitter.com/xxxholic6666</a></p><p></p><h3>Recommended embeddings:</h3><p>bad-artist: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/NiXXerHATTER59/bad-artist\">https://huggingface.co/NiXXerHATTER59/bad-artist</a></p><p>pure-ero-face: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4514/pure-eros-face\">https://civitai.com/models/4514/pure-eros-face</a></p><p></p><h3>For people who cant reach the sample images results:</h3><p>Use Hires. fix with R-ESRGAN 4x+ Anime6B in 2x upscale, set Denoising strength as 0.3~0.4, like 640*960 to 1280*1920.</p><p>Before &amp; After Hires. fix</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/41ffd4cf-82bd-42f1-4d24-0b5de9061a00/width=525/41ffd4cf-82bd-42f1-4d24-0b5de9061a00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/df8cc019-6116-4704-a69a-eb89ad382a00/width=525/df8cc019-6116-4704-a69a-eb89ad382a00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/27490901-2036-4ed3-0765-1dd611985700/width=525/27490901-2036-4ed3-0765-1dd611985700\" />","ratingcount":197,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Dungeons N Waifu's (New Version 2.2)":{"status":"inactive","modelid":"civitai-20937","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9f1e76f4-6ea3-45c6-dee7-f192b0492500/width=450/293422.jpeg","description":"<p>🔥🐉 NOW UPDATED TO V2.2! w/ BUILT IN NOISE OFFSET! 🐉🔥⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝⚝</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8d7a5727-e556-493f-e1c8-00391cb72900/width=525/8d7a5727-e556-493f-e1c8-00391cb72900\" /><p>A handpicked and curated merge of<strong> the best of the best </strong>in <strong>fantasy world, character &amp; creature design</strong>. Should serve as a bit of a swiss army knife / multi-tool to create any and all fantasy art, character concepts, portraits, designs, locations, &amp; even a bit of n00ds. I've yet to find what this can't handle❗🎨</p><p></p><p>Specializes in painterly, semi realistic to realistic illustration, and artists based prompts, but can do design work, vector illustrations, logos, and a bit of anime as well.</p><p></p><p><strong>Works best from 7-13.5 CFG and up 20-70 STEPS imho. YMMV!</strong></p><p><br /><strong>SHOW ME WHAT YOU MAKE WITH THIS!! 😉</strong><br /></p><p>Note on the Versions: Keep in mind this merged model has been evolving.. So the 1.6 version is not very similar to the 2.2 version or visa-versa. Yes, they both produce good results but the result you get will be different. (I tried to illustrate this in the example images if you flip between versions.)</p><p><br />If you find yourself asking \"which is the right version?\" If you're new to SD and want an easy ride choose version 1.0 or 1.6 both are consistent and work quite well. I still use 1.6 for some things from time to time. If you want darker more detailed environments and detailed shading choose 2.0 or 2.2 but realize that 2.0 &amp; 2.2 are a little more demanding from the prompt maker in order to get the exact result you want. <br /></p><p>There is no embedded VAE in this (other than ones included in the merges) but one of these should work fine: (click the links)<br />☞<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\"> <strong>vae-ft-mse-840000-ema-pruned.ckpt </strong></a><strong><br />☞ </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\"><strong>kl-f8-anime2.ckpt</strong></a><br /><br />*** <strong><em>Note:</em></strong><em> </em><strong><em>that the example images are provided as a basis of reference and raw output. In most cases untouched other than mild inpainting for the eyes or face in a few examples. *** THESE SHOULD BE EASILY REPRODUCIBLE RESULTS! IF YOU HAVE QUESTIONS PLEASE ASK 🗪</em></strong><br /><br /><strong>Merge listing consists of:</strong><br />===========<br /><em>(Version 1.6)</em><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5041/cheese-daddys-landscapes-mix\">cheeseDaddys_35</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">dreamshaper_33</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1540/unstableinkdream\">unstableinkdream_v6</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8124/a-to-zovya-rpg-artists-tools-15-and-21\">aToZovyaRPGArtistsTools15</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1274/dreamlike-diffusion-10\">dreamlikeDiffusion10</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">deliberate_v2</a><br />===========<br /><em>(Version 2.0)</em><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15037/cheese-daddys-landscapes-mix-or-offset-noise\">cheeseDaddysLandscapes_35 (Offset Noise)</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">dreamshaper_3.32 50% </a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1540/unstableinkdream\">UnstableInkDream_v6 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8124/a-to-zovya-rpg-artists-tools-15-and-21\">aToZovyaRPGArtistsTools15 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1274/dreamlike-diffusion-10\">dreamlikeDiffusion10 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">deliberate_v2 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">revAnimated_reva1_FULL 20%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6077/umi-ai-mythology-and-babes-by-dutchalex\">umiAIMythologyAndBabes_aphroditeRealisticV1 30%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/90/dungeons-and-diffusion-v3\">dungeonsAndDiffusion_v3 20%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10391/noise-offset-for-true-darkness-in-sd\">noiseOffsetForTrue_v10 50%</a><br />===========<br /><em>(Version 2.2)</em><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15037/cheese-daddys-landscapes-mix-or-offset-noise\">cheeseDaddysLandscapes_35 (Offset Noise)</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">dreamshaper_3.32 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1540/unstableinkdream\">UnstableInkDream_v7 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8124/a-to-zovya-rpg-artists-tools-15-and-21\">aToZovyaRPGArtistsTools15 50%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1274/dreamlike-diffusion-10\">dreamlikeDiffusion10 30%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">deliberate_v2 60%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">revAnimated_v11 25%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6077/umi-ai-mythology-and-babes-by-dutchalex\">umiAIMythologyAndBabes_aphroditeRealisticV1 25%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/14065\">FaeTastic 60%</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/90/dungeons-and-diffusion-v3\">dungeonsAndDiffusion_v3 25%</a><br />===========<br /><br /><br />There are pruned &amp; non pruned versions available if you use the pulldown <br />This is better for merging &amp; testing. Otherwise use the pruned. 👍<br /><br />🗈 PLEASE NOTE: <em>All of the originals have their own attributions so these must be followed to use this.</em><br /><br /><br /><strong>I was asked recently how to get higher quality images like the examples and about blurred eyes and faces:</strong><br />================================================<br /></p><p>Blurred eyes, or sometimes warped faces are not that uncommon in SD and sometimes require an inpaint to pull off. Most of my examples are not inpainted. But a few are.<br /><br />First off when you run txt2img <strong>ALWAYS use HIRES FIX!</strong><br /><br /><strong>latent (nearest or exact) upscale / denoise 0.4-0.7</strong> (<em>Complete variable - depends on the type and complexity of the image. YMMV!</em>) <br /><br /><strong>Upscale by 1.5-2</strong> but no more than that. <br /><br />This will get you a pretty good base image to work with.<br /><br />Afterwards.. You can always <strong>send your txt2img picture to inpaint</strong> on the bottom right under the result area &gt; select the face or eyes &gt; lower the <strong>denoise strength to 0.5-0.57</strong>. &gt; make sure your <strong>seed is set to random</strong>.<br /><br /><br />masked content = fill / inpaint area = whole picture ======<strong> for faces</strong><br /><br />masked content = fill / inpaint area = only masked ====== <strong>for eyes</strong><br /><br /><br />With \"whole picture\" selected for<strong> larger inpaint target aka faces</strong> (or hands) you may need the denoise to be lower to pick up more of the original image. 0.53-0.56<br /><br />Now with \"only masked\" and<strong> a smaller target like eyes</strong> you get a little more freedom so your denoise can be 0.54-0.57<br /><br />Run a batch of <strong>4-5 (or more) </strong>for the faces.. go through pick the best one.. if you're lucky you got the eyes and face in one go... if not you may need to <strong>choose the best face</strong>.. <strong>send back to inpaint again</strong>.. <strong>select just the eyes..</strong> and<strong> rerun a new batch</strong> (changing it to <strong>only masked and the settings described above for eyes.</strong>)<br /><br />Finally when you get it all together<strong> send to extras:</strong><br /><br /><strong>Resize to 1.5-2</strong><br /><br />Upscale 1= Nearest<br />Upscale 2= R-ESERGAN 2x or 4x<br />But google &amp; get yourself <a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database#Universal_Models\"><strong>Remacri Upscaler</strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database#Universal_Models\"><strong>Lollypop Upscaler</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database#Universal_Models\"><strong>4x_NMKD_Superscale-SP_178000_G</strong></a><br /><br />Upscaler 2 is what will get you there. If you want super sharp / realism images you choose <strong>NMKD</strong><br /><br />You want a good all around upscaler that can do nearly any subject you choose <strong>Remacri</strong><br /><br />If you're working on toons, anime, animated, cell shaded you choose <strong>Lollypop</strong><br /><br />Each of these is unique and so is their outputs if you want to compare simply change the pull down and run off the various types and contrast / compare the finished results. <br /><br />For the more advanced upscale: Get yourself <a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/generative-ai/ultimate-upscaler-for-stable-diffusion-a-step-by-step-guide-e624ca51f632\"><strong>Ultimate SD Upscale</strong></a><br />(click the link for a basic tutorial on how to get it and how to use it.)<br /><br /><em>Good Luck &amp; Have Fun!</em></p><p><br />================================================</p>","ratingcount":41,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Babes":{"status":"inactive","modelid":"civitai-21216","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/425e4b65-bf68-4404-3fe9-d94c9c204400/width=450/599318.jpeg","description":"<p>Please <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/posts/create?modelId=2220&amp;modelVersionId=21216&amp;returnUrl=/models/2220&amp;reviewing=true\">🧡 this model by reviewing it</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/mG9Pvko\">🖼️ Generate Babes online </a>... <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/alexds9/\">❤️ Support Babes </a>... <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/BKhkwwqK9m\">🫶 Discord Server</a></p><p>👀 See also: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/26566/babes-kissable-lips\">💋 <strong>Babes Kissable Lips</strong> 💋</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/35549/sexy-toons-feat-pipa\">🍒 <strong>Sexy Toons feat. Pipa </strong>🍒</a>.<br />ℹ️ This model was inspired by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1180/samdoessexy-blend\">SamDoesSexy Blend. </a>Influenced by: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1115/sdhero-bimbo-bondage\">SDHero-Bimbo-Bondage</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2290/thepit-bimbo\">Pit Bimbo</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">Analog Diffusion</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1274/dreamlike-diffusion-10\">Dreamlike Diffusion</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/64/redshift-diffusion\">Redshift Diffusion</a>. Core influence: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/86/openjourney-aka-midjourney-v4\">MidJourney v4</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1094/studio-ghibli\">Studio Ghibli</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2291/copeseethemaid\">CopeSeetheMald v2</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1188/f222\">F222</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1169/sxd\">SXD 0.8</a>.<br />⚠️ <strong>Notice</strong>: If you see skin artifacts and noise, please add \"freckles\" to the negative prompt. If you want freckles, write in your positive prompt: \"(freckles:0.7)\", values under 0.8 seem to produce normal freckles in my tests.</p><p><strong><u>📌 Are your results not 100% identical to any specific picture?</u></strong></p><ol><li><p>Make sure to use Hires-fix from example SwinIR_4x / 4x-UltraSharp / 4x-AnimeSharp / RealESRGAN_x4plus_anime_6B (<a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database\">Upscaler Download</a>) with \"Upscale latent space image when doing hires. fix\", it is what I usually use for hires-fix.</p></li><li><p>Use VAE: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">vae-ft-mse-840000-ema-pruned</a> for better colors. Download it into \"stable-diffusion-webui/models/VAE\" folder. Select it in the settings.</p></li><li><p>I use xformers - it's a small performance improvement that might change the results. It is not a must to have and can be hard to install. Can be enabled with a command argument \"--xformers\" when launching WebUI.</p></li><li><p>WebUI is updated constantly with some changes that influence image generation. Many times technological progress is prioritized over backward compatibility.</p></li><li><p>Hardware differences may influence changes. I've heard that a bunch of people tested the same prompt with the same settings, and the results weren't identical.</p></li><li><p>I have seen on my own system, that when running as part of a batch, may change a little bit the results.</p></li><li><p>I suspect there are hidden variables inside modules we can't change that produce slightly different results due to internal state changes.</p></li><li><p>Any change in image dimension, steps, sampler, prompt, and many other things, can cause small or huge differences in results.</p></li></ol><p><strong><u>📌 Do you really want to get the exact result from the image? There are a few things that you can do, and possibly get even better results.</u></strong></p><ol><li><p>Make a single word changes to prompt/negative prompt and test, and push it slowly to your desired direction.</p></li><li><p>If the image has too much of something or doesn't have enough of something, try to use <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#attentionemphasis\">emphasis</a>. For example, too glossy? use \"(glossy:0.8)\", or less, or remove it from the prompt, or add it to the negative. Want more, use values 1.1-1.4, then additional descriptors in the same direction.</p></li><li><p>Use variations - use the same seed, and to the right of the seed check \"Extra\". Set \"Variation strength\" to a low value of 0.05, generate a few images, and watch how big the changes are. Increase if you want more changes, and reduce if you want fewer changes. That way you can generate a huge amount of images that are very similar to the original, but some of them will be even better.</p></li></ol><p><strong><u>📌 Recommendations to improve your results</u></strong><u>:</u></p><ol><li><p>Use VAE for better colors and details. You can use VAE that comes with the model or download \"vae-ft-mse-840000-ema-pruned from (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main</a>) , ckpt or safetensors file into \"stable-diffusion-webui/models/VAE\" folder. In the settings find \"SD VAE\", refresh it, and select \"vae-ft-mse-840000-ema-pruned\"(or the version included with the model). Click \"Apply settings\" button on the top. The VAE that comes with the model is \"vae-ft-mse-840000-ema-pruned\", you don't need both, use the one that you downloaded, it will work very well with most of the other models too.</p></li><li><p>Use hires-fix, SwinIR_4x / 4x-UltraSharp / 4x-AnimeSharp / RealESRGAN_x4plus_anime_6B (<a target=\"_blank\" rel=\"ugc\" href=\"https://upscale.wiki/wiki/Model_Database\">Upscaler Download</a>), first pass around 512x512, second above 960x960, and keep the ratio between the two passes the same if possible.</p></li><li><p>Use negatives, but not too much. Add them when you see something you don't like.</p></li><li><p>Use CFG 7.5 or lower, with heavy prompts, that use many emphases and are long, you can go as low as 3.5. And generally try to minimize the usage of emphasis, you can just put the more important things at the begging of the prompt. If everything is important, just don't use emphasis at all.</p></li><li><p>Make changes cautiously, changes made at the beginning of the prompt have more influence. So every concept can throw your results drastically.</p></li><li><p>Read and use the manual (<a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features\">https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features</a>).</p></li><li><p>Learn from others, copy prompts from images that look good, and play with them.</p></li><li><p>DPM++ 2M Karras is the sampler of choice for many people, including me. 40 steps are plenty, and I usually use 20.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/BKhkwwqK9m\">Discord server</a> for help, sharing, show-offs, experiments, and challenges.</p></li></ol>","ratingcount":124,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AyoniMix":{"status":"inactive","modelid":"civitai-21877","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/52031be9-39c3-4761-5ebb-459b1ecde400/width=450/233747.jpeg","description":"<p>The result of many merges aimed toward making extremely highly detailed images. This can do realistic content, but I prefer to make stylized stuff so that aspect has not been extensively tested.</p><p></p><p>All example images were generated without any hypernetworks, loras, or inpainting. Everything was genned without high res fix, then upscaled using SD upscale in img2img.</p><p></p><p>Used SD 1.5 VAE</p><p></p><p>Unpruned float 32 version of AyoniMix V2 on huggingface:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Ayoni/AyoniMix_V2/blob/main/AyoniMix%20V2%20Float32.safetensors\">https://huggingface.co/Ayoni/AyoniMix_V2/blob/main/AyoniMix%20V2%20Float32.safetensors</a></p>","ratingcount":33,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"cartoonish":{"status":"inactive","modelid":"civitai-22031","rating":4.88,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/96ced1a7-91b9-4951-79f9-a8061af40300/width=450/238115.jpeg","description":"<p>Sorry for the confusion. During the upscaling process, there were sampler and seed changes. Fixed it now.</p><p><strong><u>I recommend ClipSkip 3.</u></strong> Sampler Euler a is recommended. The prompt \"upper body\" is recommended. The colors are fine with VAE applied. It's ok to use img2img SD upscale. img2img SD upscale method: scale 6~15, denoising 0.2-0.3 After selecting SD Upscale at the bottom, tile overlap 64, scale factor2 The sampler must be in DPM++SDE format. There may be some nasty troughs. It seems to be an unfinished model that gets weird when the character is far away.<br />But I don't have the confidence to make it better.<br />Also, Black Eyes can make your eyes look weird. about five out of ten<br />Please forgive the imperfect model. thank you<br /></p><p>To reiterate the important part, if the picture is strange because the character is far away, use SD upscale. And don't forget ClipSkip 3.</p><p></p><p>If you don't want to appear young, say mature, 20~70 years old in the prompt, immatuer, loli, yong in the negative prompt</p>","ratingcount":32,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Colorful":{"status":"inactive","modelid":"civitai-51426","rating":4.87,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/900150f0-2069-4c68-978e-9b3346a30500/width=450/553757.jpeg","description":"<p>Thank you so much for the feedback and examples of your work! It's very motivating.</p><p></p><p>Do you like what I do? Feel free to <a target=\"_blank\" rel=\"ugc\" href=\"https://www.buymeacoffee.com/recoilme\">buy me a coffee</a> ☕</p><p></p><p>My models:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7279/colorful\"><u>Colorful</u></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21916/animatrix\">Animatrix</a></p></li></ul>","ratingcount":39,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Galena Blend":{"status":"inactive","modelid":"civitai-23323","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d05cef23-1400-49c6-1dc9-a0ed3f6d6600/width=450/252996.jpeg","description":"<p>This is the latest in my series of mineral-themed blends. I wanted it to have a more comic/cartoon-style and appeal. It is also the most complex of my blends, requiring a small mix between AOM3 and iCoMix, several merges between unfinished results, etc.<br /><br />It's less NSFW prone than my earlier blends, but still rather prone. Clothes generate without much hassle.<br /><br />This blend was my most complex, and not all the LoRA's I used are available on CivitAI. The ones I did use that are available on CivitAI are: Sciamano240, Reiq, Omar Dogan, VanRipperArt, Tsuvida.<br /><br />I used Hires fix with 4x Fatal Anime 50000 G with 3 Hires Steps, 0.3 denoising strength, and upscaled by 1.5. I use the OrangeMix VAE.<br /><br />I'm considering making a simple cartoon style checkpoint (like Tsuvida) and something more retro inspired by PC-98 graphics. Let me know what you guys think, and leave a comment or review if you got good use out of this checkpoint.</p>","ratingcount":32,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Sardonyx Blend":{"status":"inactive","modelid":"civitai-23326","rating":4.91,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c1933119-afb1-4c92-e2d4-0310273dbc00/width=450/253024.jpeg","description":"<p>This is my flagship 'Sardonyx' blend. I find it's in line with what the community on Civit likes producing. It's pretty versatile while also having an artstyle that's unique in image generation.<br /><br />The mix is <em>incredibly</em> prone to generating NSFW, so you'll need to put more weight on clothing tags and maybe 'nsfw' in your negative prompt. It's also prone to generating see-through shirts a lot, so plan for that I guess.<br /><br />The blend was made with <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/hako-mikan/sd-webui-supermerger/\">https://github.com/hako-mikan/sd-webui-supermerger/</a>. I used AOM3 as the base, and it's made up of these LoRA's: Sciamano240, AromaSensei, Robutts, and Shexyo. <em>(All of these LoRA's can be found here on Civit.) The newest version is made with my own AromaSensei LoRA and my new Luminyu LoRA.</em><br /><br />I used Hires fix with 4x Fatal Anime 50000 G with 3 Hires Steps, 0.3 denoising strength, and upscaled by 1.5. I use the OrangeMix VAE.<br /><br />Everything else is specified in the image tags. Make sure to leave a review or a comment if you got good use out of this blend.</p>","ratingcount":43,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Comic Babes":{"status":"inactive","modelid":"civitai-50094","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f67fe32a-4fc6-4bf9-0f34-ff936c7ca800/width=450/538802.jpeg","description":"<p>A model I merged that I just keep coming back to, so I decided to share it.</p><p>A 50/50 blend of <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16164/icomix\">iCoMix v1</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2220/babes\">Babes v1.1</a>. Recommended you use a vae. I use anything_v4, which is available for download here.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a> also works very well with this merge, and minimal negative prompts tend to produce nice results.</p><p>I'm already working on some other versions that incorporate new versions of iCoMix and Babes.</p><p><strong>Please share your images! I'd love to see what you create.</strong></p><p>Thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lostdog\">lostdog</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/alexds9\">alexds9</a> for their terrific models.</p>","ratingcount":32,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"饭特稀_v0.8":{"status":"inactive","modelid":"civitai-24196","rating":4.86,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a67a29e6-2884-418d-b844-837b98a07500/width=450/447200.jpeg","description":"<p>mix of many models, VAE is baked，good at NSFW</p><p>很多模型的混合，vae已经烘焙，擅长nsfw</p><p></p><p>setting:</p><p>Denoising strength: 0.55,</p><p>Clip skip: 2,</p><p>ENSD: 31337,</p><p>Hires upscale: 4,</p><p>Hires steps: 15,</p><p>Hires upscaler: R-ESRGAN 4x+,</p><p>Eta: 0.68</p><p></p><h3>2023.3.19 update</h3><p>Two additional versions were added, 0.8a being more realistic and 0.8c being more anime</p>","ratingcount":123,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"3moon NI_real":{"status":"inactive","modelid":"civitai-25198","rating":4.86,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/845c8584-6a2c-4ffb-d531-deca893ab100/width=450/276110.jpeg","description":"<p>NSFW mordel</p>","ratingcount":49,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Level4":{"status":"inactive","modelid":"civitai-25295","rating":4.9,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f4265561-d2ca-4676-d3c0-e9778f116200/width=450/277511.jpeg","description":"<h3>Check out <a rel=\"ugc\" href=\"https://civitai.com/models/21813/edge-of-realism\">Edge Of Realism</a>, my new model aimed for photorealistic portraits!</h3><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3b315840-74ce-4490-7f17-00ab4859ec00/width=525/3b315840-74ce-4490-7f17-00ab4859ec00\" /><p></p><h3>\"Instruct\" LoRA coming soon! Will generate decent images from single line prompts, no negatives needed! Example below!</h3><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b91b29c2-11af-4423-e565-e2b6332e7d00/width=525/b91b29c2-11af-4423-e565-e2b6332e7d00\" /><p>Prompt: bunny on dirt path at night, dramatic lighting, &lt;lora:Level4_Generation:0.2&gt;</p><p></p><p>Requires a good deal of prompt crafting. I would recommend finding a prompt that generates the style and quality to your liking and saving it as a style. Working on improving the model and training an Instruct LoRA.</p><p></p><p>I use vae-ft-mse-840000-ema-pruned with this model.<br /><br />I don't remember all the merges I made to create this model. I have it recorded somewhere. Enjoy!</p><p></p><p>!!!WARNING!!!</p><p>This model is meant for SFW content, however it seems to excel and lean towards NSFW content. Was going for a hyper realistic general purpose model. Merged with a lot of different models.</p>","ratingcount":50,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"【Checkpoint】YesMix":{"status":"inactive","modelid":"civitai-25571","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/58dffba1-e9bb-4aa5-4133-14a932d23400/width=450/280940.jpeg","description":"<h3>2023/3/19 update</h3><p>Upload original version of 1.6 Yesmix. No LoRA models are merged in this version.</p><h3>2023/3/14 update</h3><p>Adjust merging proportion to fix hands. Merge following new LoRAs to enhance effect:</p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/12597/moxin\"><strong>Moxin </strong></a>by simhuang to enhance face and style.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8217/fashion-girl\"><strong>Fashion Girl</strong></a> by me to enhance face.</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16667/akiryos-mai\"><strong>Akiryo's Mai</strong></a> by me to slightly finetune face, body shape and skin texture.</p></li></ol><p>Thus, when this model and the above LoRA are used to generate images, the weight of these LoRAs should be lowered appropriately.</p><p><strong>For convenience, the preview images are generated using only tags without any extra modules (e.g. embedding, LoRA, Hypernetwork) and functions (e.g. hires fix). The NAI's VAE had been baked in this model, so there is no need to load any additional VAEs.</strong></p><h3>2023/2/16 upate</h3><p>Adjust the merging ratios to fix deformed limbs.</p><h1>Introduction</h1><p>This model is originated an idea of creating a model that can precisely generate anime nsfw images. For this reason, I fine-tuned the NAI model with more than 10k nsfw images. Unfortunately, it's overcooked. To reduce this bad effect, I have to merge this model with the following models:</p><ol><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\"><strong>Hassanblend</strong></a> by sdhassan (0.15)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5706/anyhentai\"><strong>Anyhentai</strong></a> by asdpro123 (0.1)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4451/abyssorangemix2-hardcore\"><strong>AbyssOrangeMix2 - Hardcore</strong></a> by Havoc (0.15)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/syaimu/7th_Layer\"><strong>7th-anime-v3</strong></a> by syaimu (0.2)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3850/kenshi\"><strong>Kenshi</strong></a> by Luna (0.15)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\"><strong>Grapefruit</strong></a> by Ikena (0.1)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7154/colorbombmix\"><strong>ColorbombMix</strong></a> by mocker (0.1)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468/counterfeit-v25\"><strong>Counterfeit v2.5</strong></a> by rqdwdw (0.1)</p></li></ol><p>Then this checkpoint was born after above merging, which is a very coincidental work. The name of this model is still unknown to me. Therefore it's named as \"YesMix\". <strong>The NAI's VAE had been baked in this model, so there is no need to load any additional VAEs.</strong> Thanks to the excellent models provided by the above authors. <strong>Btw, all of the preview images are generated using this model without any extra modules such as LORA and embedding.</strong></p>","ratingcount":112,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"FaceBombMix":{"status":"inactive","modelid":"civitai-25993","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/306d833f-6fb0-4afe-7114-964a7b2bdb00/width=450/285805.jpeg","description":"<p>FaceBomb : Covers from anime to 2.5D style. Suited for general use.</p><p></p><p>More info : <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/mocker/KaBoom\">https://huggingface.co/mocker/KaBoom</a></p><p></p><p>EDIT 1</p><p>If the color is washed out, try applying VAE.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\">https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt</a></p><p></p><p>EDIT 2</p><ul><li><p>Positive : <code>(masterpiece, sidelighting, finely detailed beautiful eyes: 1.2), masterpiece*portrait, realistic, 3d face, lustrous skin,</code></p></li><li><p>Negative : <code>(worst quality, low quality:1.4), watermark, logo,</code></p></li></ul><p></p><p>If the sample prompt doen't generate the image you desire, try adding <code>upper body</code> to positive prompt. That 2.5D style best applies to portrait of upper body. It's not necessary but may save you from extra *click.</p><p></p><p>Here's my configuration for duplicating first image. Sorry for inconvenience.</p><p>I use xformers so some detail(e.g. necklass) may change every time.</p><p></p><p>Below is just an example and you can/should change configuration to your liking. It's recommended but not limited.</p><p></p><p>Model : FaceBombMix-fp16-no-ema.safetensors</p><p>SD VAE : kl-f8-anime2.ckpt</p><p>Clip skip : 2</p><p>Sampling method : DPM++ SDE Karras</p><p>Sampling steps : 32 (24 ~ 32, as you like)</p><p>Upscaler : R-ESRGAN 4x+ Anime6B</p><p>Hires steps : 14 (in my case, 7 ~ 14 weren't really different for R-ESRGAN 4x+ Anime6B)</p><p>Denoising strength : 0.5 (I change around 0.45 ~ 0.55)</p><p>Upscale by : 2</p><p>CFG Scale : 9 (7 ~ 9, as you like)</p><p>(Settings &gt; Sampler parameters &gt; Eta noise seed delta) is set to `31337` unsure if it matters though.</p><p></p><p>(Sorry, I dont know hot to upload higher resolution image to description.)</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/210f4348-b837-49ea-b7ff-405886de7400/width=525\" /><p></p><p>EDIT 3(Not needed if you use bakedVAE version)</p><p>How to apply VAE</p><ol><li><p>Download VAE from EDIT 1 and copy to 'stable-diffusion-webui/models/VAE'.</p></li><li><p>Start the webui and go to 'Settings &gt; User interface &gt; Quicksettings list' and add 'sd_vae' without quotation mark.</p></li><li><p>Click 'Apply settings' and 'Reload UI'. They are orange buttons on top.</p></li><li><p>You should see SD_VAE dropdown menu on top of your main screen. Select 'kl-f8-anime2'.</p></li></ol><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1e56f1a4-8fce-41a0-093b-5d5f1398ca00/width=525/1e56f1a4-8fce-41a0-093b-5d5f1398ca00\" /><p></p>","ratingcount":92,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"MeinaHentai":{"status":"inactive","modelid":"civitai-26033","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9d3ea665-83f3-4834-b15e-25d4c402f700/width=450/286291.jpeg","description":"<p>I created a <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">discord</a> server where you can post images that you generated, discuss prompt and/or ask for help. <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/meinaverse\">https://discord.gg/meinaverse</a><br /><br /><strong>If you like one of my models and want to support their updates:</strong><br />I have a <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>ko-fi</strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>Patreon</strong></a> page where you can support me or buy me a coffee &lt;3 , <strong>it will be very much appreciated:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>https://ko-fi.com/meina</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>https://www.patreon.com/MeinaMix</strong></a><strong> </strong><br /><br /><strong>You may also try this model using</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/RR6lMmw\">Sinkin.ai</a>: <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/RR6lMmw\">https://sinkin.ai/m/RR6lMmw</a><br />----------------------------------------------------------------------------------<br />MeinaHentai is the third addition to the Meina family of models, it is laser focus in hard nsfw and hentai. for SFW checkout MeinaMix and MeinaPastel!<br /><br />MeinaHentai objective is to make detailed and hentai illustrations following the prompt as best as possible, in order to test the capabilities of it, my <strong>recommendations</strong> of use is:<br /><br /><strong>-- Recommendations of use:</strong><br /><br />If you want the art to be more realistic, add:<strong> ' photorealistic, (hyperrealistic:1.2) '</strong> in the<strong> prompt.</strong><br /><br /><em>- Sampling method: </em><strong><em>Euler a</em></strong><em>, </em><strong><em>24 steps</em></strong><em>.</em><br /><em>- Resolution: </em><strong><em>512x768, 768x512</em></strong><em>.</em><br /><em>- The VAE is baked-in.</em><br /><em>- Negative prompt: ' (worst quality, low quality:1.4), monochrome, zombie, extra limbs, ' </em><br /><br /><em>If you can use upscaler to improve some details like the eyes: </em><br /><em>Upscaler: ESRGAN_4x at 10 steps and 0,3 Denoising in 2x.</em><br /><em>However upscaler is not a necessity for MeinaHentai V2.</em></p>","ratingcount":121,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Edge Of Realism":{"status":"inactive","modelid":"civitai-51913","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5462fe1b-6928-4c9e-3016-8ef467b65200/width=450/559443.jpeg","description":"<p>A spin off from <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/17449/level4\">Level4.</a> Built to produce high quality photos. Sometimes photos will come out as uncanny as they are on the edge of realism.</p>","ratingcount":39,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"MeinaPastel":{"status":"inactive","modelid":"civitai-27135","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/287c94e0-5129-4b1c-db41-f8cc0b4cad00/width=450/298928.jpeg","description":"<p><strong>MeinaPastel </strong>aims to make illustrations with a <strong>2d feeling</strong> to them with good light, shadows and details, making <strong>pastel</strong> <strong>or colorful</strong> images!<br /><br />I created a <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">discord</a> server where you can post images that you generated, discuss prompt and/or ask for help. <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/meinaverse\">https://discord.gg/meinaverse</a><br /><br /><strong>If you like one of my models and want to support their updates:</strong><br />I have a <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>ko-fi</strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>Patreon</strong></a> page where you can support me or buy me a coffee &lt;3 , <strong>it will be very much appreciated:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>https://ko-fi.com/meina</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>https://www.patreon.com/MeinaMix</strong></a><br /><br /><strong>You may also try my model using</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/xylZzvg\">Sinkin.ai</a>: <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/xylZzvg\">https://sinkin.ai/m/xylZzvg</a><br /><br />---------------------------------------------<br /><strong>Recommendations:</strong><br /><strong>Sampler:</strong> DPM++ 2M Karras: 20 steps.<br /><strong>Resolutions:</strong> 512x768, 512x1024. ( other resolutions may work).<br /><strong>Hires.fix option 1: </strong>Latent, with 10 steps and 0.55 denoising<strong>.</strong><br /><strong>Hires.fix option 2:</strong> R-ESRGAN 4x or +Anime6b, with 15 steps at 0.1 up to 0.3 denoising.<br /><strong>Clip Skip:</strong> 2.<br /><strong>Negatives:</strong> ' (worst quality, low quality:1.4), monochrome, zombie '<br /><br /><strong>Prompt:</strong> ' colorful ' and ' high contrast ' makes the model look more 2d and with colors more vivid.<br />---------------------------------------------</p><p><br />V4 is a merge between v3 with an amazing model created by Yozora: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21200/color-box-model\">color-box-model</a> and animelike2d</p>","ratingcount":54,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Mistoon_Anime":{"status":"inactive","modelid":"civitai-28861","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/426bf1ed-56ae-425c-f521-43f46efe3200/width=450/325561.jpeg","description":"<p><strong>IF YOU ARE NEW TO STABLE DIFFUSION OR YOU HAVE PROBLEMS WITH MY MODELS GO HERE: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.github.io/guide\"><strong>Guide (</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"http://inzaniak.github.io\"><strong>inzaniak.github.io</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.github.io/guide\"><strong>)</strong></a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1a33af8e-dc44-41a4-04ff-6c8b81c03a00/width=525/1a33af8e-dc44-41a4-04ff-6c8b81c03a00\" /><h3>How to use this</h3><p>If you are new to the world of Stable Diffusion, you can learn how to run it by yourself here:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.github.io/guide\"><strong>Guide (</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"http://inzaniak.github.io\"><strong>inzaniak.github.io</strong></a><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.github.io/guide\"><strong>)</strong></a></p><p>You'll also need a VAE to use this. For the examples, I've used the Grapefruit one:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/iZELX1/Grapefruit/resolve/main/Grapefruit.vae.pt\">https://huggingface.co/iZELX1/Grapefruit/resolve/main/Grapefruit.vae.pt</a></p><h3>What's this model</h3><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6bc51c4c-ac13-4f52-fe69-4fa6df1c4600/width=525/6bc51c4c-ac13-4f52-fe69-4fa6df1c4600\" /><p>Mistoon_Anime is my blend of SD models that tries to achieve a more \"cartoony\" anime style with thick borders and brighter colors.</p><p>The starting point for this model was the \"Euclase Blend\". From there, I then added a few of my custom LoRAs in the mix to make it more colorful and with thicker borders.</p><p>An inpainting version is also available.</p><p>There are other variants of this model available, check out my profile!</p><p>Try also the other flavors:</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b1f13e1a-3e56-45a5-5a82-2c5624d81400/width=525/b1f13e1a-3e56-45a5-5a82-2c5624d81400.jpeg\" /><h3>The style</h3><p>It creates realistic and expressive characters with a \"cartoony\" twist. Unlike other anime models that tend to have muted or dark colors, Mistoon_Anime uses bright and vibrant colors to make the characters stand out.</p><p>Mistoon_Anime is ideal for anyone who loves anime and wants to create their own unique style.</p><p>All the examples have been created using this version of the model using the HiRes-Fix. Most of them are created just with a prompt and easynegative as the negative one. Some of them are created, adding a controlnet.</p><p>To generate the pictures I usually use Euler-A with 30 steps and a CFG value between 3-9.</p><p>The model can also easily do NSFW stuff (check the last examples).</p><p></p><h3>Guides</h3><p>Learn how to create pictures like mine with my step-by-step tutorials:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/bd7dbcd5ce4b\">Beginner's Guide</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/35eacb3dc5f4\">Prompting</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/@inzaniak/stable-diffusion-ultimate-guide-pt-3-high-resolution-a4f5d7b60f38\">My Workflow</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://medium.com/p/772ea69472c9\">Inpainting</a></p></li></ul><p></p><h3>Support</h3><p>You can now support me and my work by subscribing to my Deviantart account. You'll also get awesome rewards:</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e2e5484d-44b7-4955-bca7-3796154c8a00/width=525/e2e5484d-44b7-4955-bca7-3796154c8a00.jpeg\" /><p>If you want to support my work for free, you can also check out my music/art here:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://inzaniak.bandcamp.com/\">Bandcamp</a></p></li></ul><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.instagram.com/inzaniak_aiart/\">Instagram</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.deviantart.com/inzaniak\">DeviantArt</a></p></li></ul><p></p>","ratingcount":73,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Grapefruit (hentai model)":{"status":"inactive","modelid":"civitai-29179","rating":4.93,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e1e0d7b0-20f5-49c5-31aa-c295bf855e00/width=450/329636.jpeg","description":"<p><strong>Model page for grapefruit, </strong>grapefruit aims to be a hentai model with a bright, clear and less semirealistic anime style. Model is also good for SFW images.</p><p></p><p>My model that i currently develop further: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583\">https://civitai.com/models/2583</a></p><p>You can support me on my <a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/user?u=27247323&amp;utm_medium=clipboard_copy&amp;utm_source=copyLink&amp;utm_campaign=creatorshare_creator&amp;utm_content=join_link\">patreon</a>, where you can get other models of me. My <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/zSR5FcYWWE\">discord, </a>for everything related to anime models.</p><p></p><p>_____________________________________________________</p><p><strong>Using the model: </strong><u>Use mostly </u><a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/\"><strong><u>danbooru</u></strong></a><u> tags</u>.</p><p>Below V4, you need a extra vae. Only Versions beginning of V4 have vaes backed in. For better promting on it, use this <a target=\"_blank\" rel=\"ugc\" href=\"https://aituts.com/novelai-anime-prompt-techniques/\">LINK</a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://lunarmimi.net/freebies/novelai-anime-girl-prompt-guide/#1basic\">LINK</a>. But instead of {}, use (), <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">stable-diffusion-webui</a> use (). Use \"masterpiece\" and \"best quality\" in positive<u>,</u> <strong><u>\"worst quality\" and \"low quality\" in negative</u></strong>.</p><p>My negative ones are: (worst quality, low quality:1.4) with extra monochrome, signature, text or logo when needed.</p><p>Use a clip skip of 1, 2 or 4 for V3 and V4, for V2 2 or 4. Thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583?modal=commentThread&amp;commentId=14417\"><strong>omnisaa</strong></a> for <a target=\"_blank\" rel=\"ugc\" href=\"https://drive.google.com/drive/folders/1oqQoJzo59hz8_D_CyCK70qqb1KxTfnFH\">testing it out</a>! Clip 2 is better for private parts, img2img and prompt following. Clip 1 is visually better, because i assume, the model has more time and freedom there. I use clip2.</p><p>Don't use face restore and underscores _, type red eyes and not red_eyes.</p><p>Don't go to really high resolutions. Every model, like grapefruit, get lost in the vastness of big images and has a much higher chance to greate, as example, a second anus.</p><p></p><p>Applies only for V2, V3:</p><p>If you don't want a open, spread or gaping pussy, it helps to avoid the word \"pussy\" in your prompts (that applies also on vaginal insertions). Prompt \"nsfw\" can push some things into the right direction and can spice some images up (motion lines, floating hearts, steam, but adds sometimes censoring).</p><p>_____________________________________________________</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/hdgpromptassist#loras\"><strong>Lora</strong></a><strong>: </strong>Every LoRA that is build to function on anyV3 or orangeMixes, works on grapefruit too. Some can be found <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/hdglorarepo\">here</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://gitgud.io/gayshit/makesomefuckingporn#lora-list\">here</a> or on civit by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lottalewds\">lottalewds</a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/fuggy\">, </a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Trauter\">Trauter, </a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Your_computer\">Your_computer</a> or<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/fuggy\"> </a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lykon\">lykon</a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/fuggy\">.</a></p><p>_____________________________________________________</p><p>Merged models for grapefruit are <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/66/anything-v3\">AnythingV3</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hesw23168/SD-Elysium-Model/\">ElysiumV2</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">AbyssOrangeMix</a>, a bit of <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">AbyssOrangeMix2</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix\">basilMix, </a>my own lemon and gape out of anyGape. Lemon is a mix of anyGape and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix\">basilMix</a>.</p><p></p><p>Black result fix (vae bug in web ui): Use --no-half-vae in your command line arguments</p><p></p><p>Contact: <a target=\"_blank\" rel=\"ugc\" href=\"mailto:ikenaaigrapefruit@gmail.com\">ikenaaigrapefruit@gmail.com</a></p>","ratingcount":59,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"526Mix V1.4":{"status":"inactive","modelid":"civitai-34204","rating":4.91,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/4f87ba45-49cc-459d-64ce-0529c75b2a00/width=450/390830.jpeg","description":"<p><strong>Anime / 2D animated-optimized version here: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/35893?modelVersionId=42086\"><strong>https://civitai.com/models/35893?modelVersionId=42086</strong></a></p><p><strong>Surreal / vivid illustration mix: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/44596\"><strong>https://civitai.com/models/44596</strong></a></p><p></p><p>My personal merge of Stable Diffusion 1.5 custom models using the noise offset to improve contrast and dark images. An inpainting model is provided to make inpainting in the model’s styles and detail easier. <strong><em>'Negative' embeddings generally not recommended as they interfere with art styles and aesthetics (unless that's what you want, of course).</em></strong></p><p></p><p>This model is meant to be:</p><ul><li><p>Artistic and elegant</p></li><li><p>Drop-dead easy to work with</p></li><li><p>Good at making cool characters and landscapes</p></li><li><p>Not bound or leaning towards any single style</p></li><li><p>Killer at digital and conventional art in many aesthetics</p></li><li><p>And above all, fun</p></li></ul><p>If your images come out a little crunchy or there's a bright blue/white artifact, turn your step count up a little, and you should be set. <u>I normally use DDIM at 30-35 steps with high resolution optimization ON (essentially img2img upscaling, whatever the equivalent in your UI might be). You'll also want to keep CFG below 10, ideally. Around 6-7 is a good baseline. In InvokeAI, I use 0.45-0.55 high res optimization strength, which is a bit lower than the default. If your results are a bit too sharp or crispy, try making sure your high-res fix strength isn't too high as well.</u></p><p></p><p>It’s not so great at explicit sexual content and anime*, including anime-based embeddings. There’s a million other models for those if that’s what you’re after. Also maybe not the best choice for photorealism, since this model focuses on digital and conventional art. V1.3 and onward have <em>some</em> photorealism capability, but this mix isn't meant to excel at that. You might have fun playing with whosawhatsis' <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10540/verisimilitude\">verisimilitude</a> if you want to make wallpaper-quality photorealistic stuff.<br /><br />*There is some ability to bring out a neat anime aesthetic when you prompt for 'anime style', which I find to be quite cool to look at, although it can be a bit finicky. If you try to make anime-esque art with this model, do not put 'portrait' in your negative prompt, or use 'close' or 'closeup' in your positive prompt, as those seem to force it into a 3d-like style even if you add more weight on the anime style.</p><p></p><p>I also want to shoutout coreco and his <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">seek.art MEGA v2</a>, which was responsible for much of the composition of V1.3-V1.4, and is an excellent update to his Mega model capable of fun and artistic things and realism that this model doesn't (albeit since it's not a mix but a finetune by just one person, it takes more tinkering, but that's okay).</p><p></p><p>This model has a baked-in VAE based on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4\">Waifu Diffusion 1.4</a> by hakurei. You can switch this out (such as to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">vae-ft-mse-840000-ema-pruned</a>) if you wish, though I used that one specifically because it helped improve detail quality in some art styles and situations.</p><p></p><p>Example images were generated in Invoke AI with the model converted to Diffusers format, hires fix on, and the sampler k_dpmpp_2 (unless listed otherwise). This means unless you use Invoke AI, you likely won't be able to recreate my images exactly. Just learn from the prompts and modify the weighting in prompts as needed for the UI you use (if you use the A1111 UI, any (plus sign)+ is equal to one set of parentheses).</p><p></p><p>By downloading, you agree to the creativeml-openrail-m and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md\">Dreamlike-art</a> licenses.</p><p></p><p>Credits (V1.4 / V1.3.5):</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3738/roboetics-mix\">Roboetic’s Mix</a> – Roboetic</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">seek.art MEGA v2</a> – coreco</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1116/rpg\">RPG V4</a> – Anashel</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16371\">HeStyle V1.5</a> - krstive</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8067/movie-diffusion-v12\">Movie Diffusion</a> - Dalle2Pictures</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">Analog Diffusion</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2292/portrait\">Portrait+</a> - wavymulder</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9388/realscifi\">RealSciFi</a> - AIfriend</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Dunkindont/Foto-Assisted-Diffusion-FAD_V0\">Foto-Assisted Diffusion</a> - Dunkindont</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3164/fantasy-art-style\">fantasy-art-style v1.8</a> - kasukanra</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/22h/vintedois-diffusion-v0-2\">Vintedois Diffusion</a> - Predogl and piEsposito</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.crosslabs.org/blog/diffusion-with-offset-noise\">noise offset</a> – Nicholas Guttenberg</p></li></ul>","ratingcount":33,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Realistic Vision V2.0":{"status":"inactive","modelid":"civitai-29460","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/393713d6-c943-4c6a-7247-ad5f03583200/width=450/333323.jpeg","description":"<p><strong><u>Please read this!</u></strong><br />For version 2.0 it is recommended to use with VAE (to improve generation quality and get rid of blue artifacts): <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original\"><strong>https://huggingface.co/stabilityai/sd-vae-ft-mse-original</strong></a><br /><br />This model is available on<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"http://Mage.Space\"><strong>Mage.Space</strong></a><strong>, </strong><a target=\"_blank\" rel=\"ugc\" href=\"http://Sinkin.ai\"><strong>Sinkin.ai</strong></a><strong>, </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://getimg.ai/\"><strong>GetImg.ai</strong></a><strong> </strong>and (<a target=\"_blank\" rel=\"ugc\" href=\"http://RandomSeed.co\"><strong>RandomSeed.co</strong></a><strong> </strong>- NSFW content)<br /><br />Please support my friend's model, he will be happy about it - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16804\"><strong>Life Like Diffusion</strong></a></p><p></p><p>All versions of the model, including <strong><u>Realistic Vision 1.4 (beta)</u></strong> can be found on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SG161222\"><strong>Hugging Face</strong></a><br /></p><p><strong><u>I use this template to get good generation results:</u></strong><br /><br /><strong>Prompt:</strong><br />RAW photo, *subject*, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3<br /><br /><u>Example:</u> RAW photo, a close up portrait photo of 26 y.o woman in wastelander clothes, long haircut, pale skin, slim body, background is city ruins, (high detailed skin:1.2), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3</p><p><br /><strong>Negative Prompt: </strong><br />(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck</p><p></p><p><strong>OR</strong><br /><br />(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation<br /><br /><strong>Euler A</strong> or <strong>DPM++ 2M Karras with 25 steps<br />CFG Scale 3,5 - 7<br />Hires. fix with Latent upscaler<br />0 Hires steps and Denoising strength 0.25-0.45</strong><br /><strong>Upscale by 1.1-2.0</strong><br /><strong>ENSD 31337</strong><br /><br /><strong>Thanks to the creators of these models for their work. Without them it would not have been possible to create this model.</strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\"><strong>HassanBlend 1.5.1.2</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/sdhassan\"><strong>sdhassan</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661/uber-realistic-porn-merge-urpm\"><strong>Uber Realistic Porn Merge (URPM)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/saftle\"><strong>saftle</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3666/protogen-x34-photorealism-official-release\"><strong>Protogen x3.4 (Photorealism)</strong></a><strong> + </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3816/protogen-x53-photorealism-official-release\"><strong>Protogen x5.3 (Photorealism)</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/darkstorm2150\"><strong>darkstorm2150</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3950/art-and-eros-aeros-a-tribute-to-beauty\"><strong>Art &amp; Eros (aEros)</strong></a><strong> + </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1654/realeldenapocalypseanalogsexknoll4candypuresimpfeet\"><strong>RealEldenApocalypse</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/aine_captain\"><strong>aine_captain</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3811/dreamlike-photoreal-20\"><strong>Dreamlike Photoreal 2.0</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/sviasem\"><strong>sviasem</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3758/hasdx\"><strong>HASDX</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/bestjammer\"><strong>bestjammer</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\"><strong>Analog Diffusion</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/wavymulder\"><strong>wavymulder</strong></a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4041/woopwoop-photo\"><strong>WoopWoop-Photo</strong></a><strong> by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/zoidbb\"><strong>zoidbb</strong></a></p>","ratingcount":511,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AnyLoRA - Checkpoint":{"status":"inactive","modelid":"civitai-29792","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5c162e30-f848-41da-b746-c51ccbf0e700/width=450/337388.jpeg","description":"<h1>AnyLoRA</h1><p><strong>Add a ❤️ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><h2><strong>Remember to use the <u>pruned</u> version when training</strong> (less vram and no baked vae).</h2><p>I made this model to ensure my future LoRA training is compatible with newer models, plus to get a model with a style neutral enough to get accurate styles with any style LoRA. Training on this model is much more effective conpared to NAI, so at the end you might want to adjust the weight or offset (I suspect that's because NAI is now much diluted in newer models). I usually find good results at 0.65 weigth that I later offset to 1.</p><p>This is good for inference (again, especially with styles) even if I made it mainly for training. It ended up being super good for generating pics and it's now my go-to anime model. It also eats very little vram.</p><p>The first version I'm uploading is a fp16-pruned with no baked vae, which is less than 2 GB, meaning you can get up to 6 epochs in the same batch on a colab.</p><p>Just make sure you use CLIP skip 2 and booru style tags when training.</p><p>Remember to use a good vae when generating, or images wil look desaturated. I suggest <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\">WD Vae</a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">FT MSE</a>. Or you can use the baked vae version.</p><h2></h2><p></p>","ratingcount":36,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"万象熔炉 | Anything V5":{"status":"inactive","modelid":"civitai-30163","rating":4.88,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/aeda34a6-4db8-4f7e-23fd-c7bac4bcae00/width=450/342218.jpeg","description":"<h2><strong><em>See the introduction before you use it !!!!!</em></strong></h2><h2><strong>使用模型之前请看简介！！！</strong></h2><p>————————————</p><h3><strong>不忠于tag的模型，毫无意义！</strong></h3><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/92151055-c406-44b4-00c8-b0bcdcf56000/width=1024/04894-3388887486-1girl,lake,_(-3-_),short%20hair,flower-shaped%20pupils,sailor,yellow%20theme%20hair,.jpeg\" alt=\"04894-3388887486-1girl,lake,_(-3-_),short hair,flower-shaped pupils,sailor,yellow theme hair,.jpg\" /><p>如果想要如图效果的图，可以看一看另一个模型：</p><p>If you want something like this, try other model：</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/47439/yden-v3-trainfix\">yden V3 TrainFix - yden-T | Stable Diffusion Checkpoint | Civitai</a></p><h2>更新 | Update log</h2><p>Anything系列目前有V1、V2.1、V3、V5四个基础版本，标注RE的版本为修复版，修复了诸如clip等模型方面的问题，Prt是V5版本的特别修剪版，是最推荐使用的版本</p><p>Anything series model currently has four basic versions V1, V2.1, V3 and V5. The version marked with RE is the repair version, which fixes problems with models such as clip. Prt is a special trim version of V5, which is the most recommended version</p><h3>[2023/3/24]</h3><ul><li><p>A3 BF16</p></li><li><p>A3 For-Tachie</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7748fa78-1e8e-4136-7bbd-0f4892313c00/width=525/7748fa78-1e8e-4136-7bbd-0f4892313c00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/deb7cd28-2b5c-45e2-53df-47046d231f00/width=525/deb7cd28-2b5c-45e2-53df-47046d231f00.jpeg\" /></li></ul><h3>[2023/3/26]</h3><ul><li><p>Anything-V5[Prt]</p></li><li><p>AnythingV5放弃了原本的合成方法</p><p>V5 abandoned the original merger method</p></li><li><p>V5模型提示词更准确（可能），但简单提示词的效果并不如V3</p><p>V5 model prompt words are more accurate, but the effect of simple prompt words is not as good as V3 model.</p><p>↓↓↓↓↓↓↓↓↓↓↓</p></li><li><p><strong><em>如果追求单纯的图片好看而不是tag更为听话，请使用V3而不是V5</em></strong></p><p><strong><em>If there is no need to pursue upper limits, use V3 instead of V5</em></strong></p></li><li><p>V5比V3更适合搭配lora使用</p><p>V5 is better with Lora.</p></li></ul><h3>[2023/3/26]</h3><ul><li><p>Clip fix.</p></li><li><p>A5的Clip修复版本</p></li><li><p><strong><em>请使用这个版本的模型！！！</em></strong></p><p><strong><em>Please use this model!!!</em></strong></p></li></ul><h3>[2023/4/2]</h3><ul><li><p>上传了原版的V5模型，实际效果并不如Prt，更比不上Prt-Re</p><p>The original AnythingV5, but not as effective as PRT.</p></li></ul><h3>[2023/4/3]</h3><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/824d8a2c-f3f9-4c72-0063-524004ba8800/width=525/824d8a2c-f3f9-4c72-0063-524004ba8800\" /><ul><li><p>Anything-V3-RE</p></li><li><p>上传了提示词更为准确（可能）的V3重置版本</p><p>The prompt word may be more accurate</p></li></ul><h3>[2023/4/15]</h3><ul><li><p>Anything 2.1[RE]</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7890c7d4-1d3f-4733-215b-e1de5fb48e00/width=525/7890c7d4-1d3f-4733-215b-e1de5fb48e00.jpeg\" /></li><li><p>请不要随意更改本模型VAE，否则会出现饱和度过低的问题</p><p>Do not change this model VAE at will, otherwise the problem of low saturation will occur</p></li><li><p>V2.1和V5一样有着众多的衍生版本，是否分享出来还是看大家的意愿，大家想要我就发出来，不想要就不发了（主要是模型上传时间太长）</p><p>As with V5, there are many derivative versions of V2.1. Whether to share them depends on your will. If you want them, I will send them; if you don't want them, I won't send them (it takes too long to upload the model).</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5c48b8ff-e638-454d-f970-7df2ed8f7b00/width=525/5c48b8ff-e638-454d-f970-7df2ed8f7b00.jpeg\" /></li></ul><h2>说明 | specification</h2><ul><li><p>Anything是纯二次元的模型，不包含任何真人/3D模型或者25D模型</p></li><li><p>Pure quadratic metamodel</p></li><li><p>合成方式：A +0.1B+C+0.1B+D+0.1B+E+0.1B+……</p><p>Merge method:A +0.1B+C+0.1B+D+0.1B+E+0.1B+……</p></li><li><p>这种合并方法是早期不知道原理的产物，出现问题的概率很高，所以这并不是一个合理的合成方法。</p><p>This merge method has a high probability of problems.This is not a reasonable merge method.</p></li><li><p><strong>注意：Anything系列模型不会包含有AOM系列模型</strong></p><p><strong>Attention:Anything does not include AOM models.</strong></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/faa20941-a738-4d2b-a827-2ccc73e59a00/width=525/faa20941-a738-4d2b-a827-2ccc73e59a00\" /></li><li><p>huggingface:<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Linaqruf/anything-v3.0\">Linaqruf/anything-v3.0 · Hugging Face</a></p></li><li><p>[因为我不会英文的缘故，Huggingface上的模型并不是由我本人上传。是由别人经过了我的同意后上传的]</p><p>[It wasn't me who uploaded the model to huggingface, but with my permission because I don't speak any English.]</p></li><li><p><strong><em>[Introduction to using Youdao for translation]</em></strong></p></li></ul><h2>局限性 | Limitations</h2><ul><li><p>请不要把anything-v3的质量看的有多么好，因为本身就是个输入tag毫无忠诚度可言的模型。在发现这点之后我在很长一段时间内没有再融合新的模型，这种性质的融合模型简直就是浪费时间。</p><p>anything-v3は品質が良いと思わないでください入力tag自体が忠誠心のないモデルですからそれを発見してからは、長い間、新しいモデルと融合することはありませんでしたが、この種の融合モデルは時間の無駄でした。</p></li><li><p>Anything-3/2.1本来就是个把当时见到的所有模型一股脑瞎融到一起的的产物，其中Clip/UNET/VAE全都是有问题的，虽说Clip可以修复偏移，但是TE本身也是是有严重的问题的，这会造成测试出来clip并没有偏移，但是tag等依旧出现各种各样的问题。即使修复了clip模型老老实实读取tag了，TE也会影响模型对tag的理解。并且这个是完全没有修复的必要（实际修复操作还不如自己整个新模型）。</p><p>anything- 3/2.1は、最初に見たすべてのモデルをまとめたものです。Clip/UNET/VAEには問題がありました。Clipはオフセットを修正できますが、TEにも深刻な問題がありました。しかし、tagなどではさまざまな問題が出てきます。clipモデルを修正して素直にtagを読み込んでも、teはモデルのtagの理解に影響します。そしてこれは全く修復の必要がありません(実際の修復作業はむしろ自分全体の新しいモデルです)。</p></li><li><p>本以为Anything-v3是下限，但是现在这个下限变成了上限。甚至于说，前段时间出现一个tag和输出图片几乎毫不相干的模型，而且这个模型还有一大堆人去吹捧，然后群里频道一说就“不喜欢就不喜欢，没必要拉踩”。</p><p>anything-v3が下限かと思いきや、今はその下限が上限になっています。さらには、tagとアウトプットイメージがまったく関係ないモデルが出てきて、そのモデルをたくさんの人に褒められて、「気に入らないものは気に入らない。引っぱる必要はない」と言われたこともありました。</p></li><li><p>现在绝大部分融合模型作者根本没有意识到这个问题，甚至连基本的clip都不做处理，随便下载一个xxxMix都是这种情况，更别提Te等方面了：</p><p>ほとんどの融合モデルの作者はこの問題を全く意識していません。基本的なclipすら処理していません。xxxMixをダウンロードしてもそうです。Teなどはもちろんです。</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e4d973c1-6420-41ab-f739-bb9aa9ab8200/width=525/e4d973c1-6420-41ab-f739-bb9aa9ab8200.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9abe198a-38bf-4343-cade-661689f74600/width=525/9abe198a-38bf-4343-cade-661689f74600.jpeg\" /></li><li><p>相同模型不同clip的对照（读取tag能力差距非常大）</p><p>Comparison chart of different clips of the same model:(The ability to read prompts varies greatly)</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6d471862-96e7-43e9-7c24-85c3da035800/width=525/6d471862-96e7-43e9-7c24-85c3da035800.jpeg\" /></li></ul><ul><li><p><strong><em>【这次改了明白点，省的一堆人在群里说我开地图炮。】</em></strong></p></li></ul><p>【使用有道机翻】</p><h2>其他说明 | other</h2><ul><li><p>你可以随意将本模型融合到其他地方，但如果你共享该融合模型，别忘了标注一下</p><p>We allow you to merge with another model, but if you share that merge model, don't forget to add me to the credits.</p></li><li><p>[元素法典]-779</p></li><li><p>Anything系列并没有4.0和4.0版本，请不要通过这个联想到我。我本因为意识到融合模型的种种问题而放弃了angthing3之后的版本制作，没想到会有人搞出来4和4.5版本。</p><p>There is no version 4.0 or 4.0 of Anything series, please don't think of me by that. I was so aware of the problems with the fusion model that I gave up on the post-AngThing3 versions that I didn't expect anyone to come up with versions 4 and 4.5.</p></li><li><p>这是AnythingV3最开始分享的地方：</p><p>Where Anything3.0 was first released:</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1c6bf602-ef2f-4c74-39e2-41dab5241e00/width=525/1c6bf602-ef2f-4c74-39e2-41dab5241e00\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/93c904ea-cf5a-4e24-e6fb-bd7170b5bc00/width=525/93c904ea-cf5a-4e24-e6fb-bd7170b5bc00\" /></li></ul>","ratingcount":130,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Analog Madness - Realistic model":{"status":"inactive","modelid":"civitai-30227","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c33704f4-6e95-4d3d-067c-8328a1e42100/width=450/349123.jpeg","description":"<h1>Check out my new model! <a rel=\"ugc\" href=\"https://civitai.com/models/48694/chronos\">Chronos</a><br /></h1><p>About Analog Madness</p><p>A very versatile model, the more powerfull prompts you give, the better results.</p><p>Capable of creating both NSFW and SFW images but also great scenery,<br />both in landscape and portrait.</p><p></p><p>Example prompt:</p><p><em>hyper realistic gopro action photo of a beautiful 20yo Dutch girl with small breasts (looking at camera:1.3), windy, wearing old trashy worn torn out clothes, in a themepark, analog style, masterpiece, exposed breasts</em></p><p>negative prompt: <br /><em>3d max, grotesque, desaturated</em></p><p><br />tnx to Hoblin for this negative prompt!</p><p>Euler a, 25 to 35 steps, CFG7</p><p></p><p><strong>Disclaimer:</strong><br /><strong>All characters on my images are 18+. No likeness to real people intended. No pixels were hurt during the production of this images.</strong></p>","ratingcount":59,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"BRA(Beautiful Realistic Asians) V3":{"status":"inactive","modelid":"civitai-39685","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d20562d6-4279-43c0-cede-c2edb3b20a00/width=450/439436.jpeg","description":"<p>Latest Version V4 coming soon!! (maybe 1-2 weeks from now for testing)</p><p>(Beta access available for supporters below)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/bankaiplease\">https://ko-fi.com/bankaiplease</a></p><p>Trained on 6000++ pictures of Beautiful Asian women. (some nsfw images included)</p><p>This is the result of around 2 Months of training and failing and training and merging. After a lot of failures and mild successes I have finally come to a point where it is good enough to release to the public.</p><p>Trained mostly on BLIP and WD, so suggest to use similar style prompts.</p><p>This model is hosted online and can be run on the following website.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://randomseed.co/model/18\">https://randomseed.co/model/18</a></p><p>Example:</p><p>Pretty asian in a black swimsuit leaning against a wall</p><p>Korean with long black hair wearing a red shirt and a red polka dot blouse with long black hair</p><p>a woman with long hair and a black top is posing for a picture with her hand on her chin, 1girl, solo, long_hair, looking_at_viewer, brown_hair, simple_background, black_hair, jewelry, earrings, necklace, lips, black_shirt, ring, realistic</p><p>Negative Prompts:<br />use negative TI embeddings as well as (lowres,worst quality) etc</p><p>Feel Free to use this for merges or mixes, just credit.</p><p>Feel Free to add me on discord if you have questions, feedback, requests for improvements or want to ask for commisions or whatever:</p><p>ban kai#7350</p>","ratingcount":30,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"CyberRealistic ":{"status":"inactive","modelid":"civitai-55015","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1c10227c-f15c-401a-d299-e4a30a773100/width=450/595371.jpeg","description":"<p>Introducing my versatile photorealistic model - the result of a rigorous testing process that blends various models to achieve the desired output. While I cannot recall all of the individual components used in its creation, I am immensely satisfied with the end result. This model incorporates several custom elements, adding an extra layer of uniqueness to its output.</p><p>One of the model's key strengths lies in its ability to effectively process textual inversions and LORA, providing accurate and detailed outputs. Additionally, the model requires minimal prompts, making it incredibly user-friendly and accessible.</p><p>VAE recommended: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">sd-vae-ft-mse-original</a>.</p>","ratingcount":80,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Experience":{"status":"inactive","modelid":"civitai-32718","rating":4.94,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/a16f037d-cebf-4181-979b-215cc1951900/width=450/372791.jpeg","description":"<h1>Read Description</h1><p></p><p><strong>Important</strong>: Having multiple models uploaded here on civitai has made it difficult for me to respond to each and every comment. One of the ways I plan on addressing this is via the creation of a pdf guide for each and every model (think of it as the models documentation). This will take a while though. So in the meantime, if you have any questions or feedback - </p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.com/channels/1010980909568245801/1073440375336882186\"><strong>visit my thread of the Unstable Diffusion Discord</strong></a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/591685f4-1d06-403b-8132-4115b769a600/width=525/591685f4-1d06-403b-8132-4115b769a600.jpeg\" /><p></p><h1><strong>Check the versions bellow</strong></h1><p>With the release of Experience v7.0, there is now a second version you may be interested in; <u>Realistic Experience</u></p><p></p><h2>Version Selection</h2><p><strong>Experience 8</strong></p><ul><li><p>Includes Noise Offset training</p><ul><li><p>Darker images</p></li><li><p>Improved contrast</p></li><li><p>Read more here - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.crosslabs.org/blog/diffusion-with-offset-noise\">https://www.crosslabs.org/blog/diffusion-with-offset-noise</a></p></li></ul></li><li><p>Requires slightly different prompting than v7.0</p></li><li><p>Best for cinematic/dramatic generations.</p></li><li><p>Is capable of very high fidelity generations</p></li></ul><p><strong>Experience 7.5</strong></p><ul><li><p>Does <strong>not</strong> include Noise Offset training</p></li><li><p>Traditional update to v7.0</p></li></ul><p><strong>Realistic Experience</strong></p><ul><li><p>This version of the model was fine tuned for more photorealistic generations.</p></li><li><p>Realistic Experience <strong>2</strong> is fine tuned from v8.0</p><ul><li><p>Includes Noise Offset</p></li></ul></li><li><p>Realistic Experience was fine tuned from v7.0</p><ul><li><p>Initial Release</p></li><li><p>Does not include Noise Offset</p></li></ul></li></ul><p></p><p><strong>Note</strong>: A full prompt guide and more detailed explanation between the two models is being worked on. For now, since everyone has different tastes - it's best to look at the sample images and choose which model best suits your taste. All previous versions of the model will remain up, so if you liked a previous release it will still be available to download.</p><p></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/n59dx\">Note about Clipfix in v6.5</a></p><p></p><p><strong><u>Merged Models</u></strong></p><p>A list of merged models can be found bellow in the description of the attached model version.</p><p></p><p><strong><u>Capabilities</u></strong></p><ul><li><p>NSFW Photography</p><ul><li><p>SFW Photography is also possible, see \"<strong>Trigger Words</strong>\" bellow.</p></li></ul></li><li><p>Photorealistic 3D renders</p></li><li><p>human anatomy</p></li><li><p>Stylized images</p></li><li><p>Landscapes</p></li><li><p>Concept Art</p></li><li><p>Album Art</p></li><li><p>ect.. This is more of a general purpose model</p></li></ul><p></p><p><strong><u>Limitations</u></strong></p><ul><li><p><s>Anime, Although you can give it a try!</s></p></li></ul><p>Anime is now possible, although this was not the focus of the model. For a focused 3d render/anime model see, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21952/eris\">Eris</a></p><p></p><p><strong><u>Trigger Words</u></strong></p><p>I'm not aware of any trigger words that have drastic influence on the generation process.</p><p>However, tags such as:</p><p><code>\"3d render\", \"cartoon\" | \"nsfw\", \"sfw\", \"nudity\", and \"erotica\"</code></p><p>tend to add push the generation (to some degree) in one direction or another. For example, putting <code>sfw</code> in your prompt and <code>nsfw</code> in your negative prompt <em>should</em> push the generation to produce a SFW image.</p><p></p><p><strong><u>Changelog</u></strong></p><p><em>3-31-23 </em>: Uploaded Experience 8, Experience 7.5, and Realistic Experience 2</p><p><em>4-1-23</em> : Added .ckpt versions of Experience 8 and Realistic Experience 2</p><p></p><p><strong><u>Link(s) to my other models</u></strong></p><ul><li><p>Eris - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21952/eris\">https://civitai.com/models/21952/eris</a></p></li></ul><ul><li><p>Project AIO - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18428/project-aio\">https://civitai.com/models/18428/project-aio</a></p></li></ul><ul><li><p>WonderMix - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15666/wondermix\">https://civitai.com/models/15666/wondermix</a></p></li></ul><ul><li><p>Refined - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8392/refined\">https://civitai.com/models/8392/refined</a></p></li><li><p>Elegance - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5564/elegance\">https://civitai.com/models/5564/elegance</a></p></li></ul><ul><li><p>Clarity - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5062/clarity\">https://civitai.com/models/5062/clarity</a></p></li><li><p>VisionGen - Realism -<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4834/visiongen-realism\">https://civitai.com/models/4834/visiongen-realism</a></p></li></ul><p></p><p><strong><u>LoRA</u></strong></p><ul><li><p>Pant Pull Down - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11126/pant-pull-down-lora\">https://civitai.com/models/11126/pant-pull-down-lora</a></p></li></ul><p><em>If you made this far, Thanks!</em></p>","ratingcount":106,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"henmix_real":{"status":"inactive","modelid":"civitai-54044","rating":4.94,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/35ebd675-4749-49d2-0d45-7f3d8c69ee00/width=450/584136.jpeg","description":"<p>04-24</p><p>This version has changed mixing ratios compared to the previous v2.2 and includes some experimental attempts. As always, extensive testing has not been conducted.</p><p></p><p><s>I uploaded the pruned version separately, but it is currently downloading only the full version maybe there is a problem with Civitai. I will solve the problem and upload the pruned version within the 25th</s></p><p></p><p>Upload pruned model finished</p><p></p><p>04-10</p><p>I attempted to improve the skin tones and lighting and shadows, which were previously awkward. I have noticed a difference in the image, but I have not had the opportunity to thoroughly test the changes due to my limited skills.</p><p></p><p><strong>VAE</strong> : vae-ft-mse-840000-ema-pruned</p><p></p><p>Steps: 50, Sampler: DPM++ SDE Karras, CFG scale: 20, Size: 512x768, Model hash: a8907e32c0, Denoising strength: 0.35, Clip skip: 2, Hires upscale: 2, Hires steps: 20, Hires upscaler: R-ESRGAN 4x+, Dynamic thresholding enabled: True, Mimic scale: 10, Threshold percentile: 99.95, Mimic mode: Cosine Up, Mimic scale minimum: 0, CFG mode: Half Cosine Down, CFG scale minimum: 15, Eta: 0.2, DDetailer prompt: \"\", DDetailer neg prompt: \"\", DDetailer model a: \"bbox\\mmdet_anime-face_yolov3.pth [51e1af4a]\", DDetailer conf a: 30, DDetailer dilation a: 4, DDetailer offset x a: 0, DDetailer offset y a: 0, DDetailer preprocess b: False, DDetailer bitwise: None, DDetailer model b: \"None\", DDetailer conf b: 30, DDetailer dilation b: 4, DDetailer offset x b: 0, DDetailer offset y b: 0, DDetailer mask blur: 4, DDetailer denoising: 0.35, DDetailer inpaint full: True, DDetailer inpaint padding: 32, DDetailer cfg: 11</p><p></p><p></p><p>04-01</p><p>As always, I didn't conduct many tests. However, I did notice a slight improvement in prompt recognition.</p><p>I'm not entirely certain if it's an actual upgrade from the v1 version or not.<br /></p><p>Steps: 40</p><p>Sampler: DPM++ SDE Karras</p><p>CFG scale: 20</p><p></p><p>HIRES. FIX</p><p>R-ESRGAN 4X+</p><p>STEP : 20</p><p>DENOISING : 0.35</p><p>UPSCALE : 2</p><p></p><p>Dynamic Thresholding </p><p>MIMIC CFG SCALE : 10</p><p>PERCENTILE : 99.95 OR 99.9</p><p>MIMIC SCHEDULER : COSINE UP</p><p>MINIMUM VALUE OF MIMIC : 0</p><p>CFG SCHEDULER : HALF COSINE UP</p><p>MINIMUM VALUE OF CFG : 0</p><p></p><p>Ddetailer</p><p>bbox\\mmdet_anime-face_yolov3.pth</p><p>Denoising strength(Inpaint) : 0.35</p><p>Mimic CFG Scale : 15 (custom ddetailer setting)</p><p>----------------------------------------------------------------------------------</p><p></p><p>03-17</p><p>I have updated the model with the extension \"safetensors\" upon the request of someone else, while keeping it the same as the existing model.</p><p>----------------------------------------------------------------------------------</p><p></p><p>This is a realistic model that I personally merged.<br />There is limited information due to a small number of tests conducted.</p><p></p><p>This is an example of a prompt used</p><p>ultra realistic details, sharp focus, detailed skin, (21 years old pretty korean girl:1.2), (kpop idol:1.2), (korean beauty:0.8), (korean mixed),</p><p>(large breasts),</p><p>Negative prompt: Drawings, abstract art, cartoons, surrealist painting, conceptual drawing, graphics, (low resolution:1.4), (blurry:1.3), (strabismus:1.1),</p><p>(worst quality:1.3), (low quality:1.3), (thick thighs:1.2), collage, (makeup:0.8), nsfw, bad proportions, earings, floral print, loli, big eyes, (watermark:1.2), letter, (abs:1.2),</p><p></p><p>Steps: 40, Sampler: DPM++ SDE Karras, CFG scale: 7.5, Seed: 3203463706, Size: 768x512, Model hash: 1d8d6e1204, Denoising strength: 0.35, Clip skip: 2, Eta: 0.2</p><p></p><p>HIRES. FIX</p><p>R-ESRGAN 4X+</p><p>STEP : 20</p><p>DENOISING : 0.35</p><p>UPSCALE : 2</p><p></p><p>Dynamic Thresholding </p><p>CFG : 20</p><p>MIMIC CFG SCALE : 5</p><p>PERCENTILE : 99.95 OR 99.9</p><p>MIMIC SCHEDULER : COSINE UP</p><p>MINIMUM VALUE OF MIMIC : 0</p><p>CFG SCHEDULER : HALF COSINE DOWN</p><p>MINIMUM VALUE OF CFG : 10</p>","ratingcount":70,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Clarity":{"status":"inactive","modelid":"civitai-34070","rating":4.96,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d6154284-9159-454f-8664-f6b801d3ba00/width=450/389054.jpeg","description":"<h1>Read Description</h1><p></p><p><strong>Important</strong>: Having multiple models uploaded here on civitai has made it difficult for me to respond to each and every comment. One of the ways I plan on addressing this is via the creation of a pdf guide for each and every model (think of it as the models documentation). This will take a while though. So in the meantime, if you have any questions or feedback -</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://discord.com/channels/1010980909568245801/1073440375336882186\"><strong>visit my thread of the Unstable Diffusion Discord</strong></a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/21f276a8-c67d-4d42-6a9c-cbbdc23ba800/width=525/21f276a8-c67d-4d42-6a9c-cbbdc23ba800.jpeg\" /><p><strong><u>VAE NOT REQUIRED BUT RECOMENDED</u></strong></p><p>VAE is recommended - <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main</a></p><p></p><p>File Structure for AUTOMATIC1111-webui :</p><p>|──sd</p><p>|____|──stable-diffusion-webui</p><p>|____|____|──models</p><p>|____|____|____|──VAE</p><p>|____|____|____|____|──&lt;Put your VAE file here&gt;</p><p></p><p><strong><u>Merged Models</u></strong></p><p>A list of merged models can be found bellow in the description of the attached model version.</p><p></p><p><strong><u>Capabilities</u></strong></p><ul><li><p>NSFW Photography</p><ul><li><p>SFW Photography is also possible, see \"<strong>Trigger Words</strong>\" bellow.</p></li></ul></li><li><p>Photorealistic 3D renders</p></li><li><p>Emphasis on human anatomy</p></li></ul><p></p><p><strong><u>Trigger Words</u></strong></p><p>This checkpoint does not contain any trigger words.</p><p><strong>However</strong>, placing some tags at the beginning of the prompts can heavily influence the generation.</p><p>These tags include:</p><p>\"nsfw\", \"sfw\", \"erotica\", and \"nudity\" | \"3d render\", \"cartoon\"</p><p><strong>Note</strong>: For SFW generation, try adding <code>sfw</code> to your prompt and <code>nsfw</code> to your negative prompt. For NSFW generation, try adding either <code>nsfw</code>, <code>erotica</code>, or <code>nudity</code> to your prompt and <code>sfw</code> to your negative prompt. In general, this is more useful for generating sfw images. This concept also applies to <code>3rd render</code> and <code>cartoon</code>. I recommend leaving <code>3rd render</code> and <code>cartoon</code> both in your negative prompt for generating photographic images.</p><p></p><p><strong><u>Basic Prompt Guide</u></strong></p><p>This model heavily revolves around UnstablePhotorealv.5. This means that you can the tagging system for PhotoReal, although I would recommend using a combination of the PhotoReal comma system and more natural language prompting.</p><p>Guide to prompting with PhotoReal - <a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit#heading=h.3znysh7\">https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit#heading=h.3znysh7</a></p><p></p><p><strong>Example prompt using commas and natural language</strong>:</p><p><u>Positive</u></p><p><code>A Professional Full Body Photo, of a beautiful young woman, clothed, standing indoors, Caucasian, toned physique, strawberry red hair, neutral expression</code></p><p><u>Negative</u></p><p>I recommend something simple like, <code>deformed, bad anatomy, disfigured, missing limb, floating limbs, twisted, blurry, fused fingers, long neck, words, logo, text, mutated hands, mutated fingers</code></p><p>Modify as needed. For example, adding <code>3d render, cartoon</code> to your negative prompt will help generate photographic images.</p><p></p><p>The prompts for this model are fairly flexible, experiment to find out what works best for you.</p><p></p><p><strong><u>Link(s) to my other models</u></strong></p><ul><li><p>Eris - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/21952/eris\">https://civitai.com/models/21952/eris</a></p></li></ul><ul><li><p>Project AIO - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18428/project-aio\">https://civitai.com/models/18428/project-aio</a></p></li></ul><ul><li><p>WonderMix - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15666/wondermix\">https://civitai.com/models/15666/wondermix</a></p></li></ul><ul><li><p>Refined - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8392/refined\">https://civitai.com/models/8392/refined</a></p></li><li><p>Experience - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5952/experience\">https://civitai.com/models/5952/experience</a></p></li><li><p>Elegance - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5564/elegance\">https://civitai.com/models/5564/elegance</a></p></li><li><p>VisionGen - Realism -<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4834/visiongen-realism\">https://civitai.com/models/4834/visiongen-realism</a></p></li></ul><p></p><p><strong><u>LoRA</u></strong></p><ul><li><p>Pant Pull Down - <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/11126/pant-pull-down-lora\">https://civitai.com/models/11126/pant-pull-down-lora</a></p></li></ul>","ratingcount":125,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"CarDos Animated":{"status":"inactive","modelid":"civitai-36247","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1198edef-dadb-4a88-4d24-34b0cb6b4800/width=450/423987.jpeg","description":"<p>Mix of <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18569/cartoonish\">Cartoonish</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6250/dosmix\">DosMix</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">ReV Animated</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/17449/level4\">Level4</a>.</p><p>Very versatile, can do all sorts of different generations, not just cute girls. But it does cute girls exceptionally well.<br /></p><p></p><p>Using <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-ema-original/blob/main/vae-ft-ema-560000-ema-pruned.safetensors\">vae-ft-ema-560000-ema-pruned</a> as the VAE. CLIP 1 for v1.0. CLIP 2 for v2.0.</p><p>Negative embeddings used in almost all images: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative/tree/main\">easynegative</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/yesyeahvh/bad-hands-5/tree/main\">bad-hands-5</a><br /></p><p><br />Also check out my other mix, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/25399/cardos-anime\">CarDos Anime</a>!</p>","ratingcount":56,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Hassaku (hentai model)":{"status":"inactive","modelid":"civitai-37521","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/67ad471b-4fbe-433f-3a27-a3c0ad590600/width=450/423823.jpeg","description":"<p><strong>Hassaku</strong> aims to be a model with a bright, clear anime style. Model focus are nsfw images, but also with a high emphasis for good looking sfw images as well. My previous model grapefruit can be found <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/24383\">here</a>. My <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/zSR5FcYWWE\">discord</a>, for everything related to anime models.</p><p><strong><u>Sponsors:</u></strong><br /><a target=\"_blank\" rel=\"ugc\" href=\"http://AnimeMaker.ai\"><strong>AnimeMaker.ai</strong></a> is a proud sponsor of hassaku, preinstalled with 300 LoRAs &amp; 100+ full NSFW models. Render fast from ANY device. Join their community at <a target=\"_blank\" rel=\"ugc\" href=\"https://animemaker.ai/\">https://animemaker.ai/</a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/77676ade-99a6-4458-38bd-bc8e5fd8b400/width=525/77676ade-99a6-4458-38bd-bc8e5fd8b400.jpeg\" /><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\"><strong>Mage.space</strong></a> with its amazing<strong> </strong>creators program supports all kinds of creators like me! Preinstalled with 50+ high quality models, join their discord community <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/vazvge4vHf\"><strong>here!</strong></a></p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/751db691-f746-490a-9e8c-a246aca9d900/width=525/751db691-f746-490a-9e8c-a246aca9d900\" /><p><strong><u>Supporters:</u></strong></p><p>Thanks to my supporters <strong>Riyu</strong> and <strong>Alessandro</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/user?u=29825078\"> </a>on my patreon!</p><p>You can support me on my <a target=\"_blank\" rel=\"ugc\" href=\"https://patreon.com/user?u=27247323&amp;utm_medium=clipboard_copy&amp;utm_source=copyLink&amp;utm_campaign=creatorshare_creator&amp;utm_content=join_link\">patreon</a>, where you can get other models of me and early access to hassaku versions.</p><p>_____________________________________________________</p><p><strong><u>Using the model:</u></strong></p><p>Use mostly <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/\"><strong>danbooru</strong></a> tags. No extra vae needed. For better promting on it, use this <a target=\"_blank\" rel=\"ugc\" href=\"https://aituts.com/novelai-anime-prompt-techniques/\">LINK</a> or <a target=\"_blank\" rel=\"ugc\" href=\"https://lunarmimi.net/freebies/novelai-anime-girl-prompt-guide/#1basic\">LINK</a>. But instead of {}, use (), <a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/AUTOMATIC1111/stable-diffusion-webui\">stable-diffusion-webui</a> use (). Use \"masterpiece\" and \"best quality\" in positive<u>,</u> <strong><u>\"worst quality\" and \"low quality\" in negative</u></strong>.</p><p>My negative ones are: (low quality, worst quality:1.4) with extra monochrome, signature, text or logo when needed.</p><p>Use a clip skip 1 or 2. Clip 2 is better for private parts, img2img and prompt following. Clip 1 is visually better, because i assume, the model has more time and freedom there. I use clip2.</p><p><strong><u>Don't use face restore</u></strong> and underscores _, type red eyes and not red_eyes.</p><p>Don't go to really high resolutions. Every model, like hassaku, get lost in the vastness of big images and has a much higher chance to greate, as example, a second anus.</p><p>_____________________________________________________</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/hdgpromptassist#loras\"><strong><u>Loras</u></strong></a><strong><u>:</u></strong></p><p>Every LoRA that is build to function on anyV3 or orangeMixes, works on hassaku too. Some can be found <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/hdglorarepo\">here</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://gitgud.io/gayshit/makesomefuckingporn#lora-list\">here</a> or on civit by <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lottalewds\">lottalewds</a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/fuggy\">, </a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Trauter\">Trauter, </a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Your_computer\">Your_computer</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/ekune\">ekune</a> or<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/fuggy\"> </a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/lykon\">lykon</a><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/fuggy\">.</a></p><p>_____________________________________________________</p><p>Base model for hassaku where <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/66/anything-v3\">AnythingV3</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hesw23168/SD-Elysium-Model/\">ElysiumV2</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">AbyssOrangeMix</a>, a bit of <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">AbyssOrangeMix2</a>, <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix\">basilMix.</a></p><p></p><p>Black result fix (vae bug in web ui): Use --no-half-vae in your command line arguments</p><p></p><p>I use a Eta noise seed delta of 31337 or 0, with a clip skip of 2 for the example images. Model quality mostly proved with sampler DDIM and DPM++ SDE Karras. I love DDIM the most (because it is the fastest).</p>","ratingcount":139,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"A-Zovya RPG Artist Tools":{"status":"inactive","modelid":"civitai-38589","rating":4.94,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bfe8f5fc-337e-4a0f-4199-edc491bfe500/width=450/426947.jpeg","description":"<p>Depending on what you need, several models are included. If you want the best pretty girl portraits, you must have the SD 1.5 models for sure. If you need more details and better coherency on non-human objects, or you like to have hands with only 5 fingers, use the SD 2.1 models. Mix and match and use inpainting to touch up little mistakes.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/34192/ultra-sharp-high-contrast-tutorial-vaeandupscaler\"><strong>Detailed tutorial on how I get the results in the preview images.</strong></a><br />Check here if you're having trouble getting the same results.</p><p></p><p>You can prompt any style you need with these models, but the default aesthetic is listed for each of the models in this handy list.</p><p><br /><u>Different models available, check the blue tabs above the images up top:</u></p><p><u>Stable Diffusion 1.5 (512) versions:</u></p><ul><li><p><strong><u>V2</u></strong> <em>Stronger painterly style. Higher contrast and sharpness. More RPG knowledge.</em></p></li><li><p><strong><u>V2 offset</u></strong> <em>Noise Offset added making more contrast and bringing the model back to photoreal.</em></p></li><li><p><strong><u>V2 Art</u></strong> <em>Trained model. Very artsy. Strongest painterly style. Less details and bigger brush strokes to mimic digital painting style pre-AI.</em></p></li><li><p><strong><u>V2 inpaint</u></strong> <em>Inpainting version of V2 that's good for outpainting.</em></p></li><li><p><strong><u>V1</u></strong> <em>Smoother renders with least painterly effect.</em></p></li><li><p><strong><u>V1 inpaint</u></strong> <em>Inpainting version of V1 that's good for outpainting.</em></p></li></ul><p><br /><u>Stable Diffusion 2.1 (768) versions:</u></p><ul><li><p><strong><u>SD 2.1 768 V1</u></strong> <em>Strong painterly style, very coherent with hands and objects. Higher native resolution and detail. Not good for nudity.</em></p></li></ul><p></p><p><em>Not as effective, but here's the LoRA if you like to use that instead:</em><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8951/a-to-zovya-rpg-artists-tools-lora\"><strong>A to Zovya RPG Artist's Tools LoRA</strong></a><br /><br />Do you have requests? I've been putting in many more hours lately with this. That's my problem, not yours. But if you'd like to tip me, buy me a beer. Beer encourages me to ignore work and make AI models instead. Tip and make a request. I'll give it a shot if I can. <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/zovya\">Here at Ko-Fi</a></p>","ratingcount":89,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"fantasticmix":{"status":"inactive","modelid":"civitai-39725","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/56e5800f-2fa5-4397-3f44-8ae32c917500/width=450/439960.jpeg","description":"<p>It's a model that was created by merging it with the hope that it will come out beautiful even with a small prompt.</p><p></p><p>↓↓↓ Realistic version has been released ↓↓↓</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/22402/fantasticmixreal\">https://civitai.com/models/22402/fantasticmixreal</a></p><p></p><p>An example is using dynamic thresholding. Reduce the CFG scale to 7 to 10 when not in use</p><p></p><p><strong>VAE</strong> : vae-ft-mse-840000-ema-pruned</p><p></p><p><strong>Recommended Prompt</strong></p><p>(masterpiece), best quality, absurdres</p><p></p><p><strong>Negative Prompt</strong></p><p>paintings, sketches,<strong> </strong>(worst quality, low quality, normal quality:1.5~1.8), lowres, ((monochrome)), ((grayscale)), (blurry), strabismus, (wrong finger),</p>","ratingcount":34,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"fantasticmix_real":{"status":"inactive","modelid":"civitai-39880","rating":4.81,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/60f70a04-59e8-496d-e139-495a3495b900/width=450/441840.jpeg","description":"<p>It's a realistic version of the fantasticmix</p><p>↓↓↓ fantasticmix ↓↓↓</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/20632/fantasticmix\">https://civitai.com/models/20632/fantasticmix</a></p><p></p><p>An example is using dynamic thresholding. Reduce the CFG scale to 7 to 10 when not in use</p><p></p><p><strong>VAE</strong> : vae-ft-mse-840000-ema-pruned</p><p></p><p><strong>↓↓↓ V2.0 ↓↓↓</strong></p><p>I have improved and stabilized the quality.</p><p>And there's a change in the face.</p><p></p><p><strong>Recommended Prompt</strong></p><p>(masterpiece), (best quality:1.2), absurdres</p><p><strong>Negative Prompt</strong></p><p>paintings, sketches, (worst quality, low quality, normal quality:1.3~1.5), lowres, blurry, text, logo, ((monochrome)), ((grayscale)),</p><p></p><p><strong>↓↓↓ V1.0 ↓↓↓</strong></p><p><strong>Recommended Prompt</strong></p><p>(masterpiece), best quality, ultra high res</p><p><strong>Negative Prompt</strong></p><p>paintings, sketches, (worst quality, low quality, normal quality:1.7~2), lowres, blurry, text, logo, ((monochrome)), ((grayscale)),</p>","ratingcount":62,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Protogen v2.2 (Anime) Official Release":{"status":"inactive","modelid":"civitai-4007","rating":4.87,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1e0853cf-2201-4c9e-4b67-44495e7fb100/width=450/25063.jpeg","description":"<h3>Research Model - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">How to Build Protogen</a></h3><p>By Downloading you agree to the<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/CompVis/stable-diffusion-license\">CreativeML Open RAIL-M</a><br />Running on Apple Silicon devices ? <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreml/coreml-Protogen\">Try this instead</a><br />Trigger words are available for the hassan1.4 and f222, might have to google them :)</p><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/darkstorm2150/protogen-web-ui\"><strong>Live Demo at Available on Hugging Face</strong></a></h3><p><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://preview.redd.it/et9c6e3bsoda1.jpeg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=aa2049832da52e4e650e847e023147629e7faf40\"><strong>Model Weights</strong></a> thanks to reddit user <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/user/jonesaid\">u/jonesaid</a><br /></p><p>This is a cocktail mix of everything, mostly accurate for hands and skin texture, Enjoy!<br /><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.studiobinder.com/blog/ultimate-guide-to-camera-shots/\"><strong>Comprehensive guide to camera control</strong></a><strong><br /></strong></p><p>Using the tag \"modelshoot style\" can center the image on the intended subject.</p><h3>By downloading you agree to any licenses listed below.</h3><p>Models used</p><ul><li><p>f222_v1.ckpt</p></li><li><p>elldrethSLucidMix_V10.cpkt</p></li><li><p>hassanBlendAllVersio_hassanBlend14.ckpt</p></li><li><p>seek_art_mega_v1.ckpt (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">license</a>)</p></li><li><p>modelshoot-1.0.ckpt</p></li></ul><p></p><p>Fun Camera Prompt Commands by MC Mic</p><pre><code>(from_above:1.3), (from_below:1.3),(from_side:1.3),(from_behind:1.3),</code></pre><p>Movement Control</p><pre><code>(hand_on_hip:1.2), (sitting:1.2),</code></pre>","ratingcount":128,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"啥玩意完犊子（大概是一种古早画风）- old fish":{"status":"inactive","modelid":"civitai-40101","rating":4.93,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/8ed0f28c-dcd3-405b-d09e-3dd6a5ee3d00/width=450/443847.jpeg","description":"<p>太懒了不想写介绍</p><p>“啥玩意完犊子”</p><p>在一次分层融合的实验中出了一个问题，原本以为是实验事故，没想到得到了这个模型</p><p></p><p>我不知道这属于哪种风格</p><p></p><p>推荐参数</p><p>Steps: 10, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 2316919499, Size: 512x640, Denoising strength: 0.5, Clip skip: 2, Hires upscale: 2, Hires steps: 10, Hires upscaler: R-ESRGAN 4x+</p><p></p><p>ღ( ´･ᴗ･` )比心</p><p>以下机翻</p><p></p><p>In a hierarchical fusion experiment, there was a problem, originally thought to be an experimental accident, but did not expect to get this model</p><p>I don't know what style it is</p><p>Recommended parameter</p><p>Steps: 10, Sampler: DPM++ 2S a Karras, CFG scale: 7, Seed: 2316919499, Size: 512x640, Denoising strength: 0.5, Clip skip: 2, Hires upscale: 2, Hires steps: 10, Hires upscaler: R-ESRGAN 4x+</p>","ratingcount":76,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Protogen x3.4 (Photorealism) Official Release":{"status":"inactive","modelid":"civitai-4048","rating":4.78,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/2d37f24e-f9fd-4900-29b7-e9d9548ce100/width=450/25380.jpeg","description":"<p>Research Model - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">How to Build Protogen</a><br /><strong>ProtoGen_X3.4 - Enbrace the ugly, if you dare...</strong><br />By Downloading you agree to the<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreco/seek.art_MEGA/blob/main/LICENSE.txt\">Seek Art Mega License</a><strong>, </strong>and the<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/CompVis/stable-diffusion-license\">CreativeML Open RAIL-M</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://preview.redd.it/et9c6e3bsoda1.jpeg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=aa2049832da52e4e650e847e023147629e7faf40\"><strong>Model Weights</strong></a> thanks to reddit user <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/user/jonesaid\">u/jonesaid</a><br />Running on Apple Silicon devices ? <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreml/coreml-Protogen\">Try this instead</a><br />Trigger words are available for the hassan1.4 and f222, might have to google them :)<br /></p><p>Seriously, removing off (ugly) on negative prompts brings out some really detailed shots of what real life consist of, decay, rubble, grass, worned clothing...Have fun and keep it fluffy!</p><p></p><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/darkstorm2150/protogen-web-ui\"><strong>Live Demo at Available on Hugging Face</strong></a></h3><p><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.studiobinder.com/blog/ultimate-guide-to-camera-shots/\"><strong>Comprehensive guide to camera control</strong></a><strong><br /></strong></p><p>This is Protogen_v2.2 with 5% of the following</p><ul><li><p>roboDiffusion_v1.ckpt</p></li><li><p>openjourney-v2-unpruned.ckpt</p></li><li><p>analog-diffusion-1.0.ckpt</p></li><li><p>rpg_v2Beta.ckpt</p></li></ul><p></p><p>The result is Photorealism, with RPG elements, Scifi, and some creative flow from OpenJourney model.</p><p></p><p>Let me know how are the outputs on <strong>The Dicussion Below</strong>, and I will continue to release more models based on the feedback...Enjoy!</p><p></p>","ratingcount":113,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"UnstableInkDream":{"status":"inactive","modelid":"civitai-40626","rating":4.81,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ee0cd878-ee06-4d1e-9b01-918eeb628d00/width=450/449992.jpeg","description":"<h1>7.5 </h1><p>the  April version of unstableinkdream</p><p>Because it is impossible to combine animation and reality, after 7.5 it will be split into three genres - balance/anime/photoreal</p><p></p><h3>7.5-balance</h3><p>photo anime , movie,manga, photorealism 2D,2.5D,3D</p><p>All can do well</p><p>Just Try it</p><h3>7.5-photoreal version</h3><p>This is a very realistic model for photorealism and hyperrealism ,and is also a bit naughty</p><p></p><h3>V7.5-Anime</h3><p>This is a very well in manga,anime....etc</p><p></p><p></p><p></p><h3>V7.3</h3><p>Using the MBW plug-in to remerge the model more detaile and style photoreal</p><p></p><h3>V7.0</h3><p>Not uploaded for a long time<br />Using the auto-MBW plug-in to remerge the model<br /><br />Compared to V6 this is a more realistic model, but if the prompts are used properly it can also be used to produce anime.<br /><br />To be honest, the pure models have not improved much since mid-January, most of the models are already adequate, controlling the network and LORA is more important.<br /><br />The example is a quick draw of 45 cards using wildcrd and dynamicprompts, selected at random.<br /><br />Why is it a lot of fantasy WAIFU style? I like it ...... But the other styles actually look ok too</p><p><br />I'll leave it to you to try it out</p><p></p><h3>V6</h3><p>Reconstruction the model to make the prompts itself can be used to create a variety of styles including realistic photos, realistic drawings, and animations like last three fig</p><p>model tag like : nvinkpunk,kuvshinov,dreamlikeart,samdoesart and modelshoot style analog style</p><p>will effective</p><p>and normal tag like : unreal engin 5,octane render, limited palette flat color,Hyperrealism,Photorealism photorealistic also worked well</p><p>some negative prompt was come from civitai and huggingface google can find it</p><p></p><p></p><p>V5photoreal- updated</p><p>To be honest, I'm sorry, this should come out together with yesterday's V5, one is more towards animation and the other more towards reality<br /><br />But has not been adjusted very satisfactory, the effect is actually a bit close to V4</p><p>If you want to be more photo-realistic, please add (photorealistic) at the begin , and real person's name will effect</p><p>If you want to favor animation, please add (nvinkpunk,kuvshinov,dreamlikeart,samdoesart,modelshoot style,) at the end.........not only anime style but girls jump out lol</p><p></p><p>V5 updated</p><p>Enhances cartoonish and stylized intensity with better mastery of the face</p><p>model tag like : nvinkpunk,kuvshinov,dreamlikeart,samdoesart and modelshoot style will effective</p><p>and normal tag like : unreal engin 5,octane render, limited palette flat color,Hyperrealism,Photorealism also worked well</p><p>need nsfw in nagtive prompts</p><p></p><p>V4 updated</p><p>Dont ask me where are v2 or v3,mix a lot of model ,v4 is the best one</p><p>mix by V1,RPG,Protogen,dreamlikesamkuvshinov,inkpunk.......</p><p>model tag like : nvinkpunk,kuvshinov,dreamlikeart,samdoesart and modelshoot style will effective</p><p>and normal tag like : unreal engin 5,octane render, limited palette flat color,Hyperrealism,Photorealism also worked well</p><p></p><p>UnstableSamInkDream Diffusion</p><p>Combined from the following models</p><p>A:Unstable PhotoReal v0.5</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/zhg18s/unstable_diffusion_here_were_excited_to_announce/\">https://www.reddit.com/r/StableDiffusion/comments/zhg18s/unstable_diffusion_here_were_excited_to_announce/</a></p><p>B:inkpunk</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Envvi/Inkpunk-Diffusion\">https://huggingface.co/Envvi/Inkpunk-Diffusion</a></p><p>C:dreamlikesamkuvshinov</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1473/dreamlikesamkuvshinov\">https://civitai.com/models/1473/dreamlikesamkuvshinov</a></p><p>A<em>0.5+B</em>0.5=D D<em>0.6+C</em>0.4＝UnstableSamInkDream</p><p>Trigger Words:</p><p>nvinkpunk,dreamlikeart,samdoesart,kuvshinov,</p><p></p><p></p>","ratingcount":32,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AnyHentai":{"status":"inactive","modelid":"civitai-41233","rating":4.84,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b4073392-48ef-41d1-f9a0-2fe1f8249600/width=450/454802.jpeg","description":"<h2>AnyHentai is a merge of multiple models</h2><p></p><p>for sampling methods, use <strong>Euler a</strong> <strong><em>(best)</em></strong>, <strong>DDIM (second best)</strong>, or <strong>DPM++ DM Karras</strong></p><p></p><p></p><h1>DOWNLOAD/INSTALLATION</h1><p></p><p><strong>Step 1:</strong> download SAFETENSORS and VAE files.</p><p><strong>Step 2:</strong> put the SAFETENSORS file under \"stable-diffusion-webui\\models\\Stable-diffusion\"</p><p><strong>Step 3:</strong> put the VAE file under \"stable-diffusion-webui\\models\\VAE\"</p><p><strong>Step 4:</strong> Done! enjoy the model</p><p></p><h1>USAGE</h1><p></p><p>-use a minimal negative prompt for best results</p><p>-use <strong>Euler A</strong> and <strong>20-25 steps</strong> for best results</p><p>-use <a target=\"_blank\" rel=\"ugc\" href=\"https://danbooru.donmai.us/\">danbooru </a>tags</p><p>-I used a clip skip of 2 <strong>(optional)</strong></p><p>-I also used the upscaler <strong>Latent (nearest-exact)</strong> with a <strong>highres step of 20</strong> and <strong>denoise of 0.5</strong> to improve image quality and detail <strong>(optional)</strong></p><p><strong>DO NOT USE A DENOISE STRENGTH BELOW 4.5 FOR BEST RESULTS</strong></p><p></p><p><strong><em>EXAMPLE PROMPT</em></strong></p><p>((Masterpiece)), (best quality), (1girl), red hair, beautiful red eyes, medium breasts, classroom, black glasses, school uniform</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://i.ibb.co/WFcyZ1L/00011-1260232077-Masterpiece-best-quality-1girl-red-hair-beautiful-red-eyes-medium-breasts-classroom.png\"><strong>RESULT</strong></a></p><p></p><h3>VAE</h3><p>The VAE is not required. you can use any VAE you like. I have found that VAE makes more vibrant and crisp images, but this is just my testing</p><p></p><p>for the VAE I used the same one as grapefruit</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">link to the grapefruit model</a></p><p></p><p>I will try to improve and update this model by adding other images, although I'm not too familiar with SD and training models, so I will most likely stick to only merging models.</p><p></p><p>_______</p><p></p><h1>EXTRA INFO</h1><p></p><p>-Loras have not been tested yet, but they should most likely work</p><p>-use the upscaler <strong>Latent (nearest-exact) </strong>for best results</p><p>- I will try to update the model at least once per week</p><p>-<strong>Image generation</strong> on the A1111 WebUI normally <strong>took around ~10 seconds</strong> using a 3080 TI with 12 gigabytes of RAM</p><p></p><h2><strong><em>CREDIT TO THE PEOPLE WHO MADE THE MODELS </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\"><strong><em>ORANGEMIX</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.cognitionai.org/hdmainpage\"><strong><em>HENTAI DIFFUSION</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Linaqruf/anything-v3.0/tree/main\"><strong><em>ANYTHING V3</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9409/anything-v5-or-anything-diffusion-original\"><strong><em>ANYTHING V5</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\"><strong><em>DREAMSHAPER</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3850/kenshi\"><strong><em>KENSHI</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion\"><strong><em>COCOA</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4669/corneos-7th-heaven-mix\"><strong><em>CORNEO'S 7TH HEAVEN MIX</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3627/protogen-v22-anime-official-release\"><strong><em>PROTOGEN V2.2 (ANIME)</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5245/kotosmix\"><strong><em>KOTOSMIX</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4468/counterfeit-v25\"><strong><em>COUNTERFEIT</em></strong></a><strong><em>, </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7241/mix-pro-v3\"><strong><em>MIXPROV3 </em></strong></a><strong><em>AND </em></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\"><strong><em>GRAPEFRUIT</em></strong></a></h2>","ratingcount":91,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Dreamlike Photoreal 2.0":{"status":"inactive","modelid":"civitai-4224","rating":4.6,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/85ef9847-1a25-4f9e-7535-a213fc4b4100/width=450/27543.jpeg","description":"<h2>Dreamlike Photoreal 2.0 is SD 1.5 fine tuned on high quality photos, made by <a target=\"_blank\" rel=\"ugc\" href=\"http://dreamlike.art\">dreamlike.art</a></h2><p></p><p><strong>Warning: This model is horny! Add \"nude, naked\" to the negative prompt if want to avoid NSFW.</strong></p><p></p><p>You can add <strong>photo</strong> to your prompt to make your gens more photorealistic.</p><p><br />Non-square aspect ratios work better for some prompts. If you want a portrait photo, try using a vertical aspect ratio. If you want a landscape photo, try using a horizontal aspect ratio.</p><p><br />This model was trained on 768x768px images, so use 768x768px, 640x896px, 896x640px, etc. It also works pretty good with higher resolutions such as 768x1024px or 1024x768px.</p><p></p><h2>You can use this model online for free on <a target=\"_blank\" rel=\"ugc\" href=\"http://dreamlike.art\">dreamlike.art</a>!</h2><p></p><h3><strong>License</strong></h3><p>This model is licesed under a <strong>modified</strong> CreativeML OpenRAIL-M license.</p><ul><li><p><strong>You are not allowed to host, finetune, or do inference with the model or its derivatives on websites/apps/etc. If you want to, please email us at </strong><a target=\"_blank\" rel=\"ugc\" href=\"mailto:contact@dreamlike.art\"><strong><u>contact@dreamlike.art</u></strong></a></p></li><li><p><strong>You are free to host the model card and files (Without any actual inference or finetuning) on both commercial and non-commercial websites/apps/etc. Please state the full model name (Dreamlike Photoreal 2.0) and include the license as well as a link to the model card (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0\"><strong><u>https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0</u></strong></a><strong>)</strong></p></li><li><p><strong>You are free to use the outputs (images) of the model for commercial purposes in teams of 10 or less</strong></p></li><li><p>You can't use the model to deliberately produce nor share illegal or harmful outputs or content</p></li><li><p>The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license</p></li><li><p>You may re-distribute the weights. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the <strong>modified</strong> CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully) Please read the full license here: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\"><strong><u>https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md</u></strong></a></p></li></ul>","ratingcount":55,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Protogen x5.3 (Photorealism) Official Release":{"status":"inactive","modelid":"civitai-4229","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/6614bd63-e522-4826-27c5-5e93d335c000/width=450/27601.jpeg","description":"<h3>ProtoGen_X5.3 - One Step Closer to Reality</h3><h3>Research Model - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">How to Build Protogen</a></h3><p>Running on Apple Silicon devices ? <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreml/coreml-Protogen\">Try this instead</a></p><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/darkstorm2150/protogen-web-ui\"><strong>Live Demo at Available on Hugging Face</strong></a></h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://preview.redd.it/et9c6e3bsoda1.jpeg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=aa2049832da52e4e650e847e023147629e7faf40\"><strong>Model Weights</strong></a> thanks to reddit user <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/user/jonesaid\">u/jonesaid</a><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.studiobinder.com/blog/ultimate-guide-to-camera-shots/\"><strong>Comprehensive guide to camera control</strong></a><br />Trigger words are available for the hassan1.4 and f222, might have to google them :)<strong><br /></strong><br />This is ProtoGen_X3.4 revised (the original cocktail mix, with different route taken)</p><p></p><p>Robodiffusion has been removed and 10% Dreamlike-PhotoReal V.2 added, the result is better sampling at 768px to 1024px of humans and surroundings, The results are immediate!!!</p><p></p><p>Also this bad boy comes with a license, so do please read it, thank you!</p><p></p><p>Model control</p><p>Now its recommended that you add <strong>nude, naked </strong>to your negative prompts, its a horny model, well 10% but still....cant be too careful!</p><p></p><p>As for realism, you can use this template</p><p></p><p>modelshoot style, (extremely detailed 8k wallpaper),a medium shot photo of a (what you want here), Intricate, High Detail, dramatic</p><p></p><p><strong>Please click the link below to read the license before downloading, thank you!</strong></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">This model is licensed under a <strong>modified</strong> CreativeML OpenRAIL-M license.</a></p>","ratingcount":52,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Consistent-Factor":{"status":"inactive","modelid":"civitai-42561","rating":4.85,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/667ec2d9-8e62-4ecc-5e30-eab114538b00/width=450/467209.jpeg","description":"<p>A merged model trying to get as close to realistic as I can.</p><p></p><p>V1 contained parts of Deliberate, Uber Realistic Porn Merge and Realistic Vision</p><p>V2 used updated Deliberate, Realistic Vision and Uber Realistic Porn Merge.</p><p>V3 added RPG, HassanBlend, Dreamlike Diffusion, Babes (experiment 8), Experience (realistic), Protogen x5.3 and Protogen x5.8 to the original 3 models.</p><p>V3.2 used updated Realistic Vision, Experience and switched to Babes Experiment 9.</p><p>V4 has been redone from the ground up. The model will consist of Deliberate, Realistic Vision, Experience, RPG, Analog Madness and CyberRealistic. This will come in 3 flavours, Standard, LE edition and soon a vivid edition for those who like the bolder colours seen in V3.2.</p><p>Recommend: DPM++2M Karras, Steps: 32+, Hires fix 0.3 - 0.5, CFG 6 - 8.</p><p>I would also recommend using epi_noiseoffset <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/13941?modelVersionId=16576\">https://civitai.com/models/13941?modelVersionId=16576</a></p><p>Check out more of my work over at Deviantart - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.deviantart.com/consistentfactor444\">https://www.deviantart.com/consistentfactor444</a></p>","ratingcount":47,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Protogen x5.8 Rebuilt (Scifi+Anime) Official Release":{"status":"inactive","modelid":"civitai-4298","rating":4.85,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ce040db0-0acd-4908-8669-b82151f86400/width=450/28334.jpeg","description":"<h3>ProtoGen_X5.8 - Rebuilt - <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">How to Build Protogen</a></h3><p>By Downloading you agree to the following licenses<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/CompVis/stable-diffusion-license\">CreativeML Open RAIL-M</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">Dreamlike License</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreco/seek.art_MEGA/blob/main/LICENSE.txt\">Seek Art Mega License</a><br /><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://preview.redd.it/et9c6e3bsoda1.jpeg?width=1076&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=aa2049832da52e4e650e847e023147629e7faf40\"><strong>Model Weights</strong></a> thanks to reddit user <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/user/jonesaid\">u/jonesaid</a></p><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/darkstorm2150/protogen-web-ui\"><strong>Live Demo at Available on Hugging Face</strong></a></h3><p><strong><br /></strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.studiobinder.com/blog/ultimate-guide-to-camera-shots/\"><strong>Comprehensive guide to camera control</strong></a><strong><br /></strong><br />Dreamlike-PhotoReal V.2 is the core model, this cocktail version adds</p><ul><li><p>5% modelshoot-1.0</p></li><li><p>20% roboDiffusion_v1</p></li><li><p>20% MoistMix</p></li><li><p>20% HASDX</p></li></ul><p></p><p>Please click the link below to read the license before downloading, thank you!</p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">This model is licensed under a <strong>modified</strong> CreativeML OpenRAIL-M license.</a></p>","ratingcount":39,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Cheese Daddy's Landscapes mix":{"status":"inactive","modelid":"civitai-42985","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f5743ff4-f9eb-4353-6bf7-25a5e2007100/width=450/471002.jpeg","description":"<h1><u>Try out the Noise Offset version of the 2.0 and 3.5! </u><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/15037/cheese-daddys-landscapes-mix-or-offset-noise\">Here</a></h1><p><strong>If you like my work, consider buying</strong><a rel=\"ugc\" href=\"https://ko-fi.com/cheesedaddy\"><strong> me a coffee </strong>☕</a></p><p><strong>V4.1 (experimental):</strong></p><p>removed <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">rev_animated</a></p><p>added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4201/realistic-vision-v20\">realistic vision</a></p><p>fixed the model</p><p></p><p><strong>Recommendation: clip skip 1</strong> (clip skip 2 sometimes generate weird images)</p><p>2:3 aspect ratio (512x768 / 768x512) or 1:1 (512x512)</p><p>DPM++ 2M CFG 5-7</p><p>prompts that i always add: award winning photography, Bokeh, Depth of Field, HDR, bloom, Chromatic Aberration ,Photorealistic,extremely detailed, trending on artstation, trending on CGsociety, Intricate, High Detail, dramatic, art by midjourney, masterpiece, best quality, high quality,extremely detailed CG unity 8k wallpaper</p><p></p><p><strong>V4.0:</strong></p><p>added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">deliberate 2.0</a></p><p>added <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7371/rev-animated\">rev animated</a></p><p>fixed hands with <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil_mix_fixed.safetensors\">basil_mix</a></p><p></p><p><strong>V3.5: ADDED Pastel mix</strong></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5414/pastel-mix-stylized-anime-model\">https://civitai.com/models/5414/pastel-mix-stylized-anime-model</a></p><p><br /><strong>V3: ADDED AnythingV3 and fixed the model: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/66/anything-v3\"><strong>https://civitai.com/models/66/anything-v3</strong></a></p><p></p><p>RECOMMENDED VAE'S</p><p></p><p>kl-f8-anime2</p><p>Anything-V3.0</p><p></p><p>RECOMMENDED LORA'S FOR BETTER RESULTS</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SatyamSSJ10/Satyam_Public_LORA/blob/main/Jordan_3.safetensors\">Jordan 3</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/closertodeath/ctdlora/blob/main/dpep2%20768.pt\">dpep2 768</a></p><p>0.8 weight</p><p><br /><strong>V2: ADDED Deliberate</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\">https://civitai.com/models/4823/deliberate</a><br /><br />Roboetics: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3738/roboetics-mix\">https://civitai.com/models/3738/roboetics-mix</a><br />Inkpunk: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1087/inkpunk-diffusion\">https://civitai.com/models/1087/inkpunk-diffusion</a><br />DreamShaper: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4384/dreamshaper\">https://civitai.com/models/4384/dreamshaper</a><br />ChromaV5: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SomaMythos/ChromaV5\">https://huggingface.co/SomaMythos/ChromaV5</a><br />H&amp;A's 3DKX 1.1:<strong> </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2504/handas-3dkx-11\">https://civitai.com/models/2504/handas-3dkx-11</a><br />Analog diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">https://civitai.com/models/1265/analog-diffusion</a><br />The Ally's Mix: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1202/the-allys-mix\">https://civitai.com/models/1202/the-allys-mix</a><br />Tokens: Analog style, chromav5, nvinkpunk<br /><br />Chromav5 Keywords: Chromatic Aberration; Geometric Shapes; Bokeh; Depth of Field; Photorealistic; Cosmic; Detailed; Bloom; HDR</p><p></p><p></p>","ratingcount":43,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"iCoMix":{"status":"inactive","modelid":"civitai-43844","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bee10130-d5f1-4ad3-8d7a-88683a463200/width=450/480033.jpeg","description":"<h1>Comic style Mix!</h1><p>Thank you for all Reviews, Great Model/Lora Creator, and Prompt Crafter!!!</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d31bbf40-7ad1-42e6-8e01-85c8f0973400/width=525/d31bbf40-7ad1-42e6-8e01-85c8f0973400.jpeg\" /><p></p><h3>See on Huggingface <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/losti/iCoMix\">iCoMix</a></h3><p></p><p>VAE : <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/NoCrypt/blessed_vae\"><strong><u>Blessed2 VAE</u></strong></a> from NoCrypt</p><p>Default <strong>Negative Prompt</strong> i use (u can add or remove depends on your need) :</p><pre><code>(worst quality:1.4), (low quality:1.4), malformed hands, bad hands, mutated fingers, extra limbs, blurry, bad anatomy, disfigured, jpeg artifacts, child, depth of field, bad eyes</code></pre><p><strong>Thank you &amp; Enjoy! </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://beacons.ai/lostdogplay\"><strong>Buy me a coffee</strong></a></p>","ratingcount":64,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"DreamShaper":{"status":"inactive","modelid":"civitai-44525","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c5e55a0a-2fb7-44d1-ca77-8ef1eb2b7f00/width=450/486175.jpeg","description":"<h1>DreamShaper - V5 is here!</h1><h3>Please check out my newest models: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10028/neverending-dream\">NeverEnding Dream</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/23521/anime-pastel-dream\">Anime Pastel Dream</a></h3><p><strong>Check the version description below (bottom right) for more info and add a ❤️ to receive future updates.</strong><br /><strong>Do you like what I do? Consider supporting me on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/Lykon275\"><strong>Patreon</strong></a><strong> 🅿️ to get exclusive tips and tutorials, or feel free to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/lykon\"><strong>buy me a coffee</strong></a><strong> ☕</strong></p><p><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/Lykon/DreamShaper-webui\"><strong>Live demo available on HuggingFace</strong></a><strong> (CPU is slow but free).</strong></p><p><strong>Available on the following websites with GPU acceleration:</strong></p><ul><li><p><a rel=\"ugc\" href=\"https://www.mage.space/\"><strong>Mage.space</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Sinkin.ai\"><strong>Sinkin.ai</strong></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://smugo.ai/create?model=dreamshaper\"><strong>Smugo</strong></a></p></li></ul><p><strong>MY MODELS WILL ALWAYS BE FREE.</strong><br /><br /><strong>NOTES</strong></p><ul><li><p>Version 5 is the best at photorealism and has noise offset.</p></li><li><p>Version 4 is much better with anime (can do them with no LoRA) and booru tags. IT might be harder to control if you're used to caption style, so you might still want to use version 3.31.</p></li><li><p>V4 is also better with eyes at lower resolutions. Overall is like a \"fix\" of V3 and shouldn't be too much different. <strong>Stay tuned for V5!</strong></p></li><li><p>Results of version 3.32 \"clip fix\" will vary from the examples (produced on 3.31, which I personally prefer).</p></li><li><p>I get no money from any generative service, but you can buy me a coffee.</p></li><li><p>You should use 3.32 for mixing, so the clip error doesn't spread.</p></li><li><p><strong>Inpainting models are only for inpaint and outpaint, not txt2img or mixing. </strong><br /></p></li></ul><p>After a lot of tests I'm finally releasing my mix. This started as a model to make good portraits that do not look like cg or photos with heavy filters, but more like actual paintings. The result is a model capable of doing portraits like I wanted, but also great backgrounds and anime-style characters. Below you can find some suggestions, including LoRA networks to make anime style images. <br /><br />I hope you'll enjoy it as much as I do.<br /><br />Diffuser weights (courtesy of <a target=\"_blank\" rel=\"ugc\" href=\"https://reddit.com/u/Different-Bet-1686\">/u/Different-Bet-1686</a>): <br /><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Lykon/DreamShaper\">https://huggingface.co/Lykon/DreamShaper</a></p><p>Official HF repository: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Lykon/DreamShaper\">https://huggingface.co/Lykon/DreamShaper</a><br /><br /><strong>Suggested settings:</strong><br />- I had CLIP skip 2 on some pics (all of them for version 4)<br />- I had <em>ENSD</em>: 31337 for basically all of them<br />- All of them had <strong>highres.fix</strong> or img2img at higher resolution.<br />- I <strong>don't use restore faces</strong>, as it washes out the painting effect<br />- Version 4 requires no LoRA for anime style. For version 3 I suggest to use one of these LoRA networks at 0.35 weight: <br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4219\">https://civitai.com/models/4219</a> (the girls with glasses or if it says <code>wanostyle</code>)<br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/closertodeath/dpepmkmp/blob/main/last.pt\">https://huggingface.co/closertodeath/dpepmkmp/blob/main/last.pt</a> (if it says <code>mksk style</code>)<br />-- <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4982/anime-screencap-style-lora\">https://civitai.com/models/4982/anime-screencap-style-lora</a> (not used for any example but works great)<br /><br />NOTE: if you find that the prompts below look \"familiar\" it's because I've taken them from other reviews and models here, to basically compare my model to other examples. Credits to the original authors. Thanks for the benchmark.</p>","ratingcount":441,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"LOFI":{"status":"inactive","modelid":"civitai-44882","rating":4.86,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/47978501-be91-4712-e452-299f7f834000/width=450/491392.jpeg","description":"<h1>L.O.F.I: Limitless Originality Free from Interference</h1><p></p><ul><li><p>🧐 No special face alignment</p></li><li><p>🚀 Improve line details</p></li><li><p>🚀 Improve prompt understanding</p></li></ul><p></p><h3>[update:230414] LOFI V2.1</h3><ul><li><p>🧙more realistic details from more iterative training (200epochs)</p></li><li><p>🩹a little bit facial effect rollback (to LOFI V2pre)</p></li><li><p>🖌️add inpainting model (base on LOFI V2.1)</p></li></ul><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f9bd1cd7-659b-4446-b81b-b12d3559c800/width=525/f9bd1cd7-659b-4446-b81b-b12d3559c800.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/80d597a7-c7e2-4fcc-2cdd-43f353ae5c00/width=525/80d597a7-c7e2-4fcc-2cdd-43f353ae5c00.jpeg\" /><p></p><p>tips (about inpainting model):</p><p>You need to ensure that your inpaint model filename is in a format supported by the webui, such as <strong><em>LOFI_V21.inpainting.safetensors</em></strong></p><p>(This is likely a bug with Civitai, resulting in the downloaded model file having a different name than what was uploaded... so you need to manually modify it to ensure the webui can load the model correctly.)</p><p></p><p>--</p><p><em><u>Note: because I used some of the optimization of torch2.1, it is possible that you could not generate exactly same image with same parameters (but quality was good)</u></em></p><p></p><h3>[update:230325] LOFI V2</h3><p>Finally, v2 is released</p><p>Based on the LOFI-v1 model, finetuned 80,000 steps / 300 epochs</p><p></p><ul><li><p>📷more camera concept</p></li></ul><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/59429045-d793-400e-0ab1-f88da6fc4700/width=525/59429045-d793-400e-0ab1-f88da6fc4700\" /><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://emojipedia.org/artist-palette/\">🎨</a>exact palette</p></li></ul><img src=\"https://cdn.discordapp.com/attachments/1064690241765642270/1088853366660145194/xyz_grid-0366-4006333574-happy20dog20wearing20yellow20sweater_photographed20by20Canan20EOS20R62050mm201_1000s20ISO20500.png\" /><p></p><h3>[update:230224] LOFI V2pre</h3><p>version 2 pre-release. This is a pre-release version, not just the merge model, it also includes some model parts that I have fine-tuned through training, including the previously released TAF and some other train models that improve image quality</p><p></p><p>But it may cause the model to focus on “portrait of characters”, so this is only a pre-release version and needs to be updated. LOFI model aims to be general and high-quality.</p><p></p><h3><strong>Prompt suggestions</strong></h3><ul><li><p>Since the text-encoder used is enough trained version, do not use a very high attention to control weight, which will cause some wrong drawing, it is recommended that all attention weights be no higher than 1.2</p></li><li><p>If there is no special composition requirement, there is no need for a lot of negative prompts, such as \"missing hands\", which may affect human body drawing, and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">DeepNegative </a>is enough for negative prompts</p></li><li><p>It is strongly recommended to use hires.fix to generate, Recommended parameters:</p><ul><li><p>(final output 512*768)</p><p>Steps: 20, Sampler: Euler a, CFG scale: 7, Size: 256x384, Denoising strength: 0.75, Hires upscale: 2, Hires steps: 40, Hires upscaler: Latent (bicubic antialiased)</p></li></ul></li></ul><p></p><p>Most of the sample images are generated with hires.fix</p><p><em><u>Note: that if you use hires.fix, you may not be able to reproduce the image with the same set of parameters in webui, because hires.fix introduces double randomness</u></em></p><p></p><p></p>","ratingcount":70,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"MeinaMix":{"status":"inactive","modelid":"civitai-46137","rating":4.94,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/69b1092e-d3b1-4843-8980-2798253ab000/width=450/500009.jpeg","description":"<p><strong>MeinaMix objective </strong>is to be<strong> </strong>able to do good art with little prompting.<br /><br />I created a <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/F6yeQtEQ98\">discord</a> server where you can post images that you generated, discuss prompt and/or ask for help. <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/meinaverse\">https://discord.gg/meinaverse</a><br /><br /><strong>You may also try my model using</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/vln8Nwr\">Sinkin.ai</a>: <a target=\"_blank\" rel=\"ugc\" href=\"https://sinkin.ai/m/vln8Nwr\">https://sinkin.ai/m/vln8Nwr</a><br /><br /><strong>If you like one of my models and want to support their updates:</strong><br />I have a <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>ko-fi</strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>Patreon</strong></a> page where you can support me or buy me a coffee &lt;3 , <strong>it will be very much appreciated:</strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/meina\"><strong>https://ko-fi.com/meina</strong></a><strong> and </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/MeinaMix\"><strong>https://www.patreon.com/MeinaMix</strong></a><br /><br /><strong>MeinaMix and the other of Meinas will ALWAYS be FREE.</strong><br /></p><p><strong>The images in the samples aren't cherry picked, if i had spent 2h to cherry pick each of the images it would hide how the model really performs and i don't think thats fair.</strong><br /><br /><strong>Recommendations of use:</strong><br />--------------------------------------------------------------------------------<br /><strong>Enable Quantization in K samplers.</strong><br /><br /><strong>Hires.fix is needed for prompts where the character is far away</strong> in order to make decent images, it drastically improve the quality of face and eyes!<br />---------------------------------------------<br /><strong>Recommended parameters:</strong><br /><strong>Sampler:</strong> Euler a: 40~60 steps.<br /><strong>Sampler:</strong> DPM++ SDE Karras: 30~60 steps.<br /><strong>CFG Scale:</strong> 7.<br /><strong>Resolutions:</strong> 512x768, 512x1024 for Portrait!<br /><strong>Resolutions: </strong>768x512, 1024x512, 1536x512 for Landscape!<br /><strong>Hires.fix:</strong> R-ESRGAN 4x+Anime6b, with 10 steps at 0.1 up to 0.3 denoising.<br /><strong>Clip Skip:</strong> 2.<br /><strong>Negatives:</strong> ' (worst quality:2, low quality:2), (zombie, sketch, interlocked fingers, comic), '<br />--------------------------------------------------------------------------------<br /><br /><strong>In the merged models list: MeinaMix V1~6, MeinaPastel V3, MeinaHentai V2, Night Sky YOZORA Style Model, PastelMix and Facebomb, </strong>i do not have the exact recipe because i did multiple mixings using block weighted merges with multiple settings and kept the better version of each merge.</p>","ratingcount":374,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"HassanBlend 1.5.1.2 and previous versions - Fantasy.ai ":{"status":"inactive","modelid":"civitai-4635","rating":4.43,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/9b852b67-0b5d-4d41-9658-299ebeccbc00/width=450/32324.jpeg","description":"<p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/sd_hassan/membership\">Patreon Membership for exclusive content/releases</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"http://Fantasy.ai\">Fantasy.ai</a> is the official and exclusive hosted AI generation platform that holds a commercial use license for Hassan Mix, you can use their service at <a target=\"_blank\" rel=\"ugc\" href=\"https://Fantasy.ai/\">https://Fantasy.ai/</a></p><p>This means commercial platform use is exclusive but non commercial use is fine. You as a user can download the model, use it, merge with it, train with it, sell your images and content made with this but it just can't be used on a commercial platform for like commercial txt2img generation services, commercial finetuning services etc</p><p></p><p>This was a custom mix with <strong>finetuning</strong> my own datasets also to come up with a great photorealistic model with NSFW and hardcore possibilities.</p><p>You can view sample prompts from a bunch of my <a target=\"_blank\" rel=\"ugc\" href=\"https://rentry.org/sdhassan#merged-models\">models on my page here</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"discord.gg/sdmodelers\">You can join our discord to discuss any of our models/guides/embedding shares etc, we have a good community!</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hassanblend\">HuggingFace</a></p><p> </p>","ratingcount":69,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Lyriel":{"status":"inactive","modelid":"civitai-50127","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f8718950-2a4c-4a5b-1df6-25fe07efde00/width=450/539213.jpeg","description":"<p>Hello, the model was created as an artistic style, the model can do almost anything, the main thing is to follow the promt, hands and eyes looks good for the most cases</p><p>Model Information:</p><p>This model is generally designed for portraits and full-length anime style photos. Fantastic landscapes are quite decent. And it doesn't require kilometer-long queries to get a high-quality result.</p><p>Recommend: DPM++2M Karras, Clip skip 2 Sampler, Steps: 25-35+</p><p></p><p>This model would not have come out without XpucT's help, which made <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4823/deliberate\"><strong>Deliberate</strong></a></p><p>If you have the desire and means to support future models, here you go:</p><p><a rel=\"ugc\" href=\"https://wallet.advcash.com/ru/login\">Advanced Cash</a> - U 1281 8592 6885 , E 8642 3924 9315 , R 1339 7462 2915</p><p><a rel=\"ugc\" href=\"https://payeer.com/ru/\">PEYEER</a> - P1075963156</p><p>I hope you like it, thanks for the feedback</p>","ratingcount":339,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"ReV Animated":{"status":"inactive","modelid":"civitai-46846","rating":4.96,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/13303d08-1b18-4b89-728f-82aa3b4aaa00/width=450/506112.jpeg","description":"<h3><strong>Pay attention to the <em><u>About this version</u></em></strong> <strong>section </strong>of model page<strong> for specific version information. ➡️➡️➡️➡️➡️</strong></h3><h3><br /><br /><u>Model Overview:</u></h3><ul><li><p><u>rev</u> or <u>revision</u>: The concept of how the model generates images is likely to change as I see fit.</p></li><li><p><u>Animated</u>: The model has the ability to create 2.5D like image generations. This model is a checkpoint merge, meaning it is a product of other models to create a product that derives from the originals.</p></li><li><p>Kind of generations:</p><ul><li><p>Fantasy</p></li><li><p>Anime</p></li><li><p>semi-realistic</p></li><li><p><em>decent Landscape</em></p></li></ul></li><li><p>LoRA friendly</p></li><li><p>It works <strong><em><u>best on these resolution dimensions:</u></em></strong></p><ul><li><p>512x512</p></li><li><p>512x768</p></li><li><p>768x512</p></li></ul></li></ul><p></p><h3><u>VAE</u>:</h3><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/VAEs/orangemix.vae.pt\"><u>orangemix.vae.pt</u></a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/tree/main/vae\">kl-f8-anime2.ckpt</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/NoCrypt/blessed_vae/blob/main/blessed2.vae.pt\">Blessed2.vae.pt</a></p><p><br /></p></li></ul><h3><u>Prompting</u>:</h3><ul><li><p><strong>Order matters</strong> - words near the front of your prompt are weighted more heavily than the things in the back of your prompt.</p></li><li><p><strong>Prompt order</strong> - content type &gt; description &gt; style &gt; composition</p></li><li><p><strong>This model likes</strong>: ((best quality)), ((masterpiece)), (detailed) in beginning of prompt if you want anime-2.5D type</p></li><li><p>This model does great on<strong> <u>PORTRAITS</u></strong></p></li></ul><p></p><p><strong><u>Negative Prompt Embeddings:</u></strong></p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/EasyNegative/tree/main\">EasyNegative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\">Deep Negative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/bad_prompt/blob/main/bad_prompt_version2.pt\">bad_prompt_version2</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist.pt\">bad-artist</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nick-x-hacker/bad-artist/blob/main/bad-artist-anime.pt\">bad-artist-anime</a></p></li><li><p>Make use of weights in negative prompts (i.e (worst quality, low quality:1.4))</p><p></p></li></ul><p></p><h3><u>Video Features</u></h3><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://youtu.be/Nl43zR5dVuM?t=192\">Olivio Sarikas - Why Is EVERYONE Using This Model?! - Rev Animated for Stable Diffusion / A1111</a></p><p></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.youtube.com/watch?v=A6dQPMy_tHY\">Olivio Sarikas - ULTRA SHARP Upscale! - Don't miss this Method!!! / A1111 - NEW Model</a></p><p></p><p></p><h2><strong><u>Disclaimer:</u></strong><br /></h2><p><strong>Do not sell</strong> this model on any website without permissions from creator (me)</p><p><strong>Credit</strong> me if you use my model in your own merges</p><p><strong>I do not authorize</strong> this model to be used on <strong>generative services</strong></p><p>I have given you plentiful amount information and sources within this section, <strong>I will not answer</strong> <strong><u>redundant questions</u></strong> if it already exists here in the info section.<br /><br /></p><p>if you would like to support me:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/s6yx0\">https://ko-fi.com/s6yx0</a></p><h2><br /></h2>","ratingcount":619,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"GhostMix":{"status":"inactive","modelid":"civitai-47142","rating":4.96,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0f04ccf7-711e-4ab2-29ea-11b9b7bdd300/width=450/509498.jpeg","description":"<p>很多用户反映生成的图片颜色不对，大部分原因是没有设置VAE。所以上传了GhostMix-V1.1 BakedVAE（VAE:kl-f8-anime2-vae），如果你不喜欢自己设置VAE，可以试试这个。</p><p>Many users said that color of the pics is not right, mainly is because of the VAE .So I upload the GhostMix-V1.1 BakedVAE(VAE:kl-f8-anime2-vae), if you don't like setting the VAE,you can try this model.</p><p></p><h2><em>2023.4.16 GhostMix-V1.1</em></h2><h3><u>UPDATE DETAIL(更新说明)</u></h3><p>Improve the stability while using GhostMix on charactor, and make the face more like real man. Improve the quality of the model.If you like my model, feel free to upload the generated pictures to share with us. It will help me for the next version of GhostMix, thanks again.</p><p>提升了GhostMix在生成人物时的稳定性，使得人脸更逼真。模型质量进一步提升。如果觉得我的模型不错，欢迎上传生成的图片分享，会对我调下一个版本GhostMix有很大的帮助。关于图片复现问题可以看3.11的下文，谢谢。<strong>如果生成图片颜色灰暗的，一定要检查VAE，一定要检查VAE，一定要检查VAE，不能自动，推荐动漫用这个</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/23906/kl-f8-anime2-vae\">kl-f8-anime2-vae</a></p><p></p><h2><em>2023.3.11 GhostMix-V1.0</em></h2><h3><u>Introduction(中文简介在下面)</u></h3><p>First of all , I want to thank all the people who use this Checkpoint. And this is my first Checkpoint.All the sample image can be reproduced. This Checkpoint works well on both SFW and NSFW.THE NSFW PART IS VERY GOOD!!!<br />I uploaded this Checkpoint yesterday and from yesterday to today , I am still trying all the possibility of this Checkpoint. So if you try the model and find some good promts , I hope you can upload it and share with me, it will help me for the next version of GhostMix, Thank you agian!</p><h3><u>Recommend Some Promts:</u></h3><ol><li><p><strong>Fractal Art（highly recommend，awsome）</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), (1girl:1.3), (fractal art:1.3),</code></pre><ol><li><p><strong>Realistic Art-Girl &amp; Flower field</strong></p></li></ol><pre><code>((masterpiece, best quality)), 1girl, flower, solo, dress, holding, sky, cloud, hat, outdoors, bangs, bouquet, rose, expressionless, blush, pink hair, flower field, red flower, pink eyes, white dress, looking at viewer, midium hair, holding flower, small breasts, red rose, holding bouquet, sun hat, white headwear, depth of field,</code></pre><ol><li><p><strong>Color Art</strong></p></li></ol><pre><code>(flat color:1.3),(colorful:1.3),(masterpiece:1.2), best quality, masterpiece, original, extremely detailed wallpaper, looking at viewer,1girl,solo,floating colorful water</code></pre><ol><li><p><strong>Realistic Art-Nude Girl(NSFW-recommend)</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.3),  illustration, beautiful detailed eyes, (1girl), (nude),detailed nipples,huge breasts,puffy nipples, oniomania, erotic,beautiful detailed pussy,soft breasts,upper body</code></pre><h3><u>VAE&amp;Textual Inversion:</u></h3><p>VAE: kl-f8-anime2 or vae-ft-mse-840000-ema-pruned(anime suggest: kl-f8-anime2)</p><p>Textual Inversion: ng_deepnegative_v1_75t, easynegative</p><p></p><h3><u>About Image Reproduction:</u></h3><p>Some user said that they can not reproduce my result.Maybe the setting goes wrong.I just reproduce my cover image. If you want to reproduce my result, Checkpoint Model，Postive Promt，Negative Promt，Textual Inversion，Sampler Steps，Sampler，CFG，Resolution，Seed , ALL the things should be the SAME! Then be careful if you open controlnet or lora ,don't make them influnence your result.</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d644a081-4d69-441e-ea1c-81d6b1934800/width=525/d644a081-4d69-441e-ea1c-81d6b1934800.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f7062462-6f14-4555-7176-0ec8fdb67600/width=525/f7062462-6f14-4555-7176-0ec8fdb67600.jpeg\" /><p></p><h2><u>中文简介</u></h2><p>首先感谢每一个使用这个Checkpoint的人，这是我融的第一个Checkpoint。所有样图自测都可以复现。SFW和NSFW的图都挺漂亮的，NSFW的图非常棒。这个模型昨天上传到今天，我一直在尝试这个模型的可能性。希望使用这个Checkpoint的朋友们，如果你试了，觉得有不错Promts，欢迎上传图分享，让我也了解一下这个Checkpoint的可能性，也可以帮助我调下一个版本GhostMix，再次感谢。</p><h3><u>推荐Promts:</u></h3><ol><li><p><strong>分型艺术（超级推荐，必出好图）</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.2), (1girl:1.3), (fractal art:1.3),</code></pre><ol><li><p><strong>真实风格-少女与花海</strong></p></li></ol><pre><code>((masterpiece, best quality)), 1girl, flower, solo, dress, holding, sky, cloud, hat, outdoors, bangs, bouquet, rose, expressionless, blush, pink hair, flower field, red flower, pink eyes, white dress, looking at viewer, midium hair, holding flower, small breasts, red rose, holding bouquet, sun hat, white headwear, depth of field,</code></pre><ol><li><p><strong>色彩艺术</strong></p></li></ol><pre><code>(flat color:1.3),(colorful:1.3),(masterpiece:1.2), best quality, masterpiece, original, extremely detailed wallpaper, looking at viewer,1girl,solo,floating colorful water</code></pre><ol><li><p><strong>裸女(色图-推荐)</strong></p></li></ol><pre><code>(masterpiece, top quality, best quality, official art, beautiful and aesthetic:1.3),  illustration, beautiful detailed eyes, (1girl), (nude),detailed nipples,huge breasts,puffy nipples, oniomania, erotic,beautiful detailed pussy,soft breasts,upper body</code></pre><h3><u>VAE&amp;Textual Inversion:</u></h3><p>VAE:kl-f8-anime2或者vae-ft-mse-840000-ema-pruned(动画风建议kl-f8-anime2)</p><p>Textual Inversion:ng_deepnegative_v1_75t,easynegative</p><p></p><h3><u>关于图片复现:</u></h3><p>有同学好像没法复现我的图，可能是设置有点问题，刚刚我才把头图给复现了。注意几个点：Checkpoint 模型，正向Promt，反向Promt，Textual Inversion，迭代步数，迭代方法，CFG，分辨率，随机种子都必须一模一样！然后复现的话，要把controlnet和lora关掉，怕影响复现。</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/978438b2-a581-4740-a0b5-1531a2c47300/width=525/978438b2-a581-4740-a0b5-1531a2c47300.jpeg\" /><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/87b94620-4032-4ba5-1949-cb07e18cfa00/width=525/87b94620-4032-4ba5-1949-cb07e18cfa00.jpeg\" /><h1></h1>","ratingcount":46,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Crosskemono(furry_model&human_model)":{"status":"inactive","modelid":"civitai-47368","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/314ca9c9-8d8d-4d2f-45c8-21229b668700/width=450/510771.jpeg","description":"<p><strong>I will give the right to use the images generated by my model sales to my friend</strong> \"<u>聖聖聖也</u>\" -&gt; <a target=\"_blank\" rel=\"ugc\" href=\"https://www.pixiv.net/users/65258354\"><strong>his PIXIV page</strong></a></p><p>Please report to me any other unauthorized use of the images generated by the sale of my model. This is not unconditional, in the new version afterwards, the images generated by my friend \"<u>聖聖聖也</u>\" will be used as preview images for the new version.</p><p></p><p><strong>\"I would like to express my gratitude to </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Philip\"><strong>Philip_ovo</strong></a><strong> for helping me publish the model on Furry Diffusion Discord. If possible, please also support the Lora model </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/24529/mjfurry\"><strong>MJFurryLora</strong></a><strong> And </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10668/njfurry\"><strong>NJFurryLora</strong></a><strong> created by </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/Philip\"><strong>Philip_ovo</strong></a><strong>.\"</strong></p><p><br /></p><p><u>This English version of the description has been modified based on the translation by marbrdf on ChatGPT.</u></p><p><em>This model is </em><strong><em>designed to generate kemono-style furry using booru tags and can generate human-like figures without decreasing the quality of the output.</em></strong><em> The model is </em><strong><em>designed to produce images without blurring the background.</em></strong></p><h1><strong>See the model description for more details.</strong></h1><ul><li><p><strong>Models are named alphabetically based on the order in which they were uploaded, and the later models are not necessarily better. Choose Model A, B, C, D, E, F or G based on your needs. This is similar to orange and 7th, and you can intuitively compare them with reference images to see the differences.</strong></p></li><li><p>If you only want to use a short prompt without adjusting the weights and without using the kemono-style Hypernetwork or Lora to generate kemono,<strong> choose Model B</strong>.</p></li><li><p>If you have a basic prompt foundation and can adjust the weights but do not want to use the kemono-style Hypernetwork or Lora to generate kemono,<strong> choose Model D</strong>.</p></li><li><p>If you want a very different style and can accept using the kemono-style Hypernetwork or Lora to generate kemono, <strong>choose Model C.</strong></p></li><li><p>If you want to generate attractive human-like figures and kemono-style furry that are close to the current mainstream anime style, and can accept using the kemono-style Hypernetwork or Lora to generate kemono, <strong>choose Model A.</strong></p></li><li><p>If you are looking for a more realistic texture similar to AOM2 or AOM3, and can accept not using the kemono-style Hypernetwork or Lora to generate kemono with a more realistic painting style, then <strong>choose Model F</strong>.</p></li><li><p>If you want clear lines and celluloid-style coloring, and are willing to accept that the characters generated by Model E may appear very young and petite, then <strong>choose Model E.</strong></p></li><li><p>If you are looking for a highly impasto coloring style and incredibly detailed and accurate scenes with a rich and colorful palette, and are willing to accept that the generated kemono poses in Model G may have a more fleshy feel, such as a more visible navel, then <strong>choose Model G.</strong> Please note that this model requires the use of kemono-style Hypernetwork or Lora to generate kemono, as otherwise, unnecessary human ears and incorrect animal noses may be generated.</p></li></ul><p>This series of models combines five Lora styles I trained myself with five kemono-style furry Lorastyles in a hierarchical U-net model that I repeatedly fine-tuned through layer merging.</p><p>Like Counterfeit and Pastel, this model uses a hierarchical U-net model combined with Lora. However, because it includes two completely different species with different body structures, humans and kemono furry, in the merging process, its stability is not as good as that of a general model.</p><p>The models used in the process include but are not limited to the Anything series, Orange series, Pastel+ (Yohan series), Counterfeit series, and 7th series, totaling more than 50 models combined, plus my own personal Lora model, so I cannot share the recipe.</p><p>Although this series of models can generate NSFW content, it is recommended to use any Lora related to NSFW for overlaying. The example images do not use Lora related to NSFW, but overlaying any of them will significantly improve the quality.</p><p>This series of models was generated with the default HI-RES setting, and I am not sure how much the image quality would be affected without it. However, based on the images generated by others in the discussion area without HI-RES, the results seem to be good.</p><p>I will not upload more example images because the style is very diverse, combining more than 50 models, <strong>including some realistic style images created by others in the discussion area.</strong></p><p>2023/2/24 <u>CrosskemonoC</u></p><p>2023/2/24 <strong>Deleted most of the example images, including NSFW, and replaced two images. Following Civitai's rules, example images with minors and NSFW are not included.</strong></p><p>2023/2/24 <u>CrosskemonoD</u></p><p>2023/3/1 <u>CrosskemonoF</u></p><p>2023/3/7 <u>CrosskemonoE</u></p><p>2023/3/8 <u>CrosskemonoE_2</u></p><p>2023/3/13 <u>CrosskemonoG</u></p><p>2023/3/14 <u>CrosskemonoG_2</u></p><p>2023/3/23 <u>Crosskemono2.0TEST</u></p><p>2023/3/24 <u>Crosskemono2.0TEST_2</u></p><p>2023/4/1 <u>Crosskemono2.0</u></p><p>2023/4/17 <u>Crosskemono2.5</u></p><p><em>這個模型是以活用booru tag</em><strong><em>簡單生成kemono 風格的獸人</em></strong><em>，同時又能</em><strong><em>在模型中生成人類卻不降低生成質量，並且保持背景不會模糊</em></strong><em>的前提下製作的。</em></p><h1>詳見型號說明。</h1><ul><li><p><strong>按照上傳順序對模型以英文字母順序命名型號，並不是越後面上傳的模型就越好，請根據你的需要選擇A型、B型、C型、D型、E型、F型、G型，這有點類似orange以及7th，你可以從參考圖像直觀獲得對比，每個型號都有較大的差異。</strong></p></li><li><p>如果你只想用簡短的prompt，不調整權重，也不使用kemono風格的Hypernetwork或者Lora來簡單生成kemono，那麼<strong>請選擇B型號。</strong></p></li><li><p>如果你有一定的prompt基礎，可以接受調整權重，但不使用kemono風格的Hypernetwork或者Lora來生成kemono，那麼可以<strong>選擇D型號。</strong></p></li><li><p>如果你想要一個很不一樣的風格，同時又能接受使用kemono風格的Hypernetwork或者Lora來生成kemono，那麼<strong>請選擇C型號。</strong></p></li><li><p>如果你想要和目前主流的anime模型接近的畫風和構圖，想生成好看的人類又想生成kemono風格的獸人,同時又能接受使用kemono風格的Hypernetwork或者Lora來生成kemono，那麼可以<strong>選擇A型號。</strong></p></li><li><p>如果你想要類似AOM2orAOM3的那樣更加立體的質感，又能接受不使用kemono風格的Hypernetwork或者Lora來生成kemono時畫風較為寫實，那麼請<strong>選擇F型號</strong>。</p></li><li><p>如果你想要清晰的線條的賽璐璐上色，又能接受使用模型E時，該模型生成的人物會顯得非常年輕和嬌小，那麼請<strong>選擇E型號</strong>。</p></li><li><p>如果你想要非常厚塗的上色風格，以及非常細緻且正確的場景，非常豐富多姿的色彩塗抹，又能接受在使用模型G時生成kemono的時候生成的姿態會非常具備肉感，也就是肚臍可能會比較明顯，那麼請<strong>選擇G型號</strong>。(這個型號需要使用kemono風格的Hypernetwork或者Lora來生成kemono，否則可能會生成不必要的人類耳朵和不正確的動物鼻子)。</p></li></ul><p>這個系列模型是將我自己訓練的5個風格lora+5個kemono風格獸lora合併到我使用階層U-net合併的模型內，然後反復階層合併微調的模型。</p><p>和 counterfeit 以及 pastel 一樣 使用 階層U-net合併+lora合併的模型，不過因為在合併過程中加入了完全兩極的人類和獸人兩個身體構造不同的物種，穩定性較一般模型要差，望周知。</p><p>中間使用過的包含civitai和hugging這2個網站上有名的模型合併</p><p>包括不限於</p><p>anything series</p><p>orange series</p><p>pastel +（yohan series）</p><p>counterfeit series</p><p>7th series</p><p>等合計50多個模型合併，加上Lora模型為個人私享，所以不能分享食譜。</p><p>這個系列模型雖然可以生成nsfw,但推薦搭配任何跟nsfw有關的lora疊加使用，示例圖像沒有疊加nsfw相關的lora使用，實際上疊加任何一個都有很大的改善。</p><p>這個系列模型是在默認開啟 HI-RES 的情況下來生成的模型，我不清楚不使用HI-RES會對生成的圖像質量有多大的影響，但是看討論區其他人在不使用 HI-RES 的情況下生成的圖，感覺還不錯。</p><p>我不再上傳更多的示例圖像，因為基於我自己的模型並合併了50多種模型的緣故，風格非常的多樣化，<strong>評論區上也有人用來創作寫實風格的圖像，所以請參考評論區其他人創作的圖像</strong>。</p><p>2023/2/24 <u>CrosskemonoC</u></p><p><strong>2023/2/24 刪除大部分示例圖像，包括NSFW，並替換了兩張圖片，遵循civitai的規定在<u>示例圖像上不放入包含有 minors NSFW 的內容，所有示例圖像的prompt 均不包含 loli or shota 的內容</u>。</strong></p><p>2023/2/24 <u>CrosskemonoD</u></p><p>2023/3/1 <u>CrosskemonoF</u></p><p>2023/3/7 <u>CrosskemonoE</u></p><p>2023/3/8 <u>CrosskemonoE_2</u></p><p>2023/3/13 <u>CrosskemonoG</u></p><p>2023/3/14 <u>CrosskemonoG_2</u></p><p>2023/3/23 <u>Crosskemono2.0TEST</u></p><p>2023/3/24 <u>Crosskemono2.0TEST_2</u></p><p>2023/4/1 <u>Crosskemono2.0</u></p><p>2023/4/17 <u>Crosskemono2.5</u></p>","ratingcount":45,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"majicMIX realistic":{"status":"inactive","modelid":"civitai-48289","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/f3776d9c-e688-4bb8-b94f-be13d023a300/width=450/519083.jpeg","description":"<p>第二版我改善了一下特定成分的权重，也改善了光影 </p><p>In Version2 I adjust the weight of certain element so that the hands and body can be better. I also adjust the lighting slightly.</p><p></p><p>新的展示图用了胶片风 In show case I used <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/33208/lora\">胶片风女孩LoRA</a><br /></p><p></p><p><br />融合了多种模型，可以生成好看的脸部，也能有效应对暗部处理。远距离脸部需要inpaint以达成最好效果。</p><p>A good looking model, suitable for NSFW and dark scene (because I added noiseoffset). long-range facial detail require inpainting to achieve the best results.</p><p>听我一句劝，不要开脸部修复！不要开脸部修复！</p><p><strong>Please don't use Face Restoration! Please don't use Face Restoration!</strong><br /><br />推荐关键词 recommended positive prompts: <em>Best quality, masterpiece, ultra high res, (photorealistic:1.4), 1girl</em><br /><br />如果想要更暗的图像 if you want darker picture, add: <em>in the dark, deep shadow, low key</em>, etc.<br /><br />负面关键词 use <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4629/deep-negative-v1x\"><em>ng_deepnegative_v1_75t</em> </a>and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16993/badhandv4-animeillustdiffusion\"><em>badhandv4</em> </a>in negative prompt</p><p><br /><strong>I've used a bug-fixed version of DPM++ 2M Karras, you can check this out: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/35966/dpm-2m-alt-karras-sampler\">https://civitai.com/models/35966/dpm-2m-alt-karras-sampler</a><br /></p><p>推荐参数Recommended Parameters:</p><p>Sampler: DPM++ 2M Karras (bug-fixed) or DPM++ SDE Karras</p><p>Steps: 20~40</p><p>Hires upscaler: R-ESRGAN 4x+ or 4x-UltraSharp</p><p>Hires upscale: 2</p><p>Hires steps: 15</p><p>Denoising strength: 0.2~0.5</p><p>CFG scale: 6-8</p><p>clip skip 2<br /><br />脸部修复的方法 to inpaint the face: inpaint--&gt;only masked--&gt;set to 512x512--&gt;Denoising strength:0.2~0.5<br /><br />formula:<br /><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/24591/kanpiromix\"><strong>KanPiroMix</strong></a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/31473/xsmix\"><strong>XSMix</strong></a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9871/chikmix\"><strong>ChikMix</strong></a></p><p><strong>关注我的TG频道看更多例图：</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://t.me/majic_NSFW\"><strong>https://t.me/majic_NSFW</strong></a></p>","ratingcount":47,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"DivineEleganceMix ":{"status":"inactive","modelid":"civitai-48473","rating":4.97,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/472cac5c-c67a-4b7a-cff2-ddac86fe8600/width=450/520699.jpeg","description":"<p>It's 10K downloads my dudes! <a target=\"_blank\" rel=\"ugc\" href=\"https://emojidb.org/tada-emojis\">🎉🎉🎉</a><br /><br />If you ran into any troubles with my mix, please read description below. There is plenty of useful information.<br /></p><h3>Updates:</h3><ul><li><p>02.02.2023 - Added lightweight pruned fp-16 no ema model for DivineEleganceMix and DivinePastelMix.</p></li><li><p>16.02.2023 - <code>DivineEleganceMix2</code> released.</p></li><li><p>17.03.2023 - <code>DivineEleganceMix3</code> released.</p></li><li><p>24.03.2023 - <code>DivineEleganceMix4</code> released.</p></li><li><p>18.04.2023 - <code>DivineEleganceMix5</code> released.<br /></p></li></ul><h3>Introduction:</h3><p>All the models i've used before first ever DivineElegance realse did not fit my requirements at all, so i decided to do something by myslef. I saw different mixes built on Anything v4 or v4.5 and i've realized what i truly need. But the main differences between Any | AOM and DivineElegance was the backgrounds.</p><p>DivineElegance at the beginning was a mix for my personal use, but it was warmly received by Unstable Diffusion's discord community and some time later i decided to share it, due to many requests.</p><p>Right now DivineElegance is my favourite model and quite unique thing for me. The main goal of DivineElegance - anime characters with as many details as it could have. Hair, clothes, backgrounds, all of this things should be beautiful, slightly more realistic and detailed.</p><p>I hope you also would like DivineElegace, so stay tuned for newer versions of mix!</p><p></p><h3>Recommendations:</h3><ul><li><p>Use danbooru tagging for prompts</p></li><li><p>Sampler: Euler at / 30-50 steps</p></li><li><p>Sampler: UniPC at 30 steps for landscapes</p></li><li><p>Cfg scale: 7</p></li><li><p>Clip Skip: 2 &lt;---- VERY IMPORTANT</p></li><li><p>ENSD (Eta noise seed delta) - leave blank</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/pastel-mix/blob/main/pastel-waifu-diffusion.vae.pt\">Pastel Waifu Diffusion VAE</a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\">kl-f8-anime2 VAE</a><br /></p></li></ul><h3>Recommendations (Hires Fix):</h3><ul><li><p>Upscaler: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Akumetsu971/SD_Anime_Futuristic_Armor/blob/main/4x_fatal_Anime_500000_G.pth\">Fatal Anime</a></p></li><li><p>Hires steps: 10-15</p></li><li><p>Denoising strength: 0.35</p></li><li><p>Denoising strength (Latent): 0.5</p></li><li><p>Upscale by: <em>any</em><br /></p></li></ul><p>If you want to get mostly the same results, you difinitely will need negative embeddings:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7808/easynegative\">EasyNegative</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Cordeliya/animefull-latest/resolve/main/bad-hands-3.pt\">Bad-Hands-3</a></p></li></ul><p>I'd also recomment it for permanent use.</p><p>If you're ran into any problem with my mix, you can dm me on discord: TroubleDarkness#6280, I'll be glad to help | Буду рад помочь.<br /></p><h3>DivineEleganceMix V5:</h3><p>My main model right now.</p><p>To merge it by yourself you need:</p><ul><li><p>Step 0: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/Cocoa.ckpt\">Cocoa</a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix3/AOM3_orangemixs.safetensors\">AOM3</a> at Weighted Sum 0.4</p><ul><li><p>Convert <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9409/or-anything-v5\">Anything v5 PRT-RE</a> to ckpt</p></li><li><p>Convert <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix3/AOM3_orangemixs.safetensors\">AbyssOrangeMix3</a> to ckpt</p></li><li><p>Convert <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit 3.1</a> to ckpt</p></li><li><p>Convert SenzusHolyshit to ckpt</p></li><li><p>Convert <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">FaceBombMix </a>to ckpt</p></li></ul></li><li><p>Step 1: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9409/or-anything-v5\">Anything-5</a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil_mix_fixed.safetensors\">BasilMix-Fixed</a></p><p>MBW: 1,0.9,0.7,0.5,0.3,0.1,1,1,1,1,1,1,0,0,0,0,0,0,0,0.1,0.3,0.5,0.7,0.9,1 - Alpha 0</p></li><li><p>Step 2: Previous mix + (NovelAI-NSFW - NovelAI-SFW) at Add Difference 0.3</p></li><li><p>Step 3: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit 3.1</a> at Weighted Sum 0.5</p></li><li><p>Step 4: Previous mix + CocoaAOM3 at Weighted Sum 0.5</p></li><li><p>Step 5: Previous mix + SensuzHolyshit at Weighted Sum 0.2</p></li><li><p>Step 6: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">Face-Bomb-Mix</a> at Weighted Sum 0.3</p></li><li><p>Step 7: Convert .ckpt file to fp16 no-ema .safetensors model</p><p></p></li></ul><p>Don't save anything before Step 7 as safetensors of half!</p><p></p><h3>DivineEleganceMix V4:</h3><p>Old version of DivineElegance.</p><p>To merge it by yourself you need:</p><ul><li><p>Step 0: You need:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0/blob/main/anything-v4.5.ckpt\">Anything V4.5 </a>(Full version)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil_mix_fixed.safetensors\">BasilMixFixed</a> with TensorFix and coverted to .ckpt</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit 3.1 </a>converted to .ckpt</p></li></ul></li><li><p>Step 1: Block Merge (Anything4.5 + BasilMix Fixed) at weights 1,0.9,0.7,0.5,0.3,0.1,1,1,1,1,1,1,0,0,0,0,0,0,0,0.1,0.3,0.5,0.7,0.9,1 and Base Alpha 0</p></li><li><p>Step 2: Previous Mix + NovelAI NSFW + NovelAI SFW at Add Difference 0.3</p></li><li><p>Step 3: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit 3.1</a> at Weighted Sum 0.5</p></li><li><p>Step 4: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0/blob/main/anything-v4.5.ckpt\">Anything V4.5 </a>at Weighted Sum 0.4</p></li><li><p>Step 5: Previous Mix + (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/Cocoa.ckpt\">Cocoa </a>+ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/Models/AbyssOrangeMix3/AOM3_orangemixs.safetensors\">AOM3</a> at WS 03) at WS 0.5</p></li><li><p>Step 6: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">FaceBombMix (no vae) </a>at Weighted Sum 0.3</p></li><li><p>Step 7: Convert .ckpt file to fp16 ema-only .safetensors model</p><p></p></li></ul><p>Don't save anything before Step 7 as safetensors of half!</p><p></p><h3>DivineEleganceMix V3:</h3><p>Old version of DivineElegance.</p><p>To merge it by yourself you need:</p><ul><li><p>Step 0: You need:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0/blob/main/anything-v4.5.ckpt\">Anything V4.5 </a>(Full version)</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil_mix_fixed.safetensors\">BasilMixFixed</a> with TensorFix and coverted to ckpt</p></li></ul></li><li><p>Step 1: Block Merge (Anything4.5 + BasilMix Fixed) at weights 1,0.9,0.7,0.5,0.3,0.1,1,1,1,1,1,1,0,0,0,0,0,0,0,0.1,0.3,0.5,0.7,0.9,1 and Base Alpha 0</p></li><li><p>Step 2: Previous Mix + NovelAI NSFW + NovelAI SFW at Add Difference 0.3</p></li><li><p>Step 3: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit 4.1</a> at Weighted Sum 0.5</p></li><li><p>Step 4: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/Cocoa.ckpt\">Cocoa </a>at Weighted Sum 0.3</p></li><li><p>Step 5: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16161/zerotolerances\">ZeroTolerances</a> at Weighted Sum 0.15</p></li><li><p>Step 6: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">FaceBombMix </a>at Weighted Sum 0.25</p><p></p></li></ul><p>Don't save anything above as safetensors of half!</p><p></p><h3>DivineEleganceMix V2:</h3><p>Old version of DivineElegance.</p><ul><li><p>Recipe is lost :(</p></li></ul><p>Actually, the same receipe as V1, but with different weight values and without TensorFix. Receipe would be changed in future releases.<br /></p><h3>DivineEleganceMix V1:</h3><p>Old version of DivineElegance.</p><p>To merge it by yourself you need:</p><ul><li><p>Step 1: Block Merge (<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0/blob/main/anything-v4.5.ckpt\">Anything V4.5 </a>+ <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix/blob/main/Basil_mix_fixed.safetensors\">BasilMixFixed</a>) at weights 1,0.9,0.7,0.5,0.3,0.1,1,1,1,1,1,1,0,0,0,0,0,0,0,0.1,0.3,0.5,0.7,0.9,1 and Base Alpha 0</p></li><li><p>Step 2: Previous Mix + NovelAI NSFW + NovelAI SFW at Add Difference 0.3</p></li><li><p>Step 3: Previous Mix + AnythingGape (Made of Anything4.5 + Gape60 + NAI NSFW at Add Difference 1.0) + NAI NSFW at Add Difference 0.3</p></li><li><p>Step 4: Previous Mix + <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/Cocoa.ckpt\">Cocoa </a>at Weighted Sum 0.5 = DivineEleganceMix, then, make a TensorFix (aka ClipFix)</p></li></ul><p>That's all you need for base model. Also, you can skip step 3 to avoid more nsfw-ish images in generations.</p><p></p><p>Really BIG thanks to:</p><ul><li><p>Nigurumi for<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/nuigurumi/basil_mix\"> BasilMix</a>.</p></li><li><p>WarriorMama777 for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs\">AbyssOrangeMixes</a> and reciepes.</p></li><li><p>andite for <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0/blob/main/anything-v4.5.ckpt\">Anything4.5</a>/<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion/blob/main/Cocoa.ckpt\">Cocoa</a>/<a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/pastel-mix\">PastelMix</a>.</p></li><li><p>Ikena for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2583/grapefruit-hentai-model\">Grapefruit</a>.</p></li><li><p>Cyria for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16161/zerotolerances\">ZeroTolerances</a>.</p></li><li><p>devdevice545734 for <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7152/facebombmix\">FaceBombMix</a>.</p></li><li><p>You, for reading, downloading and reviewing this mix.</p></li></ul>","ratingcount":36,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AbyssOrangeMix2 - SFW/Soft NSFW":{"status":"inactive","modelid":"civitai-5021","rating":4.86,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/783195a0-a51d-47ef-8cde-c29cb1b9f900/width=450/113922.jpeg","description":"<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2\">AbyssOrangeMix2 (AOM2) HuggingFace Model Card</a><br /><strong>All credit for this model goes to the original author(s) and the repository maintainer on HuggingFace, </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777\"><strong>WarriorMama777</strong></a><strong>. Also, check out their profile on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/WarriorMama777\"><strong>Civitai</strong></a><strong>!</strong><br /><br /><strong>Compatible ControlNets available for this model at </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9557/abyssorangemix2-controlnets\"><strong>Difference ControlNets</strong></a><strong>.</strong><br />For hardcore NSFW, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4451/abyssorangemix2-hardcore\">hardcore</a>. For less hardcore NSFW, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4449/abyssorangemix2-nsfw\">NSFW</a>. For a more anime style, check out <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7911/bloodorangemix-sfwsoft-nsfw-bloodnightorangemix\">BloodOrangeMix - SFW/Soft NSFW</a>. For more of an illustrated/painted style, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8402/eerieorangemix2-sfwsoft-nsfw-eerieorangemix2night\">EerieOrangeMix2 - SFW/Soft NSFW</a>.<br /><br /><strong>Additional Request</strong></p><ul><li><p>Please clearly indicate where modifications have been made if used as a basis for any further work (i.e training, merging/mixing, or extraction), and if used for merging/mixing, please state what steps (i.e. recipe) you took to do so.</p></li></ul><p><br />See <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2\">https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2</a> for a detailed explanation of the model, recipes, and tips on how to best use it.<br /><br /><strong>Additional notes - Using the SD MSE VAE (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\"><strong>https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main</strong></a><strong>) and the Obsidian Skin LoCon (LyCORIS), available at </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18584/obsidian-skin\"><strong>https://civitai.com/models/18584/obsidian-skin</strong></a><strong> for the dark skinned preview image.</strong></p>","ratingcount":35,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AbyssOrangeMix2 - NSFW":{"status":"inactive","modelid":"civitai-5036","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/5595d43e-4ad1-45d3-739a-0dca707cf000/width=450/87056.jpeg","description":"<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2\">AbyssOrangeMix2 (AOM2) HuggingFace Model Card</a><br /><strong>All credit for this model goes to the original author(s) and the repository maintainer on HuggingFace, </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777\"><strong>WarriorMama777</strong></a><strong>. Also, check out their profile on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/WarriorMama777\"><strong>Civitai</strong></a><strong>!</strong><br /><br /><strong>Compatible ControlNets available for this model at </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9557/abyssorangemix2-controlnets\"><strong>Difference ControlNets</strong></a><strong>.</strong></p><p>For more hardcore NSFW, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4451/abyssorangemix2-hardcore\">hardcore</a>. For SFW, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4437/abyssorangemix2-sfw\">SFW</a>. For more of an anime style, check out <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7926/bloodorangemix-nsfw-bloodorangemixhalf\">BloodOrangeMix - NSFW</a>. For more of an illustrated/painted style, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8375/eerieorangemix2-nsfw-eerieorangemix2half\">EerieOrangeMix2 - NSFW</a>.<br /><br /><strong>Additional Request</strong></p><ul><li><p>Please clearly indicate where modifications have been made if used as a basis for any further work (i.e training, merging/mixing, or extraction), and if used for merging/mixing, please state what steps (i.e. recipe) you took to do so.</p></li></ul><p><br />See <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2\">https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2</a> for a detailed explanation of the model, recipes, and tips on how to best use it.<br /><br /><strong>Additional notes - Using the SD MSE VAE (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\"><strong>https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main</strong></a><strong>) and the Obsidian Skin LoCon (LyCORIS), available at </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18584/obsidian-skin\"><strong>https://civitai.com/models/18584/obsidian-skin</strong></a><strong> for the dark skinned preview image.</strong></p>","ratingcount":63,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AbyssOrangeMix2 - Hardcore":{"status":"inactive","modelid":"civitai-5038","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b7dad00b-cf2e-4a24-9fc8-100cc0cb4e00/width=450/92442.jpeg","description":"<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2\">AbyssOrangeMix2 (AOM2) HuggingFace Model Card</a><br /><strong>Credit for this model goes to the original author(s) and the maintainer on HuggingFace, </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777\"><strong>WarriorMama777</strong></a><strong>. Also, check out their profile on </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/user/WarriorMama777\"><strong>Civitai</strong></a><strong>!</strong><br /><br /><strong>Compatible ControlNets available for this model at </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9557/abyssorangemix2-controlnets\"><strong>Difference ControlNets</strong></a><strong>.</strong><br />For less hardcore NSFW, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4449/abyssorangemix2-nsfw\">NSFW</a>. For SFW, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4437/abyssorangemix2-sfw\">SFW</a>. For more of an anime style, check out <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7933/bloodorangemix-hardcore-bloodorangemix\">BloodOrangeMix - Hardcore</a>. For more of an illustrated/painted style, see <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8348/eerieorangemix2-hardcore-eerieorangemix2\">EerieOrangeMix2 - Hardcore</a>.<br /></p><p><strong>Additional Request</strong></p><ul><li><p>Please clearly indicate where modifications have been made if used as a basis for any further work (i.e training, merging/mixing, or extraction), and if used for merging/mixing, please state what steps (i.e. recipe) you took to do so.</p></li></ul><p><br />See <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2\">https://huggingface.co/WarriorMama777/OrangeMixs#abyssorangemix2-aom2</a> for a detailed explanation of the model, recipes, and tips on how to best use it.<br /><br /><strong>Additional notes - Using the SD MSE VAE (</strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\"><strong>https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main</strong></a><strong>) and the Obsidian Skin LoCon (LyCORIS), available at </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/18584/obsidian-skin\"><strong>https://civitai.com/models/18584/obsidian-skin</strong></a><strong> for the dark skinned preview image.</strong></p>","ratingcount":238,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"BRA(Beautiful Realistic Asians) V4":{"status":"inactive","modelid":"civitai-51395","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1a995fcd-1394-4556-bcfb-a65bbb968e00/width=450/553410.jpeg","description":"<p></p><p>If you would like to see more and better versions of Bras please consider supporting (tryna recoup gpu cost lol)</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/bankaiplease\">https://ko-fi.com/bankaiplease</a></p><p>Trained on countless pictures of Beautiful Asian women. (some nsfw images included)</p><p>This is the result of around 3 Months of training and failing and training and merging. After a lot of failures and mild successes I have finally come to a point where it is good enough to release to the public.</p><p>Trained mostly on BLIP and WD, so suggest to use similar style prompts.</p><p>This model is hosted online and can be run on the following website.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://randomseed.co/model/18\">https://randomseed.co/model/18</a></p><p>Example:</p><p>Pretty asian in a black swimsuit leaning against a wall</p><p>Korean with long black hair wearing a red shirt and a red polka dot blouse with long black hair</p><p>a woman with long hair and a black top is posing for a picture with her hand on her chin, 1girl, solo, long_hair, looking_at_viewer, brown_hair, simple_background, black_hair, jewelry, earrings, necklace, lips, black_shirt, ring, realistic</p><p>Negative Prompts:<br />use negative TI embeddings as well as (lowres,worst quality) etc</p><p>Feel Free to use this for merges or mixes, just credit.</p><p>Feel Free to add me on twitter if you have questions, feedback, requests for improvements or want to ask for commisions or whatever:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://twitter.com/PleaseBanKai\">https://twitter.com/PleaseBanKai</a></p>","ratingcount":56,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Art & Eros (aEros) - A tribute to beauty":{"status":"inactive","modelid":"civitai-5180","rating":4.91,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b5d5e0c6-009f-42b5-0ea8-4e06b5f50e00/width=450/39078.jpeg","description":"<p>PLEASE READ DESCRIPTION</p><p>Deprecated model, consider updating to: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5935/liberty\">https://civitai.com/models/5935/liberty</a> it is also <strong><u>licenseless</u></strong></p><p><strong>Very NSFW biased model!!</strong></p><p><em>FINAL UPDATE</em> - <u>Two files added:</u></p><p>-<strong>aErosNoVAE:</strong> It is the exact same file as aEros prunned but<strong><u> without the VAE requirement</u></strong>, which also means that you <em>can now train embeddings</em> succesfully with aEros. (VAE would still be <em>recommended</em> for normal use).</p><p>-<strong>aErosNoVAE-inpainting:</strong> An <u>inpainting focused</u> version fo the model mixing it with SD 1.5 inpainting model.</p><p></p><p>UPDATE: This model has experimented a <u>restrictive change of license </u><strong>ONLY </strong>because it inherited it from some of it's building models.</p><p>Until further notice, I am not developing it anymore.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0\">https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0</a></p><p></p><p>Check any info or questions at our private Discord here: <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/z88HpDwbGq\">https://discord.gg/z88HpDwbGq</a></p><p></p><p><strong>it needs vae-ft-mse-840000-ema-pruned (or another one if you want to get experimental) or it will output broken images.</strong></p><p>Art&amp;Eros is out!!! This is my second model. It is similar to REA (my previous model) in it's concept, and many of it's building materials are the same, so most that worked for REA works for aEros, but it is not an evolution of it. It has been rebuild from the ground to be 'better, faster, stronger'.</p><p>My thanks to everybody who made it possible, because I if there's anything good on it is because the source material was great too. In no particular order to <em>Hassan</em>, <em>AloeVera</em>, the <em>CivitAI Team</em>, <em>Izuek</em>, <em>Someone88</em>, <em>wavymulder</em>, <em>UnstableDiffusion Team, justmaier, moist, sviasem, kavellion</em> and any other creator I might not have been able to cite.</p><p><strong>The main download is the PRUNED safetensors NoVAE version. You have the unpruned ckpt as an optional download.</strong></p><p><u>ABOUT:</u></p><p>First it may not be the best begginer checkpoint out there. I consider myself experienced at prompting so I haven't tried much basic prompts, however I doubt that a plain \"pretty naked woman, big boobs\" is going to take you very far with it. However, although I prompt a bit different than that I have tested that <strong>it understands the words from the language of PhotoReal v0.5</strong> (it is contained within the merge), so if you are having troubles getting good outputs from it you can begin from there, but in general, try to use a more natural language than an array of commas: <a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit\">https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</a></p><p>There's also one screenshot with a very basic example prompt for you to get the idea.</p><p>According to my testing it is a very powerful model for it's purpose, but it is a project I made for myself which means that depending on what you want it may or may not lack certain areas. It has been intensively tested to <strong>generate photorealistic(ish) images of different types of girls in different poses in different places wearing different things with different artistic moods</strong>. Nothing more, nothing less. From hardcore, to to group, to drawing, are out of the scope uses that may or may not work (But have improved since REA). <strong>It's community report that it is very good at fantasy and landscapes/interiors too.</strong></p><p>List of keywords known: <em>'elden ring style', 'postapocalypse', 'knollingcase', 'cyborgdiffusion', 'analog style', 'swpunk', 'synthwave', 'dreamlikeart', 'modelshoot style'</em></p><p><u>'bf' is no longer a trigger word, nor part of the model.</u></p><p><u>HOW TO USE IT:</u></p><ul><li><p>You <strong>MUST USE vae-ft-mse-840000-ema-pruned</strong> (or experimentally other VAEs). Otherwise it breaks.</p></li><li><p>Some users report having problems using something different than Automatic1111webui. Cannot troubleshoot that myself.</p></li><li><p>This model <strong>DOES <u>NOT</u> REQUIRE TO USE TRIGGER WORDS</strong>.</p></li><li><p>Trigger words are general <strong>style or composition modifiers</strong>. They can be used alone or in combination and will give an special mood (or mix) to the image.</p></li><li><p>Trigger words have only been tested using them <strong>at the beggining</strong> of the prompt.</p></li><li><p>There is no longer a proper order to mix trigger words between them, needs experimenting for your desired outputs.</p></li><li><p>Works for a wide variety of steps from 20 to 130 tested. <strong>I use 66 Euler A + hires fix.</strong></p></li><li><p>It works on it's own without triggers at making general or NSFW images of ladies of high quality.</p></li><li><p>Resolutions tested are <em>512x512, 384x704, 512x768</em> and <em>768x768</em>.</p></li></ul><p><u>MERGED:</u></p><p>I haven't kept track of all the steps done in the merge (I used a weird methodology), but this is what's inside in different proportions:</p><ul><li><p>PhotoReal v0.5: <a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit\">https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</a></p></li><li><p>Elden Ring Style: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5/elden-ring-style\">https://civitai.com/models/5/elden-ring-style</a></p></li><li><p>Postapocalypse: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1136/postapocalypse\">https://civitai.com/models/1136/postapocalypse</a></p></li><li><p>Analog Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">https://civitai.com/models/1265/analog-diffusion</a></p></li><li><p>SXD: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1169/sxd\">https://civitai.com/models/1169/sxd</a></p></li><li><p>Knollingcase: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1092/knollingcase\">https://civitai.com/models/1092/knollingcase</a></p></li><li><p>Hassan's 1.4 and CandyBerry: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-all-versions\">https://civitai.com/models/1173/hassanblend-all-versions</a></p></li><li><p>PurePornPlus: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1235/purepornplus-merge\">https://civitai.com/models/1235/purepornplus-merge</a></p></li><li><p>SimpMaker 3K1: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1258/aloeveras-simpmaker-3k-series\">https://civitai.com/models/1258/aloeveras-simpmaker-3k-series</a></p></li><li><p>Modelshoot style: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2147/modelshoot-style\">https://civitai.com/models/2147/modelshoot-style</a></p></li><li><p>SynthPunk Search: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2856/synthpunk-search\">https://civitai.com/models/2856/synthpunk-search</a></p></li><li><p>MoistMix: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3450/moistmix\">https://civitai.com/models/3450/moistmix</a></p></li><li><p>Dreamlike Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1274/dreamlike-diffusion-10\">https://civitai.com/models/1274/dreamlike-diffusion-10</a></p></li><li><p>Cyborg Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1365/cyborg-diffusion\">https://civitai.com/models/1365/cyborg-diffusion</a></p></li><li><p>It also works GREAT as an extra style modifier with this hypernetwork for extra artistic outputs: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1141/mjv4-hypernetwork\">https://civitai.com/models/1141/mjv4-hypernetwork</a></p></li><li><p>Honorable mention tu Uber, whose model is not part of the merge, but helped me imrprove general hardcore capacity of aEros: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661/uber-realistic-porn-merge-urpm\">https://civitai.com/models/2661/uber-realistic-porn-merge-urpm</a></p></li></ul><p><u>TROUBLESHOOT:</u></p><ul><li><p>Images are a chaotic trip of LSD colors: <em>You are not using the VAE.</em></p></li><li><p>I promiss that I have the VAE!!!: <em>If you swear over the grave of Chanquete, then another user of Discord found the solution, but please, BE SURE THAT YOU HAVE THE VAE WORKING FOR OTHER MODELS:</em></p><p><strong>xtrebel - </strong><em>\"In case anyone else is still having trouble with LSD colors, despite having the correct VAE loaded like me... I discovered this checkbox in settings has to be off/unchecked for it to properly load the VAE:</em><br /><em>[ ] ignore selected VAE for stable diffusion checkpoints that have their own .</em><a target=\"_blank\" rel=\"ugc\" href=\"http://vae.pt\"><em>vae.pt</em></a><em> next to them</em>\"</p></li><li><p>Images seem like real images but are a mess of body horror and whatnot: <em>You need to keep working in your prompt. This is <u>NOT</u> an easy to use model (not rocket science either).</em></p></li></ul><p><u>FUTURE:</u></p><p>This project is considered finished. From now on it is going to become my base model. I may start to train it as the big kids do. But I am more likely gonna try to update it with the updates some of the building materials have experimented. Be it aEros v2 or a totally new thing... Who knows? The sky is the limit!!! Stay tuned on:</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://linktr.ee/ainecaptain\">https://linktr.ee/ainecaptain</a></p>","ratingcount":105,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"526Mix V1.4.5":{"status":"inactive","modelid":"civitai-53814","rating":4.91,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/efe63e22-248e-4f9e-a63c-1c8a94078c00/width=450/582417.jpeg","description":"<p>This model is a tad overbaked, so you'll <u>likely want to keep CFG at 5-6 usually</u>. I've tried down-weighting the model, but even a small 5% dilution with SD 1.5 can be awful for a noticeable number of prompts. This is the most fun it gets, folks.<br /><br />Example images generated in InvokeAI with DDIM, using high res optimization (img2img, 0.47 strength) to upscale from a low resolution. <u>Some prompts may need closer to 40 steps to come out with the cleanest detail if you're using a different method of high res optimization than I am.</u><br /></p><p><strong>&lt;neg-sketch-2&gt;</strong> negative embedding for photographic and 3D images can be found here: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/JPPhoto/neg-sketch-2\">https://huggingface.co/JPPhoto/neg-sketch-2</a>. Works great with this model for boosting photorealism and reducing the amount of negative prompting to bring out better photos and 3D art, though does occasionally have odd behavior in some prompts (e.g. interior photos and spaghetti demons in particular).</p><p></p><p><strong>Update V1.4.5</strong>: This version tries to somewhat improve peoples' eyes and general coherence somewhat, on average. Also, it's a touch less dark. This was accomplished by building a sub-mix with similar behavior to V1.4, but with better eyes and 50% noise offset, then mixing that in at 20% and hoping for the best. Seemed to work okay. Has occasional interpolation weirdness in a few prompts.</p><p></p><p>Anime / 2D animated-optimized version here: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/35893?modelVersionId=42086\">https://civitai.com/models/35893?modelVersionId=42086</a></p><p>Surreal / vivid illustration mix: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/44596\">https://civitai.com/models/44596</a></p><p></p><p>My personal merge of Stable Diffusion 1.5 custom models using the noise offset to improve contrast and dark images. An inpainting model is provided to make inpainting in the model’s styles and detail easier. <strong><em>'Negative' embeddings generally not recommended as they interfere with art styles and aesthetics (unless that's what you want, of course).</em></strong></p><p></p><p>This model is meant to be:</p><ul><li><p>Artistic and elegant</p></li><li><p>Drop-dead easy to work with</p></li><li><p>Good at making cool characters and landscapes</p></li><li><p>Not bound or leaning towards any single style</p></li><li><p>Killer at digital and conventional art in many aesthetics</p></li><li><p>And above all, fun</p></li></ul><p>If your images come out a little crunchy or there's a bright blue/white artifact, turn your step count up a little, and you should be set. <u>I normally use DDIM at 30-35 steps with high resolution optimization ON (essentially img2img upscaling, whatever the equivalent in your UI might be). In InvokeAI, I use 0.45-0.55 high res optimization strength, which is a bit lower than the default. If your results are a bit too sharp or crispy, try making sure your high-res fix strength isn't too high as well.</u></p><p></p><p>It’s not so great at explicit sexual content and anime*, including anime-based embeddings. There’s a million other models for those if that’s what you’re after. <br /><br />*There is some ability to bring out a neat anime aesthetic when you prompt for 'anime style', which I find to be quite cool to look at, although it can be a bit finicky. If you try to make anime-esque art with this model, do not put 'portrait' in your negative prompt, or use 'close' or 'closeup' in your positive prompt, as those seem to force it into a 3d-like style even if you add more weight on the anime style.</p><p></p><p>I want to also bring attention to whosawhatsis' <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/10540/verisimilitude\">verisimilitude,</a> which is great at readily making wallpaper-quality photorealistic stuff.</p><p></p><p>I also want to shoutout coreco and his <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">seek.art MEGA v2</a>, which was responsible for much of the composition of V1.3-V1.4, and is an excellent update to his Mega model capable of fun and artistic things and realism that this model doesn't (albeit since it's not a mix but a finetune by just one person, it takes more tinkering, but that's okay).</p><p></p><p>This model has a baked-in VAE based on <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4\">Waifu Diffusion 1.4</a> by hakurei. You can switch this out (such as to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">vae-ft-mse-840000-ema-pruned</a>) if you wish, though I used that one specifically because it helped improve detail quality in some art styles and situations.</p><p></p><p>Example images were generated in Invoke AI with the model converted to Diffusers format, hires fix on, and the sampler k_dpmpp_2 (unless listed otherwise). This means unless you use Invoke AI, you likely won't be able to recreate my images exactly. Just learn from the prompts and modify the weighting in prompts as needed for the UI you use (if you use the A1111 UI, any (plus sign)+ is equal to one set of parentheses).</p><p></p><p>By downloading, you agree to the creativeml-openrail-m and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md\">Dreamlike-art</a> licenses.</p><p></p><p>Credits (V1.4 / V1.3.5):</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3738/roboetics-mix\">Roboetic’s Mix</a> – Roboetic</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">seek.art MEGA v2</a> – coreco</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1116/rpg\">RPG V4</a> – Anashel</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/16371\">HeStyle V1.5</a> - krstive</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8067/movie-diffusion-v12\">Movie Diffusion</a> - Dalle2Pictures</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">Analog Diffusion</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2292/portrait\">Portrait+</a> - wavymulder</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/9388/realscifi\">RealSciFi</a> - AIfriend</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Dunkindont/Foto-Assisted-Diffusion-FAD_V0\">Foto-Assisted Diffusion</a> - Dunkindont</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3164/fantasy-art-style\">fantasy-art-style v1.8</a> - kasukanra</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/22h/vintedois-diffusion-v0-2\">Vintedois Diffusion</a> - Predogl and piEsposito</p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.crosslabs.org/blog/diffusion-with-offset-noise\">noise offset</a> – Nicholas Guttenberg</p></li></ul>","ratingcount":34,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"AnythingElse V4":{"status":"inactive","modelid":"civitai-5581","rating":4.5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c128dda2-207b-4d6f-0d20-33bb8e3b6d00/width=450/44683.jpeg","description":"<p><strong>Note</strong>: We've been told that this is just a troll and not an official version of Anything V4.</p><p>Originally <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/anything-v4.0\">posted to Hugging Face by Andite</a></p><p>Thanks to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Linaqruf\"><strong><u>Linaqruf</u></strong></a> for letting me borrow his model card for reference.</p><p>Welcome to Anything V4 - a latent diffusion model for weebs. The newest version of Anything. This model is intended to produce high-quality, highly detailed anime style with just a few prompts. Like other anime-style Stable Diffusion models, it also supports danbooru tags to generate images.</p><p>e.g. <strong><em>1girl, white hair, golden eyes, beautiful eyes, detail, flower meadow, cumulonimbus clouds, lighting, detailed sky, garden</em></strong></p><p>I think the V4.5 version better though, it's in this repo. feel free 2 try it</p>","ratingcount":117,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Kotosmix":{"status":"inactive","modelid":"civitai-6087","rating":4.93,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/62f620e7-8ff8-4f86-bc96-d6e2016c5e00/width=450/52456.jpeg","description":"<p>This is a general purpose model able to do pretty much anything decently well from realistic to anime to backgrounds</p><p>All the images are raw outputs (with some using highresfix) no postprocessing involved or img2img upscaling</p><p></p><h3>Prompt style</h3><p>Keep it short and simple. If you want realism simply add (Realistic:1.5) to the beginning of your prompt and don't overcomplicate things</p><p></p><p>I recommend using DPM++ 2M Karras as the sampler</p><p></p><p>The images uploaded were upscaled through</p><p></p><p>latent(bilinear) 0.55-0.6 denoise upscaled by 1.5-2.5 OR</p><p>ESRGAN-4x 0.3-0.5 denoise upscaled by 1.5-2</p><p></p><h3>Where are the negative embeddings you used?</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/embed/EasyNegative/tree/main\">https://huggingface.co/embed/EasyNegative/tree/main</a></p><p></p><h3>My generations are all desaturated and not colourful like yours?</h3><p><a target=\"_blank\" rel=\"ugc\" href=\"https://stable-diffusion-art.com/how-to-use-vae/\">https://stable-diffusion-art.com/how-to-use-vae/</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/yesyeahvh/bad-hands-5/tree/main\">https://huggingface.co/yesyeahvh/bad-hands-5/tree/main</a></p><p>these are the best ones</p><p></p><h3>My generations STILL don't look like yours?</h3><p>Did you use clip skip 2 and xformers AND the negative embeddings?</p><p></p><p>The images with longer prompts are very old generations I made back in October of 2022 there has been ALOT of changes since then and you might have a hard time replicating those gens.</p><p></p><p></p><p></p><h3>What vae did you use?</h3><p>For most of the images above I used the orange vae.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/VAEs/orangemix.vae.pt\">https://huggingface.co/WarriorMama777/OrangeMixs/blob/main/VAEs/orangemix.vae.pt</a></p><p></p><p>However I would recommend <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt</a> as It gives you much more vibrant realistic colours</p><p></p><h3>My generations have ugly faces?</h3><p>After some recent updates to auto1111 some things have changes. One noticeable thing is the order of the prompts you use matter ALOT more. Try reducing the prompt and use HIRESFIX or generating at a higher resolution</p><h3>I want to replicate the first image in the previews?</h3><h3><a target=\"_blank\" rel=\"ugc\" href=\"https://files.catbox.moe/y9pfir.png\">https://files.catbox.moe/y9pfir.png</a></h3><p>the link above has the image with all the metadata</p><p></p>","ratingcount":174,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"StablyDiffused's Aesthetic Mix":{"status":"inactive","modelid":"civitai-6266","rating":4.89,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/bc93a02b-c6e5-446b-d9cc-aacaf9515500/width=450/55081.jpeg","description":"<p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/coreco/seek.art_MEGA/blob/main/LICENSE.txt\"><strong>Seek Art license</strong></a><strong>, </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\"><strong>Dreamlike license</strong></a><strong>.</strong></p><p>This is a mix of some of my favorite models to create something that captures the aesthetic I like but also without sacrificing NSFW capabilities. Basically an 'almost' do everything mix for me.</p><p>For best results use the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">Standard SD VAE.</a></p><p>Disclaimer: All prompts in the example images use InvokeAI Syntax NOT Automatic1111 syntax. The key thing you need to know is that 'term+' is equivalent to '(term)' ++ is the same as (()) and so on.</p><h2>Version 2:</h2><p>Well... Where to start... This has been a very long project. After using V1 for a while there were several things I just wasn't happy with and felt it needed updates. I tried many different merges and couldn't get what I wanted out of it. I really like Protogen 5.3 and wanted to use it as the base, but I felt like I couldn't get it to give me what I wanted Luckily <span data-type=\"mention\" class=\"mantine-1yiar0p\" data-id=\"mention:49070\" data-label=\"darkstorm2150\">@darkstorm2150</span> was gracious enough to outline his <a target=\"_blank\" rel=\"ugc\" href=\"https://www.reddit.com/r/StableDiffusion/comments/1079c0d/protogen_checkpoint_merging_data_reference/\">full recipe on Reddit</a> and explained how to build protogen from the ground up. I studied this for a while and dug deep into it. In the end I settled on rebuilding using a similar recipe but with several tweaks so that I could get something else out of it. So Version 2 is a complete and total rebuild. Keeping in fashion with Darkstorm who provided the base recipe I will also provide my full recipe below so that you can fully see what I changed.</p><p>The following Recipe was created on Automatic1111 WebUI using the Checkpoint Merger tool. There are two possible formulas that show in this recipe.</p><p>Primary Model (A) + Secondary Model (B) @ Multiplier (M) -- This indicates that a Weighted Sum merge was used</p><p>Primary Model (A) + (Secondary Model(B) - Tertiary Model (C)) @ Multiplier (M) -- This indicates Add Difference was used</p><p>Aesthetic_v1.1 = <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1188/f222\">f222_v1</a> + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3866/elldreths-imagination-mix\">elldrethSImagination_v10</a> @ 0.85</p><p>Aesthetic_v1.2 = <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\">hassanBlend1512And_hassanBlend1512_1</a> + Aesthetic_v1.1 @ 0.85</p><p>Aesthetic_v1.3 = Aesthetic_v1.2 + (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1116/rpg\">rpg_rpgV3Candidate16</a> - <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/runwayml/stable-diffusion-v1-5\">v1.5-pruned-emaonly</a>) @ 0.15</p><p>Aesthetic_v1.4 = Aesthetic_v1.3 + (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1315/seekart-mega\">seek_art_mega_v1</a> - <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/runwayml/stable-diffusion-v1-5\">v1.5-pruned-emaonly</a>) @ 0.25</p><p>Aesthetic_v1.5 = Aesthetic_v1.4 + (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2147/modelshoot-style\">modelshoot-1.0</a> - <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/runwayml/stable-diffusion-v1-5\">v1.5-pruned-emaonly</a>) @ 0.15</p><p>Aesthetic_v1.6 = Aesthetic_v1.5 + (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4750/daugeph\">daugeph_daugeph</a> - Aesthetic_v1.5) @ 0.25</p><p>Aesthetic_v1.7 = Aesthetic_v1.6 + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3450/moistmix-v1\">moistmixV1_moistmixV1</a> @ 0.1</p><p>Aesthetic_v1.8 = Aesthetic_v1.7 + <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/prompthero/openjourney-v2/tree/main\">openjourney-v2-unpruned</a> @ 0.05</p><p>Aesthetic_v1.9 = Aesthetic_v1.8 + <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">analog-diffusion-1.0</a> @ 0.05</p><p>Aesthetic_v2.0 = Aesthetic_v1.9 + (<a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3811/dreamlike-photoreal-20\">dreamlikePhotoRealV2</a> - <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/runwayml/stable-diffusion-v1-5\">v1.5-pruned-emaonly</a>) @ 0.05</p><p></p><p>The prunes that are available are fp16 no-ema prunes created using the Model Converter extension in Automatic1111 and I have confirmed that they produce the same results as the unpruned versions. All example images were generated using InvokeAI from the pruned CKPT version using gfpgan face restoration at 0.8 strength and with High Res Optimization turned on.</p><p></p><h2>Version 1:</h2><p>Models used in the original mix:</p><ul><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3627/protogen-v22-anime-official-release\">Protogen 2.2</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3816/protogen-x53-photorealism-official-release\">Protogen 5.3</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2747/elldreths-vivid-mix\">Elldreth's Vivid Mix v1</a></p></li><li><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661/uber-realistic-porn-merge-urpm\">URPM v1.2</a></p></li></ul>","ratingcount":37,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Kenshi":{"status":"inactive","modelid":"civitai-6792","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/164653b5-9392-440b-b62e-da98f2cc4100/width=450/261941.jpeg","description":"<h1><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/40199/aurora\">Be sure to Check out Aurora 💛 - Luna</a></h1><p></p><h1>Kenshi</h1><img src=\"https://i2.lensdump.com/i/TAxjOD.png\" alt=\"TAxjOD.png\" /><h1></h1><p><strong>“Do I hide or do I roam? That indecision… Now the world has changed and I’ve missed it all.”</strong></p><p></p><p><strong>Kenshi</strong> is my merge which were created by combining different models. <strong><em>This includes models such as Nixeu, WLOP, Guweiz, BoChen, and many others.</em></strong></p><p></p><p><code>My goal is to archive my own feelings towards styles I want for Semi-realistic artstyle. Through this process, I hope not only to gain a deeper understanding of my own artistic preferences, but also to inform and refine the capabilities of my personal skills and AI Art as it generates artwork that reflects my desired style.</code></p><p></p><p>Kenshi because it represents strength, resilience, and the ability to adapt and overcome challenges. Just like AI.</p><h1></h1><h1></h1><h2><strong>Usage</strong></h2><p>These are my settings I <strong><em>always </em></strong>use it is recommended <strong><em>but not essential;</em></strong></p><p><strong>Steps: 20+</strong></p><p><strong>Sampler: DPM++ 2M Karras</strong></p><p><strong>CFG scale: 2 to 7</strong></p><p><strong>Size: 600x800</strong></p><p><strong>Clip skip: 2</strong></p><p><strong>ENSD: 31337</strong></p><p><strong>Hires Fix : Enabled</strong></p><p><strong>Upscale by : 1.5</strong></p><p><strong>Upscaler : </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://de-next.owncube.com/index.php/s/x99pKzS7TNaErrC\"><strong>https://de-next.owncube.com/index.php/s/x99pKzS7TNaErrC</strong></a></p><p></p><p>Put Upscaler file inside [YOURDRIVER:\\STABLEDIFFUSION\\stable-diffusion-webui\\models\\ESRGAN]</p><p></p><p>In this case my upscaler is inside this folder.</p><p>E:\\SD\\stable-diffusion-webui\\models\\ESRGAN</p><p></p><p></p><p><strong>Kenshi is not recommended for new users since it requires a lot of prompt to work with I suggest using this if you still want to use the model (install it as an extension on Automatic1111 WebUI) : </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"><strong>https://github.com/DominikDoom/a1111-sd-webui-tagcomplete</strong></a></p><h1></h1><h1></h1><h3><strong>Versatility</strong></h3><p>Unlike most models, <strong>Kenshi </strong>is known for its <strong>versatility</strong>, able to perform various styles with remarkable results. I've undergone testing with <strong><em>over 30 to 50 styles</em></strong> and most of the time I get remarkable results. I recommend using <strong>Lora </strong>and <strong>Embedding</strong> to improve this even further.</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/b93086e5-acfd-4637-8120-5da341992600/width=525\" /><p></p><h2><strong>VAE</strong></h2><p>I recommend <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/blob/main/vae/kl-f8-anime2.ckpt\"><strong><u>kl-f8-anime2.ckpt</u></strong></a> VAE from waifu-diffusion-v1-4 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hakurei\"><strong><u>which is made by hakurei.</u></strong></a></p><p></p><p>On <strong>CivitAI</strong>, I have uploaded baked version, you do not need to install VAE anymore if you want to.</p><img src=\"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/3838ba14-a32c-436a-828d-56c729d29500/width=525\" /><h3><strong><em>VAE is important, please download it.</em></strong></h3><h1></h1><h1></h1><h2>Hugging Face</h2><p>For more information and easier to read or download, please use this link</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SweetLuna/Kenshi\">https://huggingface.co/SweetLuna/Kenshi</a></p><h1></h1><h1></h1><h1>Demo</h1><p>We have a Demo version available on <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/pD9MKyBgNp\">Discord</a>.</p><p>The demo doesn't have hires and incorrect settings, so it isn't the best way to judge this model. It exists for testing reasons.</p><img src=\"https://i.lensdump.com/i/RwAkqx.png\" alt=\"RwAkqx\" /><h1></h1><h1></h1><h1><strong>Merge Recipes</strong></h1><p><a target=\"_blank\" rel=\"ugc\" href=\"https://www.figma.com/file/aESyZAxHxBJjE63gog5ExZ/KENSHI?node-id=0%3A1&amp;t=2ULQWeLUSIWhk1aE-0\"><strong><u>Here is my Cookbook that you can check out.</u></strong></a></p><p></p><img src=\"https://i2.lensdump.com/i/RLCJIH.png\" alt=\"COOKBOOK\" /><h1></h1><h1>Donation</h1><p>I've been working hard to complete my college education. The thing is, paying for college is no joke and I've been feeling the pressure of the mounting bills.</p><p></p><p>I know times are tough for everyone, but if you're able to help in any way, I would be forever grateful.</p><p></p><p>Considering supporting me on <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/thesweetluna\"><strong>Patreon</strong></a></p><h1></h1><h2>Embeddings</h2><p>I recommend grabbing <strong><em>all</em></strong> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Nerfgun3\"><strong><u>Nerfgun3</u></strong></a> embeddings <strong><em>and</em></strong> Sirveggie <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/SirVeggie/nixeu_embeddings\"><strong><u>nixeu_embeddings</u></strong></a></p><p></p><p>Additional Embeddings that I found on Discord :</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://cdn.discordapp.com/attachments/1032948846197747731/1069660323709190195/bad-hands-5.pt\">Bad-Hands-5.pt</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://cdn.discordapp.com/attachments/1032948846197747731/1069660324405452840/vile_prompt3.pt\">Vile_prompt3.pt</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://cdn.discordapp.com/attachments/1032948846197747731/1069660324720017510/bad_quality.pt\">Bad_quality.pt</a><br /><a target=\"_blank\" rel=\"ugc\" href=\"https://cdn.discordapp.com/attachments/1032948846197747731/1069660431309864990/bad-image-v2-39000.pt\">Bad-image-v2-39000.pt</a></p><p></p><p>Credit to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Nerfgun3\"><strong><u>Nerfgun3</u></strong></a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/hesw23168\"><strong>Bob</strong></a> for these Quality of life embeddings, you guys are amazing.</p><p></p><p><strong>ChatGPT Prompt:</strong></p><p></p><p><em>(A cursed knight, clad in black armor,) must journey through a desolate, haunted land to reach the Elden Ring and lift the (curse that plagues their soul.)Along the way, they encounter other travelers, (each struggling with their own demons and secrets), As they draw closer to the Elden Ring, they are confronted with visions of their past mistakes, (all tinged with a red hue,)</em></p><p><em>looking at viewer, highres, superb, 8k wallpaper, extremely detailed, intricate, unreal engine 5, volumetric lighting, realistic, realistic lighting, cinematic, 4k, cinematic lighting, 8k, depth of field, 3d, perfect, award-winning, hyper-detailed, photorealistic, ultra realistic, realistic light, hard lighting, intricate details, stop motion, hyperfocus, tonemapping, sharp focus, hyper detailed, detailed eyes, eyes focus, (illustration:1.1), highres, (extremely detailed CG unity 8k wallpaper:1.1), (beautiful face:1.15), (cowboy_shot:1.5)</em></p><p><em>(nixeu_soft:0.7), (nixeu_white:0.7),</em></p><p></p><p>These prompts are generated by ChatGPT, with embedding and lighting I use which you can copy and paste.</p><h1></h1><h1></h1><h2><strong>License</strong></h2><p>This embedding is open access and available to all, with a CreativeML OpenRAIL-M license further specifying rights and usage. The CreativeML OpenRAIL License specifies:</p><ol><li><p>You can't use the model to deliberately produce nor share illegal or harmful outputs or content</p></li><li><p>The authors claims no rights on the outputs you generate, you are free to use them and are accountable for their use which must not go against the provisions set in the license</p></li><li><p>You may re-distribute the weights and use the model commercially and/or as a service. If you do, please be aware you have to include the same use restrictions as the ones in the license and share a copy of the CreativeML OpenRAIL-M to all your users (please read the license entirely and carefully) <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/spaces/CompVis/stable-diffusion-license\"><strong><u>Please read the full license here</u></strong></a></p></li></ol><p></p><p><strong>Patreon</strong>: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/thesweetluna\"><strong>https://www.patreon.com/thesweetluna</strong></a></p>","ratingcount":64,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Corneo's 7th Heaven Mix":{"status":"inactive","modelid":"civitai-6878","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1936128b-cbba-41e2-c002-0be9e7607e00/width=450/62865.jpeg","description":"<p>This is a checkpoint mix I've been experimenting with - I'm a big fan CocoaOrange / Latte, but I wanted something closer to the more anime style of Anything v3, rather than the softer lines you get in CocoaOrange. If that sounds like something you want, this is the mix for you!</p><p><em>And yes, it does NSFW quite well.</em></p><p>The recipe is fairly simple:</p><p>35% Cocoa from <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/andite/yohan-diffusion\">https://huggingface.co/andite/yohan-diffusion</a><br />35% Counterfeit v2 from <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.0\">https://huggingface.co/gsdf/Counterfeit-V2.0</a><br />30% 7th Anime v2_A from <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/syaimu/7th_Layer\">https://huggingface.co/syaimu/7th_Layer</a></p><p>The comparison images were all generated using the Anything v3 VAE and no hypernetwork.</p><p>If you enjoy this embed, I genuinely love seeing your creations with it - you can attach them to a review if you're not aware (but not comments sadly)!</p>","ratingcount":81,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Liberty":{"status":"inactive","modelid":"civitai-6908","rating":4.68,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/d045e1d7-cff8-4ba1-3e6c-c9f635ecaf00/width=450/123962.jpeg","description":"<p>PLEASE READ DESCRIPTION</p><p>Patreon at the begining :) ! <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/user?u=84473395\">https://www.patreon.com/user?u=84473395</a></p><p>Also, we now have an sponsor!! You can use Liberty model at their website without any hardware or installation requirements!: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/\">https://www.mage.space/</a></p><p><strong>Extremely NSFW biased model!!!</strong> But awesome at SFW too. <em>Use it at your own risk of getting <u>unprompted</u> explicit images</em>.</p><p>This is not an easy to prompt model, <em>nor the best one for begginers.</em></p><p></p><p>According to one user: \"<em>If you have the model-keyword extension make sure you uncheck it. It appends all the triggers words and results in complete nonsense results. Was getting super frustrated that even copy/pasting prompts gave me trash</em>\".</p><p></p><p>Check any info or questions at our private Discord here: <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.gg/z88HpDwbGq\">https://discord.gg/z88HpDwbGq</a></p><p></p><p><strong>MODEL </strong>(there are two possibilities)<strong>:</strong></p><ul><li><p><strong>Liberty-Main:</strong> <u>You should be using this model.</u> It might not be the easiest one to prompt depending on your style. But you'll get used to it soon and is the most powerful one.</p></li><li><p><strong>Liberty-BadClip:</strong> This version <u>uses a broken CLIP model</u> in the same style aEros CLIP model was broken, so outputs are very different from main version. If you really know what you are doing, or you really don't want to change your prompting style from aEros and it performs bad in main version, or are getting general bad results with main one, etc... you could <em>try</em> this one. Keep in mind that some UIs have problems with broken CLIPS. Also that I won't continue or support this version of the model.</p></li></ul><p><strong>VERSIONS </strong>(both models have 3 versions + 1 pix2pix version)<strong>:</strong></p><ul><li><p><strong>Standart:</strong> Intended for general use. It has VAE <a target=\"_blank\" rel=\"ugc\" href=\"http://vae-ft-mse-840000-ema-pruuned.vae.pt\">vae-ft-mse-840000-ema-pruuned.vae.pt</a> baked in. There's no need to use any additional file.</p></li><li><p><strong>Inpainting:</strong> Intended to use in the inpainting section of the img2img tab, it is mixed with original SD 1.5 inpainting model and is much more coherent whith masking areas. <strong>Only select it for that purpose. </strong>There's no need to use any additional file.</p></li><li><p><strong>Pix2Pix:</strong> Main Version exclusive. Intended to be used as a pix2pix option of the img2img tab, it is mixed with original 1.5 pix2pix model. <strong>Only select it for that purpose. </strong>There's no need to use any additional file.</p></li><li><p><strong>Training:</strong> Intended to use in the Train tab, for embedding creation. It uses SD 1.5 original VAE baked in, so it doesn't deepfries embeddings. <strong>Only select it for that purpose. </strong>There's no need to use any additional file.</p></li></ul><p>All of the files are <strong>provided in <em>ckpt</em> and <em>safetensors</em></strong> format for your convenience ;)</p><p><strong>ABOUT:</strong></p><p>Liberty is freedom. A merge with <strong>over 23 other models</strong> with a methodical, careful and genuine approach. Check 'CREDITS' section for the full list.</p><p>Freedom of prompting art or photo or both, landscapes or backgrounds or interiors, people or entities or scenes, stiff poses or movement or even mouth and facial emotions, SFW or nudes or even hardcore sex. I tried to make it as versatile as possible and merged it with half CivitAI to get the most out of any <strong><u>free</u></strong> model out there.</p><p>And it is <em>free to use for any open source purpose, commercial or no</em>t. All the models I used <u>were licenseless when I grabbed them</u>, although some have changed licenses afterwards. However it is also much more modular in it's development process, which means that if any problem arised, I could rebuild it much quickier to avoid getting chained to a license or other type of problems.</p><p><strong>HOW TO USE:</strong></p><ul><li><p>This model <strong><u>does not need to use any of it's trigger words</u></strong>. They are a tool, and the knowledge of those trigger words is deeper known and better accesed directly. So '<em>a photo of a cyborg woman</em>' will work better than '<em>cyborgdiffusion, photo of a woman'</em>, but you can also try '<em>cyborgdiffusion, photo of a cyborg woman</em>' or even '<em>cyborgdiffusion, photo of a knight woman</em>' for special and unique effects. If you want to get an idea of what they can help to achieve visit the 'CREDITS' section to check the models they come from.</p></li><li><p>I mainly <strong>try natural language</strong> for my tests. <strong>You have an example prompt screenshot</strong> avaible to build from there if you want to. There's a more advanced prompting guide at my Patreon: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/posts/aines-prompting-77121972\">https://www.patreon.com/posts/aines-prompting-77121972</a></p></li><li><p>It is merged with UnstablePhotoreal (but with much less weight than aEros), and it reacts well to their prompting language, <u>you don't need to use it as comma separated tags</u>: <a target=\"_blank\" rel=\"ugc\" href=\"https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit\">https://docs.google.com/document/d/1-DDIHVbsYfynTp_rsKLu4b2tSQgxtO5F6pNsNla12k0/edit</a></p></li><li><p>As with my other models I have tested most intensively how good it is at making <em>erotic and artistic nudes</em>. But this time I have tried many other types of prompts too, some of them borrowed. But keep in mind that some uses are edge case. For example <em>it is not so good at hardcore sex scenes as far as I know</em>, you'll get more consistent and effective sex scenes at other specialised models instead of Liberty. And it won't make the best anime art out there either.</p></li><li><p>It may not be the easiest model to use, give it some time to get used to it :)</p></li></ul><p><strong>CREDITS</strong> (Many thanks in no particular order to all of the authors of this awesome models, part of Liberty, without them this wouldn't exist)<strong>:</strong></p><ul><li><p>UBER v1.2: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/2661/uber-realistic-porn-merge-urpm\">https://civitai.com/models/2661/uber-realistic-porn-merge-urpm</a></p></li><li><p>Analog Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1265/analog-diffusion\">https://civitai.com/models/1265/analog-diffusion</a></p></li><li><p>Artificial Journey: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5279/artificialjourney-v10-768\">https://civitai.com/models/5279/artificialjourney-v10-768</a></p></li><li><p>Cyborg Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1365/cyborg-diffusion\">https://civitai.com/models/1365/cyborg-diffusion</a></p></li><li><p>David Tennant: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4125/david-tennant\">https://civitai.com/models/4125/david-tennant</a></p></li><li><p>Elden Ring Style V3: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/5/elden-ring-style\">https://civitai.com/models/5/elden-ring-style</a></p></li><li><p>GTM V1: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4525/galaxytimemachines-gtmultimateblendv1\">https://civitai.com/models/4525/galaxytimemachines-gtmultimateblendv1</a></p></li><li><p>Hassan V1.4: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1173/hassanblend-1512-and-previous-versions\">https://civitai.com/models/1173/hassanblend-1512-and-previous-versions</a></p></li><li><p>Hunter69: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4680/hunter69-v1\">https://civitai.com/models/4680/hunter69-v1</a></p></li><li><p>Knollingcase: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1092/knollingcase\">https://civitai.com/models/1092/knollingcase</a></p></li><li><p>Myztery V2: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3947/myztery-a-class-based-fantasy-model\">https://civitai.com/models/3947/myztery-a-class-based-fantasy-model</a></p></li><li><p>Postapocalypse: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1136/postapocalypse\">https://civitai.com/models/1136/postapocalypse</a></p></li><li><p>Sci-Fi Diffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4404/sci-fi-diffusion-v10\">https://civitai.com/models/4404/sci-fi-diffusion-v10</a></p></li><li><p>SynthwavePunk V2 (<em>do not mistake it with the licensed one</em>): <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1102/synthwavepunk\">https://civitai.com/models/1102/synthwavepunk</a></p></li><li><p>SXD V1: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1169/sxd\">https://civitai.com/models/1169/sxd</a></p></li><li><p>Project Unreal Engine 5: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4752/project-unreal-engine-5\">https://civitai.com/models/4752/project-unreal-engine-5</a></p></li><li><p>Unstable PhotoReal V0.5: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/3753/unstablephotorealv5\">https://civitai.com/models/3753/unstablephotorealv5</a></p></li><li><p>Vintedois: <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/22h/vintedois-diffusion-v0-1\">https://huggingface.co/22h/vintedois-diffusion-v0-1</a></p></li><li><p>Wavyfusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1196/wavyfusion\">https://civitai.com/models/1196/wavyfusion</a></p></li><li><p>AltroticArt's Penis Model: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1245/airoticarts-penis-model\">https://civitai.com/models/1245/airoticarts-penis-model</a></p></li><li><p>Homoerotic V2: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1256/homoerotic\">https://civitai.com/models/1256/homoerotic</a></p></li><li><p>SimpMaker 3K1: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1258/aloeveras-simpmaker-3k-series\">https://civitai.com/models/1258/aloeveras-simpmaker-3k-series</a></p></li><li><p>F222: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1188/f222\">https://civitai.com/models/1188/f222</a></p></li></ul><p></p><p><em>Let's all have fun and play together!</em></p>","ratingcount":59,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"RPG":{"status":"inactive","modelid":"civitai-7133","rating":4.95,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e0b0da8b-b31c-4be0-fa5a-8409caa2d800/width=450/234899.jpeg","description":"<p><strong>NEW: Download the new User Guide here: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Anashel/rpg/resolve/main/RPG-V4-Model-Download/RPG-Guide-v4.pdf\"><strong>RPG User Guide v4.3</strong></a></p><p>Available on:</p><ul><li><p>Originally posted to <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Anashel/rpg\">HuggingFace by Anashel</a></p></li><li><p>Mage: <a target=\"_blank\" rel=\"ugc\" href=\"https://www.mage.space/u/Anashel\">https://www.mage.space/u/Anashel</a></p></li><li><p>RunDiffusion: <a target=\"_blank\" rel=\"ugc\" href=\"https://rundiffusion.com/\">https://rundiffusion.com/</a></p></li><li><p>StableHorde: <a target=\"_blank\" rel=\"ugc\" href=\"https://stablehorde.net/\">https://stablehorde.net/</a></p></li></ul><p><br />STATUS: <strong>RELEASE</strong><br />VERSION <strong>4.0</strong></p><p>I have built a guide to help navigate the model capacity and help you start creating your avatar.</p><p><strong>Download the User Guide v4.3 here: </strong><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/Anashel/rpg/resolve/main/RPG-V4-Model-Download/RPG-Guide-v4.pdf\"><strong>RPG User Guide v4.3</strong></a><br /></p><p>If you like the model, please leave a review!</p><p>This model card focuses on <strong>Role Playing Game</strong> portrait similar to Baldur's Gate, Dungeon and Dragon, Icewindale, and more modern style of RPG character.</p><p>The model is the result of various iterations of merge pack combined with Dreambooth Training. This is a work in progress. If you are interested to help, reach me via <a target=\"_blank\" rel=\"ugc\" href=\"https//discord.gg/arg\">Discord</a> user <strong>Anashel</strong>.</p><p></p><p><strong>LAST UPDATE January 31th:</strong></p><p>Version 4.0 published with new concepts</p><ul><li><p>Cloth &amp; Dress</p></li><li><p>Cloak</p></li><li><p>Battle Worn Armor</p></li><li><p>Body Tattoo</p></li></ul><p></p>","ratingcount":164,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"DosMix":{"status":"inactive","modelid":"civitai-7328","rating":4.94,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/ccdff29f-16cd-4f56-0fbc-3a0652c5e500/width=450/67938.jpeg","description":"<p></p><p>Alternative use of ClipSkip 1 or 2</p><p>While this model may seem fine to some, it may be an unpleasant trough to some.<u> The solution is to write at the prompt (Realistic:0.1~1.4) or(realistic:0.1~1) in the negative prompt.</u></p><p></p><p>Default prompt: best quality, masterpiece</p><p>default negative prompt: (low quality, worst quality:1.4)</p><p></p><p></p><p>Recommended: Sampler, <s>eluer a, DPM++SDE Karras. Step 20, scale 6,</s>(Modified. You can use a high scale and step. I'm not good at drawing pictures).</p><p></p><p>Apply VAE. kl-f8-anime2 or vae-ft-mse-840000-ema-pruned</p><p></p><p><s>clip skip 2</s></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt</a> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae\">https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae</a> Apply VAE. You will get better color results.</p><pre><code></code></pre><p></p><p>hires fix denoise 0.5, upscale by 2. Latent, R-ESRGAN 4×+ Anime6B.</p><p>If you don't upscale the hires fix you may not get the results you expect.</p><p></p><p>This model seems to have better hand batting average than other models, but it is my personal opinion. I want you to test it yourself. I don't recommend hitting the prompt too hard. Even if you don't use the hand prompt, it comes out okay 3 times out of 10 times.</p><p></p><p>The closer the person is, the more detailed it is. Upper body, cowboy shot, these prompts are also recommended.</p><p></p><p>I also checked the operation of Colab. It works very well..</p><p></p><p>other models</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6437/anidosmix\">https://civitai.com/models/6437/anidosmix</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8437/ddosmix\">https://civitai.com/models/8437/ddosmix</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6925/realdosmix\">https://civitai.com/models/6925/realdosmix</a></p><pre><code></code></pre><p><br /></p><pre><code></code></pre><p><br /></p><pre><code></code></pre>","ratingcount":106,"config":"configs/stable-diffusion/v1-inference.yaml","default":false}," Counterfeit-V2.5":{"status":"inactive","modelid":"civitai-7425","rating":4.92,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/79a71ba8-5efb-4b47-9903-d3ab125f2800/width=450/69402.jpeg","description":"<p>high quality anime style model.</p><p>more info. <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.0\">https://huggingface.co/gsdf/Counterfeit-V2.0</a></p><p>Verson2.5 <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/gsdf/Counterfeit-V2.5\">https://huggingface.co/gsdf/Counterfeit-V2.5</a><br />EasyNegative(Negative Embedding) <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/datasets/gsdf/EasyNegative\">https://huggingface.co/datasets/gsdf/EasyNegative</a></p>","ratingcount":395,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"HARDblend":{"status":"inactive","modelid":"civitai-7552","rating":4.98,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/c344d6f1-4f7a-4d9b-c6c7-d017112eca00/width=450/70732.jpeg","description":"<p>A model that I trained over ~500 portrait photographs merged with my favorite models for versatility; Hassanblend, Aeros, RealisticVision, Deliberate, sxd, and f222.</p><p>Happy generating!</p><p>huggingface repo <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/theintuitiveye/HARDblend\"><strong><u>here</u></strong></a></p><p>If you like the model, consider supporting on <a target=\"_blank\" rel=\"ugc\" href=\"https://www.patreon.com/intuitiveai\"><strong><u>Patreon</u></strong></a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://ko-fi.com/intuitiveai\"><strong><u>Ko-fi</u></strong></a> / <a target=\"_blank\" rel=\"ugc\" href=\"https://www.paypal.com/paypalme/theintuitiveye\"><strong><u>Paypal</u></strong></a></p><p></p>","ratingcount":51,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"RealDosMix":{"status":"inactive","modelid":"civitai-8137","rating":4.9,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/0795dfb9-386a-4ba3-df43-d6c512370e00/width=450/76860.jpeg","description":"<p>!!pruned fp16 replaced with no ema. The change in quality is less than 1 percent, and we went from 7 GB to 2 GB.<br /></p><p>See example picture for prompt.There are recurring quality prompts.</p><p>vae-ft-mse-840000-ema-pruned or kl f8 amime2</p><p>img2img SD upscale method: scale 20-25, denoising 0.2-0.3 After selecting SD Upscale at the bottom, tile overlap 64, scale factor2</p><p>caution! Sampler must be DPM++SDE karras.</p><p>clip skip 2</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt\">https://huggingface.co/stabilityai/sd-vae-ft-mse-original/blob/main/vae-ft-mse-840000-ema-pruned.ckpt</a> <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae\">https://huggingface.co/AIARTCHAN/aichan_blend/tree/main/vae</a> Apply VAE. You will get better color results.</p><p>We recommend hiring and upscaling only the pictures whose faces are damaged from being far away.</p><p></p><p>As it is a semi-realistic model, we do not recommend inappropriate exposure.</p><p></p><p>There are other dos series as well.</p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6250/dosmix\">https://civitai.com/models/6250/dosmix</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6437/anidosmix\">https://civitai.com/models/6437/anidosmix</a></p><p><a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/8437/ddosmix\">https://civitai.com/models/8437/ddosmix</a></p><pre><code></code></pre><p><br /></p>","ratingcount":151,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Ares Mix":{"status":"inactive","modelid":"civitai-8145","rating":5,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/e5094812-9aa8-4809-7429-6b79cab25d00/width=450/76977.jpeg","description":"<p>Attention: You need to get your own VAE to use this model to the fullest. While it does work without a VAE, it works much better with one. I recommend you try <a rel=\"ugc\" href=\"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/tree/main\">this one</a> out.</p><p></p><p>Hey everyone. After GrapeLikeDreamFruit hit, I started missing having a more general purpose model for the mundane kind of pictures - nude photographs on different backgrounds and some light hardcore capabilities. This model here is my response to that need. It handles the female nude superbly, and while it's less of an artistic model than GrapeLike, it's still quite capable in that regard. It's quite good at hardcore, even if that is just a secondary goal for this model, and can be prompted for a variety of acts. Model has a good response to Danbooru tags.</p><p></p><p>This model involves dreamlike photoreal, so here is the <a target=\"_blank\" rel=\"ugc\" href=\"https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0/blob/main/LICENSE.md\">license</a> that you must abide by.</p><p></p><p>See examples for some ideas.</p><p></p><p>Deeper explanation:</p><p>This model merge was done following a similar phylosophy to GrapeLike: a Block merge between a realistic anatomy + skin core and a posing anime core. The block merge is done in such a way as to emphasize the anime core in the center of the Unet, while rapidly decaying back to the realistic core at the edges. This has the effect of bringing a lot of posing and composition ideas from hentai models inside the photorealistic core we have available without touching textures and photorealism. Full recipe follows:<br /><br />Anatomy core:</p><p>izumi, F222, dreamlike photoreal, realistic vision 1.2, sxd, all at the same intensity. ie, the merge chain was:<br />(((izumi + F222 0.5) + dreamlike photoreal 0.33) + realistic vision 0.25) + sxd 0.2</p><p></p><p>Anime core:</p><p>Anything v4.5 merged with Basil Mix using the same block merge coefficients used in mixing <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4451/abyssorangemix2-nsfw-hardcore\">Abyss Orange Mix</a>, then merged 40% with grapefruit, the result was merged 30% with gape60 and finally 15% with RPG v4.</p><p></p><p>Bringing both together:</p><p>The block merge for both was done using a formula. I kept the bottleneck Model A was anatomy, model B was anime. I kept the center lalyer at 0.7, as well as base alpha, then followed <code>0.8/(n**1.1)</code>as a merge rule, with n being distance from the center. Full numbers were \"0.05199847612695355,0.05722134125067434,0.06354625877794251,0.07135480548979826,0.08122523963562354,0.09407671474206218,0.11146117361039158,0.13621438760332552,0.17411011265922482,0.23892225595753655,0.373213196614723,0.8,0.7,0.8,0.373213196614723,0.23892225595753655,0.17411011265922482,0.13621438760332552,0.11146117361039158,0.09407671474206218,0.08122523963562354,0.07135480548979826,0.06354625877794251,0.05722134125067434,0.05199847612695355\".</p>","ratingcount":45,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"QGO-10b":{"status":"inactive","modelid":"civitai-8677","rating":4.8,"thumbnail":"https://imagecache.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/1b4ee5a9-1e1a-46b2-e88b-2fadca4d4200/width=450/82672.jpeg","description":"<p><strong><em>Note that a CLIP-fixed version is available below the main 10b version (because all the sample images are made on that one, and the -fix version may deviate slightly)</em></strong></p><p></p><p>The biggest difference here has not been the merge, but just cutting down on negative prompt. This can have amazing results for realism, though you may run into things that are a little <em>too</em> real. Be warned ;)</p><p>This merge involves <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/4462/aaacups\">aaacups </a>to have more variation in breast sizes, I personally have a wildcard that has the terms<em> \"big, huge, massive, giant small, tiny, flat, little, aaa\"</em> in it, followed by a <em>\"breasts, tits, boobs, chest\" </em>wildcard.</p><p>It uses <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/1116/rpg\">RPGv4</a> instead of v3. It also involves <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6319/latex-diffusion-v2\">Latex</a> to get some of the bondage model back in as well..</p><p></p><p>As you can see I am currently addicted to the \"Shirtlift\" LORA, that can be found here: <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6693/shirtlift-a-lora-for-flashing-tits\">https://civitai.com/models/6693/shirtlift-a-lora-for-flashing-tits</a> There are no words to describe how good this one is, go leave a like!</p><p>There may also be traces of the <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/7016/middle-finger-lora\">Middle Finger</a> and <a target=\"_blank\" rel=\"ugc\" href=\"https://civitai.com/models/6725/gun2head-pose\">Gun2Head Pose</a> LORAs in the examples.</p><p></p><p>Advisable to use <strong>Hires.fix </strong>with the following (or similar) settings:</p><ol><li><p><strong>Upscaler:</strong> ESRGAN_4x (NMKD superscale can be a bit sharper, which is nice for smaller upscales)</p></li><li><p><strong>Upscale by: </strong>1.1~2.0 (whatever suits your purpose)</p></li><li><p><strong>Denoising </strong>strength: 0.3 (or 0.5~0.7 if you don't mind changes from the base image)</p></li></ol><p>You can of course generate low resolution versions first, and pick out the ones you enter into the upscale process (saves a lot of time). I really takes the amount of detail, especially of the face and eyes, to the next level.</p><p>This model aims for photorealism at higher resolutions, and large variation in poses, settings and genres. (And having a lot of fun filling half the prompt with wildcards).</p><p>I will still be tweaking it in the near future, to eliminate unwanted outputs and/or increase possibilities. Let me know if you run into anything that seems off.</p><p></p><p>Shout-out to the <a target=\"_blank\" rel=\"ugc\" href=\"https://discord.com/invite/bq4jrdDvDa\">Unstable Diffusion</a> Discord, where all the cool people share their gens in #photorealistic</p>","ratingcount":45,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"Stable Diffusion v1.5":{"status":"inactive","modelid":"stable-diffusion-v1-5","rating":null,"thumbnail":"https://hallucinate.app/static/sd1-1.jpg","description":"The classic Stable Diffusion from Stability AI.","ratingcount":null,"config":"configs/stable-diffusion/v1-inference.yaml","default":false},"stable-diffusion-v1-5":{"status":"inactive","description":"Stable Diffusion version 1.5","modelid":"stable-diffusion-v1.5","website":"https://stability.ai/","thumbnail":"https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1677792559545-55FBL2X2SFVHMKFGFYO1/2777127019_abstract_shapes__colorways__patterns_and_shapes__Partnership_Stability_and_Krikey_team_together__bes.png?format=750w","width":512,"height":512,"rating":5,"ratingcount":20,"default":true},"stable-diffusion-v2-1":{"status":"inactive","description":"Stable Diffusion version 1.5","modelid":"stable-diffusion-v1.5","website":"https://stability.ai/","thumbnail":"https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1677792559545-55FBL2X2SFVHMKFGFYO1/2777127019_abstract_shapes__colorways__patterns_and_shapes__Partnership_Stability_and_Krikey_team_together__bes.png?format=750w","width":512,"rating":5,"ratingcount":20,"height":512,"default":true}}